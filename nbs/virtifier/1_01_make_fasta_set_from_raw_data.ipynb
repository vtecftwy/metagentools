{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make fasta sets from from Seq2Vec raw data (Virtifier)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data in the Seq2Vec repo are encoded into sequences of numbers, instead of letter codons.\n",
    "\n",
    "This notebook make proper fasta files out of the raw data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import shutil\n",
    "\n",
    "from pathlib import Path\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Training Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "File Structure:\n",
    "```\n",
    "project\n",
    "  |\n",
    "  |---data\n",
    "  |     |\n",
    "  |     |-virtifier\n",
    "  |     |     |\n",
    "  |     |     |- raw  (data from Seq2Vec repo: https://github.com/crazyinter/Seq2Vec)\n",
    "  |     |     |   |- embedding_matrix.csv\n",
    "  |     |     |   |- NCBI_accession_numbers_of_the_whole_Refseq_genomes.xlsx\n",
    "  |     |     |   |- test_real_data.fasta\n",
    "  \n",
    "  |     |     |   |- train_300bp.fasta\n",
    "  |     |     |   |- train_500bp.fasta\n",
    "  |     |     |- processed  (all processed files from raw)\n",
    "  |     |     |      |\n",
    "  |     |     |      |\n",
    "  \n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = Path('../../data/virtifier').resolve()\n",
    "raw = data_dir / 'raw'\n",
    "processed = data_dir / 'processed'\n",
    "assert data_dir.is_dir()\n",
    "assert raw.is_dir()\n",
    "assert processed.is_dir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9000, 298) (9000, 498)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([46., 57., 35., 61., 16.,  6.,  9., 35., 61., 16.])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_file_300 = raw /'train_300bp.fasta'\n",
    "train_file_500 = raw /'train_500bp.fasta'\n",
    "\n",
    "assert train_file_300.is_file()\n",
    "assert train_file_500.is_file()\n",
    "\n",
    "X_train_300=np.loadtxt(open(train_file_300,\"rb\"),delimiter=\",\",skiprows=0)\n",
    "X_train_500=np.loadtxt(open(train_file_500,\"rb\"),delimiter=\",\",skiprows=0)\n",
    "print(X_train_300.shape, X_train_500.shape)\n",
    "X_train_300[0,:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Codon 2 Numerical Code\n",
    "Conversion between codon and number code according to the Virifier code. The conversion dictionary is saved in a json file. For conversion identical to the one used by `Seq2Vec` package (Vitrifier), the file is `seq2vec_codon2codes.json` in processed directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TGTCTATTCTATTATATTATATAGACGGATTAGTCTCAAACCTTTGATATTAAAAGGTTTGAGTTTTTTATTTTTATCTAACAATAGAATTAACAGAGTTTTTAACAGAGTTCTATTTTAAAAGTTGGCATACTTAGTAAATAGTTCAAGCTCTTTATTCTTCTTTTCGGGCTCAAGATGTGAGTATAGGTCCATAGTCAATTGCAACTTTGAATGACCTAGCCTTTCTTGAATCACTTTATAACTCATTTCAGCATTTAAACAAAGGCTAGCGTGTGAACGCCTGAATCCATGAAAGCTCAACAACGGCAGTTCAGCATTTTTGATTATATTATTCAGCTTGTAGATAAGGTTGTGATAATCCATCACTCCACCTTCTATTTTTGGAAATACTAGGTTTTGTTGTGGATTTCCTAACTTCATAAAGTGTTTCTTTTGAAAGAAGTACCAGCTTTTTAATACATAAATTGCCTTATCGTCAATGCTAATAATTCGATTGC\n",
      "GAAATTACTAAGACAAGGTTCTTTGTCAGTAAATCTGGGACACGTACTGGTAAAGGGTTGCGTCATAAAGTAATTTCATCAATTTTTGATACGAAACATGTCAATCTAGACGAACTCTCAAATAAGGCAACGGCTGCAATGGCTTGGGCTGGATTTGATGGCGGAGAAATGTTACTGGTGACTGAATCAGGAGAAATCGGAAAAAGCTTAGAACGTTATTTGAAAATACTGGCTACTGAAAGTACATATCGTGGTCGAGGTATCGGTCAAAACTATGCGGATATTAATCTTACTGGTGTGCTGTCTATTGATTCAAATGAAAAAGTTCTGTTTTCTTCTGAGATGAATAGCAGGGCTGTGAACATTGCTTTTAAGAATCGTCCTAAAGGGGAAACTGATAGCGAACGTGAATCAATCTTTGCGCCCTACTGGGAAGCATTTACTGAACAGCGTGTATCTGAGACCAGTCGAGAAGCAACGGCGCTTGCAGGAGTGCTGCT\n",
      "AGGCTTAACAATCTGTTTGAATTAGCTTTAGGGGGAAGTATTTCATATCCTACAGGAGAATGAGAAATAGCTTTGTTGATATCAAGAGTTGATTTTCTATAATCTTTCCATTCAAGAGCGAGAAGTTCACCTTTACGAATTCCAGTAAAAGCAAGGATACGAAATAAAGCTATTTTCTTAATATCATTCGTTTTTTCTACTAAAGCCATAAAATCTCTTAATTCATCGGTATCATAAAAGTCTTTCTTTTCTTCAACTTTTTTCTTAATACCTTGAGACGTCACAGGAAGCGCTGGATTAGCTTGTATGTAACTTAGCAGAGCAGCGTGATTAAATACCTTGCGAACCATTCCGAAGAGTTTACGAGCGAATTTAAGCTTCTCAGATAAATCATTTCTAAAGTTTTGTAACTCCATGGGTGTAAAATCTGATAGTTTTGTGCTTCCTATGACGGGTAAGACATGTTTTTCAAAAGCTCGAGTAGTTTTGTAGTAAGTGCT\n"
     ]
    }
   ],
   "source": [
    "def decode_sequence(seq, code2codon=None):\n",
    "    \"\"\"Takes a sequence encoded for Seq2Vec (stride 1) and recover the initial sequence as a letter string\"\"\"\n",
    "\n",
    "    if code2codon is None:\n",
    "        # Build the list to convert a codon code into a three letter string \n",
    "        # Format: code2codon[i] returns the three letter codon\n",
    "        \n",
    "        # load the codon2code dictionary from json file\n",
    "        json_fname =  processed/ 'seq2vec_codon2codes.json'\n",
    "        \n",
    "        if not json_fname.is_file():\n",
    "            raise ValueError(f\"Must have {json_fname.name} file in virtifier data folder\")\n",
    "        with open(json_fname, 'r') as fp:\n",
    "            codon2code = json.load(fp)\n",
    "\n",
    "        # build list by using each (codon, code) present in the dictionary. All others are 'Unknow'\n",
    "        code2codon = ['Unknow'] * 65\n",
    "        for codon, i in codon2code.items():\n",
    "            code2codon[i] = codon\n",
    "\n",
    "    # check format of the passed sequence and cast it as a np.array\n",
    "    if isinstance(seq, list):\n",
    "        seq = np.array(seq)\n",
    "    elif seq.ndim > 1:\n",
    "        raise ValueError('seq should be a list or a 1D np.array')\n",
    "\n",
    "    seq_len = seq.shape[0]\n",
    "    sep = ''\n",
    "    s = sep.join([code2codon[int(i)][0] for i in seq]) + sep + code2codon[int(seq[seq_len-1])][1:]\n",
    "    return s\n",
    "\n",
    "for seq_nbr in [0, 10, 30]:\n",
    "    seq_decoded = decode_sequence(X_train_500[seq_nbr, :])\n",
    "    print(seq_decoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Sequence 0\n",
      "TGTCTATTCTATTATATTATATAGACGGATTAGTCTCAAACCTTTGATATTAAAAGGTTTGAGTTTTTTATTTTTATCTAACAATAGAATTAACAGAGTTTTTAACAGAGTTCTATTTTAAAAGTTGGCATACTTAGTAAATAGTTCAAGCTCTTTATTCTTCTTTTCGGGCTCAAGATGTGAGTATAGGTCCATAGTCAATTGCAACTTTGAATGACCTAGCCTTTCTTGAATCACTTTATAACTCATTTCAGCATTTAAACAAAGGCTAGCGTGTGAACGCCTGAATCCATGAAAGCT\n",
      "> Sequence 1\n",
      "TTTTATTGCTTTTTGGTGTATCTTGAATTTGAAATCGTCTAACTGTGGTTTTGCTGACAGATACAGTCTGGTTTTGAAAGTTAATATCAGACCATGATAAGGCCATAGCTTCGCCAATACGCAAACCAGAAGCCACAAGCAAGCGTAGAAGAGCTTTAAAGTATTCATTTGACCACTGGCCACTCTTTAGAGATTCAAGGTAATTAAAGAGTTTTGCTAATTCCGATTTTTTGTAGAACTTTATCTCTTTTTTTGCTTGTTCCACCTTTACTTGGGGTACGATCACTGACTGACAAGGAT\n",
      "> Sequence 2\n",
      "GGCAAAGTATAATTATCGAGATTTGATCTCATTTGGTCAATAGAACCTATTTTACGTTGCAGCTTATAAAGTTCAAAAAAGCTCTCAGCAACCTCTTCAAAAGTTTCGAGTGATTCTTTACCTTTGGTGTTACCGTTCTTTTTAAAATTATTTTTCAGGCGTTCTAGTTCATTCTTGACGCCTGTTTTTGTGCGCCCTCTAATATCTGTTTTTATTTGCTTACCTGTCAGCACATCAGTACCGATATAAGCGCCACGGAGAATATAACGCACCTCTCCGGCTTTTGTTTTGTATTCTTTT\n",
      "> Sequence 3\n",
      "TCTAAGAAATCCTCTAGAGAATGTAGCCTTTCAAGTATTTCCCTAGAATTCTCTGTTAAATAATCCTCGGCACTTGTCTCTTCATTGTTGTTATTATAGTAACTTTTGTACGAATATTTCATAGTGTCAAGGATTCTAGTACGCAATTCTCTACTAAGATTCATTAATATTTTGCGTTCCAAACTTTCAGGATCCGACCAAGATTCAATAGTATATTTTTTAGTCTCATTAAACTTTTTATCTGCTTGTTCAGTATTTAAGAAACTTGAAGCATTTGAATACATTATACTTTTTACTTCA\n",
      "> Sequence 4\n",
      "ACCTTTTCCAGCGCTAAAGAGAGCGCCAAACTCTTCAAGCGTCATTCCCTTTTTAGTTCGTATACTTTTTATTCTCTGACCAATATCAACTTTATTATTATTCATATTTACACCTCTAAGAAAAATTATAACATTATTCTAATAAAAAAAACTAAAAAAGTTCTAAAAAGTTACACGTTTTTGTTATTTTTCTCTTGACAACGATTATTAAATAAGTTATTATGGGTGTATAAAGTTACGAAGGAGGTTGCTTGTGAATACTAAAAACAAGATTAAAGGTTACCGTAATATGCTCGGAAA\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def array2sequences(a):\n",
    "    \"\"\"Build list to convert a codon code into a three letter string\n",
    "\n",
    "    Format: code2codon[i] returns the three letter codon\n",
    "    \"\"\"\n",
    "    \n",
    "    # load the codon2code dictionary from json file\n",
    "    seq2vec_json = processed / 'seq2vec_codon2codes.json'\n",
    "    \n",
    "    if not seq2vec_json.is_file():\n",
    "        raise ValueError(f\"Must have {seq2vec_json.name} file in data folder\")\n",
    "    with open(seq2vec_json, 'r') as fp:\n",
    "        codon2code = json.load(fp)\n",
    "\n",
    "    # build list by using each (codon, code) present in the dictionary. All others are 'Unknow'\n",
    "    code2codon = ['Unknow'] * 65\n",
    "    for codon, i in codon2code.items():\n",
    "        code2codon[i] = codon\n",
    "    sequences = ''\n",
    "    \n",
    "    for n, row in enumerate(a):\n",
    "        \n",
    "        s = decode_sequence(row, code2codon=code2codon)\n",
    "        sequences = sequences + f\"> Sequence {n}\\n{s}\\n\"\n",
    "    return sequences\n",
    "\n",
    "print(array2sequences(X_train_300[:5, :]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Sequence 0\n",
      "GCTCCAGTAATGACCGCTGACATCGCTTGTTCTGGAACCGCCAAGTCTTTAGCAATTGTTAATTCTGAAGGATTAGTGAAACGGCTGATATAAGGAGAAACAGCATTCAAGAAATCTGCATGTTCAGATTTAATCAACATTGGGACAGCTTTAGACAATGGAGTATTAACCTCAGCACGAATATTACGAACGGCTGTAATTAATTCGATTAACATCGCCACACCTTCGCTTGCCTTGTCATCATTAAATTCTGGACGTACTTTTGGATATTCGGCAACAACAATTGAACCAGAAGTATTT\n",
      "> Sequence 1\n",
      "AACACCAAATTCAAATTTATCCATTTGTTCAGTCACGCGCTCAACAGTATCATTCAAACGTGTCAAAATCCAACGGTCAGTGACATTACCAGCAGTTTTATTTGCAACTTTTGTCAAAGCCGAAGAAACAGCATCAGCGCTGATATCTTCTGCATTCATCAAAATATAACGTGAAACATTCCAAATTTTATTGATGAAATTCCAAGCGGCATCCATTTTATCATAAGAAAAACGTACATCTTGTCCTGGTGCAGAACCATTTGATAGGAACCAACGGAGTGCATCAGCTCCATACTTTTC\n",
      "> Sequence 2\n",
      "TGAAGTCTGCTGAGTTTTCGTCTGGCCAACCCATTGTTGAAAACGGCCACAAAGCTGAACTAAACCAAGTATCGAGCACATCTTCATCTTGTGTCCAACCTTCTCCCTCAGGTGCTTCTTCACCAACATACATTTCACCCGCTTCATTATACCAAGCTGGAATTTGATGTCCCCACCAAAGTTGACGTGAAATAACCCAATCATGAACATTTTCCATCCATTGCATGAAAGTATCATTGAAACGTGGCGGATAAAATTCTACTGCATCTTCTGTTGTTTGATTAGCAATTGCATTCTTAG\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(array2sequences(X_train_300[-3:,:]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save sequences in fasta file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(processed / 'training_sequences_300bp.fasta', 'w') as fp:\n",
    "    fp.write(array2sequences(X_train_300))\n",
    "\n",
    "with open(processed / 'training_sequences_500bp.fasta', 'w') as fp:\n",
    "    fp.write(array2sequences(X_train_500))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load and Convert Test data\n",
    "Must handle line by line because the sequences do not have the same length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reached EOF\n"
     ]
    }
   ],
   "source": [
    "test_file = raw / 'test_real_data.fasta'\n",
    "test_fasta = processed / 'test_sequences.fasta'\n",
    "\n",
    "assert test_file.is_file\n",
    "\n",
    "# output file will be create by appending lines, must delete any pre-existing file.\n",
    "if test_fasta.is_file():\n",
    "    os.remove(test_fasta)\n",
    "\n",
    "with open(test_file, 'r') as fp_in:\n",
    "    with open(test_fasta, 'a') as fp_out:\n",
    "        n = 1\n",
    "        while True:\n",
    "            line = fp_in.readline()\n",
    "            if line == '':\n",
    "                print('Reached EOF')\n",
    "                break\n",
    "            else:\n",
    "                s = decode_sequence(line.split(','))\n",
    "                fp_out.write(f\"> Sequence {n}\\n\")\n",
    "                fp_out.write(f\"{s}\\n\")\n",
    "                n += 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
