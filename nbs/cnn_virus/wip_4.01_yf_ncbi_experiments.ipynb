{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiments for Inference and Analysis NCBI Yellow Fever"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TBC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Imports and setup environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "`ecutilities` already installed\n",
      "`metagentools` already installed\n"
     ]
    }
   ],
   "source": [
    "# Install required custom packages if not installed yet.\n",
    "import importlib.util\n",
    "if not importlib.util.find_spec('ecutilities'):\n",
    "    print('installing package: `ecutilities`')\n",
    "    ! pip install -qqU ecutilities\n",
    "else:\n",
    "    print('`ecutilities` already installed')\n",
    "if not importlib.util.find_spec('metagentools'):\n",
    "    print('installing package: `metagentools')\n",
    "    ! pip install -qqU metagentools\n",
    "else:\n",
    "    print('`metagentools` already installed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set autoreload mode\n",
      "Tensorflow version: 2.8.2\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Import all required packages\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "import time\n",
    "\n",
    "from datetime import datetime\n",
    "from ecutilities.core import files_in_tree\n",
    "from ecutilities.ipython import nb_setup\n",
    "from functools import partial\n",
    "from IPython.display import display, update_display, Markdown, HTML\n",
    "from pandas import HDFStore\n",
    "from pathlib import Path\n",
    "from pprint import pprint\n",
    "from tqdm.notebook import tqdm, trange\n",
    "\n",
    "# Setup the notebook for development\n",
    "nb_setup()\n",
    "\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' # or any {'0', '1', '2'}\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.client import device_lib\n",
    "from tensorflow.keras.models import load_model\n",
    "print(f\"Tensorflow version: {tf.__version__}\\n\")\n",
    "\n",
    "from metagentools.cnn_virus.data import _base_hot_encode, strings_to_tensors\n",
    "from metagentools.cnn_virus.data import split_kmer_into_50mers, combine_predictions\n",
    "from metagentools.cnn_virus.data import FastaFileReader, FastqFileReader, AlnFileReader\n",
    "from metagentools.cnn_virus.data import OriginalLabels\n",
    "from metagentools.cnn_virus.data import string_input_batch_to_tensors, split_kmer_batch_into_50mers\n",
    "from metagentools.cnn_virus.architecture import create_model_original\n",
    "from metagentools.core import ProjectFileSystem, TextFileBaseReader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "List all computing devices available on the machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Devices:\n",
      "  - CPU  /device:CPU:0                          \n",
      "  - GPU  /device:GPU:0  NVIDIA GeForce GTX 1050 \n"
     ]
    }
   ],
   "source": [
    "devices = device_lib.list_local_devices()\n",
    "print('\\nDevices:')\n",
    "for d in devices:\n",
    "    t = d.device_type\n",
    "    name = d.physical_device_desc\n",
    "    l = [item.split(':', 1) for item in name.split(', ')]\n",
    "    name_attr = dict([x for x in l if len(x)==2])\n",
    "    dev = name_attr.get('name', ' ')\n",
    "    print(f\"  - {t}  {d.name} {dev:25s}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Setup paths to files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Key folders and system information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running linux on local computer\n",
      "Device's home directory: /home/vtec\n",
      "Project file structure:\n",
      " - Root ........ /home/vtec/projects/bio/metagentools \n",
      " - Data Dir .... /home/vtec/projects/bio/metagentools/data \n",
      " - Notebooks ... /home/vtec/projects/bio/metagentools/nbs\n"
     ]
    }
   ],
   "source": [
    "pfs = ProjectFileSystem()\n",
    "pfs.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `p2model`: path to file with saved original pretrained model\n",
    "- `p2virus_labels` path to file with virus names and labels mapping for original model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "p2model = pfs.data / 'saved/cnn_virus_original/pretrained_model.h5'\n",
    "assert p2model.is_file(), f\"No file found at {p2model.absolute()}\"\n",
    "\n",
    "p2virus_labels = pfs.data / 'CNN_Virus_data/virus_name_mapping'\n",
    "assert p2virus_labels.is_file(), f\"No file found at {p2virus_labels.absolute()}\"\n",
    "\n",
    "p2fasta = pfs.data / 'ncbi/refsequences/yf/yf_2023_yellow_fever.fa'\n",
    "assert p2fasta.is_file(), f\"No file found at {p2fasta.absolute()}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Load reference sequence data and review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "fasta = FastaFileReader(p2fasta);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 69 sequences in this file\n",
      "\n",
      "First Sequence:\n",
      ">11089:ncbi:1\t1\tAY968064\t11089\tncbi\tAngola_1971\n",
      "ATGTCTGGTCGAAAAGCTCAGGGTAAAACCCTGGGCGTCAATATGGTAAGACGAGGGGTTCGCTCCTTGTCAAACAAAAT ...\n",
      "{'accession': 'AY968064', 'organism': 'Angola_1971', 'seqid': '11089:ncbi:1', 'seqnb': '1', 'source': 'ncbi', 'taxonomyid': '11089'}\n",
      "\n",
      "Last Sequence:\n",
      ">11089:ncbi:69\t69\tOM066737\t11089\tncbi\tVHF-21-037/GHA/Damongo/2021\n",
      "ATGTCTGGTCGTAAAGCTCAGGGCAAAACCCTGGGCGTCAATATGGTACGACGAGGAGTCCGCTCCNNNNNNNNNAAAAT ...\n",
      "{'accession': 'OM066737', 'organism': 'VHF-21-037/GHA/Damongo/2021', 'seqid': '11089:ncbi:69', 'seqnb': '69', 'source': 'ncbi', 'taxonomyid': '11089'}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "69"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fasta.review()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Load simulated reads and review"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check which simread files are already created:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "simreads\n",
      "  |--yf\n",
      "  |    |--readme.md (0)\n",
      "  |    |--single_1seq_150bp\n",
      "  |    |    |--single_1seq_150bp.fq (1)\n",
      "  |    |    |--single_1seq_150bp.aln (2)\n",
      "  |    |--single_69seq_150bp\n",
      "  |    |    |--single_69seq_150bp.fq (3)\n",
      "  |    |    |--single_69seq_150bp.aln (4)\n",
      "  |    |--paired_1seq_150bp\n",
      "  |    |    |--paired_1seq_150bp2.aln (5)\n",
      "  |    |    |--paired_1seq_150bp2.fq (6)\n",
      "  |    |    |--paired_1seq_150bp1.fq (7)\n",
      "  |    |    |--paired_1seq_150bp1.aln (8)\n",
      "  |    |--paired_69seq_150bp\n",
      "  |    |    |--paired_69seq_150bp1.fq (9)\n",
      "  |    |    |--paired_69seq_150bp2.fq (10)\n",
      "  |    |    |--paired_69seq_150bp1.aln (11)\n",
      "  |    |    |--paired_69seq_150bp2.aln (12)\n"
     ]
    }
   ],
   "source": [
    "files_in_tree(pfs.data / 'ncbi/simreads/yf');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "p2fastq = pfs.data / 'ncbi/simreads/yf/single_1seq_150bp/single_1seq_150bp.fq'\n",
    "assert p2fastq.exists()\n",
    "p2aln = pfs.data / 'ncbi/simreads/yf/single_1seq_150bp/single_1seq_150bp.aln'\n",
    "assert p2aln.exists()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16,999 simulated reads\n"
     ]
    }
   ],
   "source": [
    "fastq = FastqFileReader(p2fastq)\n",
    "for i, fq_read in enumerate(fastq):\n",
    "    pass\n",
    "print(f\"{i:,d} simulated reads\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16,999 simulated reads\n"
     ]
    }
   ],
   "source": [
    "aln = AlnFileReader(p2aln)\n",
    "for i, aln_read in enumerate(aln):\n",
    "    pass\n",
    "print(f\"{i:,d} simulated reads\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/bin/art_illumina -i /home/vtec/projects/bio/metagentools/data/ncbi/refsequences/yf/yf_1971_angola.fa -ss HS25 -l 150 -f 250 -o /home/vtec/projects/bio/metagentools/data/ncbi/simreads/yf/single_1seq_150bp/single_1seq_150bp -rs 1724156163\n",
      "@SQ\t11089:ncbi:1\t1\tAY968064\t11089\tncbi\tAngola_1971\t10237\n"
     ]
    }
   ],
   "source": [
    "print(aln.header['command'])\n",
    "print('\\n'.join(aln.header['reference sequences']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction Loop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Yellow_fever_virus', 118)]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(k,v) for k, v in OriginalLabels()._species2label.items() if 'yellow' in k.lower()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([8, 150, 5]), TensorShape([8, 187]), TensorShape([8, 10]))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aln.reset_iterator()\n",
    "for batch in aln.cnn_virus_input_generator(bs=8, label=118):\n",
    "    kmer_tensor, (label_tensor, position_tensor) = string_input_batch_to_tensors(batch, k=150)\n",
    "    break\n",
    "\n",
    "kmer_tensor.shape, label_tensor.shape, position_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([808, 50, 5])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split_kmer_batch_into_50mers(kmer_tensor).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([8, 150, 5]), 808)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kmer_tensor.shape, (kmer_tensor.shape[1]-49) * kmer_tensor.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_label_predictions(probs_elements, prob_threshold=0.9):\n",
    "    \"\"\"???\"\"\"\n",
    "\n",
    "    label_probs = probs_elements[0]\n",
    "    position_probs = probs_elements[1]\n",
    "\n",
    "    labels_preds = tf.argmax(label_probs, axis=1)\n",
    "    positions_preds = tf.argmax(position_probs, axis=1)\n",
    "\n",
    "    valid_labels_filter = tf.reduce_max(label_probs, axis=1) > prob_threshold\n",
    "    valid_labels_preds = labels_preds[valid_labels_filter]\n",
    "    \n",
    "    valid_positions_preds = positions_preds[valid_labels_filter]\n",
    "\n",
    "\n",
    "    if valid_labels_preds.shape[0] == 0:\n",
    "        combined_label = tf.constant(187, shape=(1,), dtype=tf.int64)\n",
    "        combined_position = tf.constant(10, shape=(1,), dtype=tf.int64)\n",
    "\n",
    "    else:\n",
    "        uniques, _, counts = tf.unique_with_counts(valid_labels_preds)\n",
    "        combined_label = uniques[tf.argmax(counts)]\n",
    "\n",
    "        # filter which reads give the majority label prediction\n",
    "        combined_label_filter = valid_labels_preds == combined_label\n",
    "\n",
    "        # pick the corresponding position predictions\n",
    "        filtered_positions = valid_positions_preds[combined_label_filter]\n",
    "        unique_positions, _, counts = tf.unique_with_counts(filtered_positions)\n",
    "        combined_position = unique_positions[tf.argmax(counts)]\n",
    "\n",
    "        combined_pred = tf.concat([combined_label, combined_position], axis=0)\n",
    "\n",
    "    return combined_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_predictions(probs, n=3):\n",
    "\n",
    "    def top_n_most_frequent(preds, n=3):\n",
    "        \"\"\"Returns the top n most frequent predictions for each read\"\"\"\n",
    "        # print(preds.shape)\n",
    "        uniques, counts = np.unique(preds, return_counts=True)\n",
    "        top_idx = np.argsort(counts)[-n:]\n",
    "        return uniques.take(top_idx)\n",
    "\n",
    "    top_preds_in_50mers = np.argsort(probs, axis=-1)[:, :, -n:]\n",
    "    nb_seq, nb_50mer, nb_lbls = top_preds_in_50mers.shape\n",
    "    # print(top_preds_in_50mers.shape)\n",
    "    top_preds_in_kmer = top_preds_in_50mers.reshape(nb_seq,nb_50mer * nb_lbls)\n",
    "    # print(top_preds_in_kmer.shape)\n",
    "\n",
    "    return np.apply_along_axis(top_n_most_frequent, axis=1, arr=top_preds_in_kmer, n=n)\n",
    "\n",
    "# top_predictions(label_probs_per_kmer, n=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_successive_label_preds(label_probs_per_kmer):\n",
    "    series = []\n",
    "    label_preds_per_kmer = tf.argmax(label_probs_per_kmer, axis=2)\n",
    "    same_as_next = tf.roll(label_preds_per_kmer, shift=-1, axis=1) == label_preds_per_kmer\n",
    "    same_as_previous = tf.roll(label_preds_per_kmer, shift=+1, axis=1) == label_preds_per_kmer\n",
    "    xor = tf.bitwise.bitwise_xor(tf.cast(same_as_next, dtype=tf.int16), tf.cast(same_as_previous, dtype=tf.int16))\n",
    "    for i in range(b):\n",
    "        kmer_series_idxs = tf.range(k-49)[tf.cast(xor[i], dtype=tf.bool)]\n",
    "        start_idxs = kmer_series_idxs[0::2]\n",
    "        end_idxs = kmer_series_idxs[1::2]\n",
    "        kmer_series = {key: [] for key in range(187)}\n",
    "        for s,e in zip(start_idxs, end_idxs):\n",
    "            kmer_series[label_preds_per_kmer[i,s].numpy().item()].append((e-s+1).numpy().item())\n",
    "        series.append(kmer_series)\n",
    "    return series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run the Loop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before running the next cell, define:\n",
    "- size of the batch `b`\n",
    "- the number of bp in a k-mer\n",
    "- the number n for top-n predictions to save\n",
    "- whether to run the full loop or only a few batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'single_1seq_150bp'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fastq = FastqFileReader(p2fastq);\n",
    "aln = AlnFileReader(p2aln)\n",
    "p2fastq.stem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = 1024     # number of k-mer in a batch\n",
    "k = 150\n",
    "top_n = 5   # n for top-n prediction to keep\n",
    "run_all_batches = False\n",
    "nb_batches_to_run = 2\n",
    "\n",
    "uid = datetime.today().strftime('%Y-%m-%d_%H_%M_%S')\n",
    "\n",
    "p2result_folder = pfs.data /'ncbi/infer_results/yf-ncbi'\n",
    "p2results = p2result_folder / f\"{p2fastq.stem}-{uid}-results.csv\"\n",
    "p2probs = p2result_folder / f\"{p2fastq.stem}-{uid}-probs.csv\"\n",
    "\n",
    "nb_50mer = k - 49\n",
    "print(f\"Run prediction loop with the following parameters:\")\n",
    "print(f\"   {b} k-mer per batch; {k} bp per sequence; keep top-{top_n} predictions\")\n",
    "\n",
    "fastq.reset_iterator()\n",
    "aln.reset_iterator()\n",
    "model = create_model_original(path2parameters=p2model)\n",
    "\n",
    "# create a dataframe to store results\n",
    "pred_cols = ['lbl_pred','pos_pred']\n",
    "top_pred_cols = [f\"top_{top_n}_lbl_pred_{i}\" for i in range(top_n)]\n",
    "prob_cols = [f\"R{i}ProbL{j}\" for i in range(k-49) for j in range(187)]\n",
    "df = pd.DataFrame(\n",
    "    columns=pred_cols + top_pred_cols + ['series']\n",
    ")\n",
    "\n",
    "df_probs = pd.DataFrame(\n",
    "    columns= prob_cols,\n",
    "    dtype=float\n",
    ")\n",
    "\n",
    "df.to_csv(p2results)\n",
    "df_probs.to_csv(p2probs)\n",
    "print(f\"results will be saved to {p2results.absolute()} and \\nprobs will be saved to {p2probs.absolute()}\")\n",
    "\n",
    "batch_seq_strings = []\n",
    "batch_seq_refs = []\n",
    "batch_nb = 1\n",
    "print(f\"Batch {batch_nb:3d} ...\")\n",
    "load_seq_starts = time.time()\n",
    "\n",
    "for i,fqelement in enumerate(fastq):\n",
    "    seq = fqelement['sequence'][:k]\n",
    "    batch_seq_strings.append(f\"{seq}\\t0\\t0\")\n",
    "    batch_seq_refs.append(fqelement['definition line'])\n",
    " \n",
    "    # After reading b sequences from the fq file, make a prediction and load results in a dataframe\n",
    "    if (i+1) % b == 0:\n",
    "        pred_starts = time.time()\n",
    "        print(f\"   {b} sequences loaded in {time.time() - load_seq_starts:.2f} s\")\n",
    "        print(f\"   prediction for batch {int((i+1)/b)} starting ...\")\n",
    "        # Prediction\n",
    "        strings_ts = tf.convert_to_tensor(batch_seq_strings)\n",
    "        seqs_kmer, (labels, positions) = base_string_kmers_to_tensors(strings_ts, k)\n",
    "        last_step = pred_starts\n",
    "        current_step = time.time()\n",
    "        # print(f\"       str to tensor: {current_step - last_step:.2f} s at {datetime.now().strftime('%H:%M:%S')}\")\n",
    "\n",
    "        seqs_50mer = split_kmer_batch_into_50mers(seqs_kmer)\n",
    "        last_step = current_step\n",
    "        current_step = time.time()\n",
    "        # print(f\"       split_kmer: {current_step - last_step:.2f} s at {datetime.now().strftime('%H:%M:%S')}\")\n",
    "\n",
    "        labels_probs, positions_probs = model.predict(seqs_50mer)\n",
    "        last_step = current_step\n",
    "        current_step = time.time()\n",
    "        print(f\"       model predict: {current_step - last_step:.2f} s at {datetime.now().strftime('%H:%M:%S')}\")\n",
    "\n",
    "        label_probs_per_kmer = tf.reshape(labels_probs, shape=(b,nb_50mer,-1))\n",
    "        position_probs_per_kmer = tf.reshape(positions_probs, shape=(b,nb_50mer,-1))\n",
    "        last_step = current_step\n",
    "        current_step = time.time()\n",
    "        # print(f\"       reshape: {current_step - last_step:.2f} s at {datetime.now().strftime('%H:%M:%S')}\")\n",
    "\n",
    "        successive_preds = count_successive_label_preds(label_probs_per_kmer)\n",
    "\n",
    "        combined_predictions = tf.map_fn(\n",
    "            fn=combine_label_predictions, \n",
    "            elems=[label_probs_per_kmer, position_probs_per_kmer], \n",
    "            fn_output_signature=tf.int64\n",
    "            )\n",
    "        last_step = current_step\n",
    "        current_step = time.time()\n",
    "        print(f\"       combine:       {current_step - last_step:.2f} s at {datetime.now().strftime('%H:%M:%S')}\")\n",
    "\n",
    "        label_predictions = combined_predictions[:,0]\n",
    "        position_predictions = combined_predictions[:,1]\n",
    "        top_preds = top_predictions(label_probs_per_kmer, n=top_n)\n",
    "\n",
    "        # Add results for batch\n",
    "        res = np.concatenate(\n",
    "            [\n",
    "                np.expand_dims(label_predictions.numpy(), axis=1),\n",
    "                np.expand_dims(position_predictions.numpy(), axis=1),\n",
    "                top_preds[:, ::-1],\n",
    "                np.expand_dims(np.array(successive_preds), axis=1)\n",
    "            ],\n",
    "            axis=1\n",
    "        )\n",
    "        df = pd.DataFrame(data=res, index=batch_seq_refs, columns=df.columns)\n",
    "        df.to_csv(p2results, mode='a', header=False)\n",
    "        \n",
    "        df_probs = pd.DataFrame(label_probs_per_kmer.numpy().reshape(b, -1), index=batch_seq_refs, columns=df_probs.columns)\n",
    "        df_probs.to_csv(p2probs, mode='a', header=False)\n",
    "        \n",
    "        # Reset batch\n",
    "        batch_seq_strings = []\n",
    "        batch_seq_refs = []\n",
    "        print(f\"   prediction done in {time.time() - pred_starts:.2f} s\")\n",
    "        batch_nb += 1\n",
    "        print(f\"Batch {batch_nb:3d} ...\")\n",
    "        load_seq_starts = time.time()\n",
    "\n",
    "    # Stop after a few batches\n",
    "    if not run_all_batches and (i+1) >= b * nb_batches_to_run: \n",
    "        break\n",
    "\n",
    "print('Done')\n",
    "print(f\"Predicted virus class for {df.shape[0]} {k}-mer sequences\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis Ideas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Other Ideas:\n",
    "- Analysing the False Negatives (top-k)\n",
    "- Can we identify a False negative vs a True Positive from the probabilities of all 101 50-mers?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate features from extracted series lengths, for each label or the top k labels evalaute for each k-mer\n",
    "- number of series\n",
    "- average length\n",
    "- maximum length\n",
    "- cummulative lengths of series ($\\sum_{series}{}$ lengths of serie)\n",
    "- standard deviation of length"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate statistics feature over all 50-mer for each k-mer (for all labels or the top k):\n",
    "- min probability across 101 50-mer\n",
    "- max probability\n",
    "- mean probability\n",
    "- standard deviation probability\n",
    "- count 50-mer probability in given quantile [(pd doc)](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.quantile.html)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate bio features:\n",
    "- position of read for TP and FN\n",
    "- mapping with the probabilities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyse accuracy per accession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p2result_folder = pfs.data /'ncbi/infer_results/yf'\n",
    "files_in_tree(path=p2result_folder);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# p2resfile = pfs.project_root /'data/ncov_data/reads/yf/yf-mapped-results-2024-04-29_17_31_10.csv'\n",
    "p2resfile = p2result_folder /'yf_2023-single-69seq-150bp-2024-05-02_16_29_18-results.csv'\n",
    "assert p2resfile.is_file()\n",
    "\n",
    "df = pd.read_csv(p2resfile, index_col=0)\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lbls = OriginalLabels(p2mapping=p2virus_labels)\n",
    "lbls.label2species(118)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df.lbl_pred == 118, :].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "29367 / df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['accession'] = df.index\n",
    "pattern = r'^@(?P<refseqid>(?P<refseq_accession>[a-zA-Z0-9]+).*)-(?P<readnb>\\d+)$'\n",
    "df['accession'] = df.loc[:, 'accession'].str.replace(pattern, r'\\g<refseq_accession>', regex=True)\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "by_accession = df.groupby('accession', sort=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_by_accession = by_accession['lbl_pred'].count()\n",
    "count_by_accession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_by_accession = (df.loc[df.lbl_pred == 118, :]).groupby('accession')\n",
    "count_correct_by_accession = correct_by_accession['lbl_pred'].count()\n",
    "count_correct_by_accession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_by_accession = count_correct_by_accession / count_by_accession\n",
    "accuracy_by_accession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(accuracy_by_accession.sort_values(ascending=True)[:20])\n",
    "display(accuracy_by_accession.sort_values(ascending=False)[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "read_ids = list(df.index)\n",
    "pattern = r'^@(?P<refseqid>(?P<refseq_accession>[a-zA-Z0-9]+).*)-(?P<readnb>\\d+)$'\n",
    "\n",
    "ids_set = set([re.sub(pattern, r'\\g<refseqid>', s) for s in read_ids])\n",
    "accessions_set = set([re.sub(pattern, r'\\g<refseq_accession>', s) for s in read_ids])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(ids_set), len(accessions_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping_accession_refseq_id = {}\n",
    "for accession in accessions_set:\n",
    "    temp_accession = None\n",
    "    for read_id in ids_set:\n",
    "        if accession in read_id:\n",
    "            if temp_accession is None:\n",
    "                temp_accession = accession\n",
    "                mapping_accession_refseq_id[accession] = read_id\n",
    "                continue\n",
    "            else:\n",
    "                print(f\"{accession} in two read ids: {temp_accession} and {read_id}\")\n",
    "                continue\n",
    "mapping_accession_refseq_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_by_accession.index = [mapping_accession_refseq_id[idx] for idx in accuracy_by_accession.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_by_accession.sort_values(ascending=False)[:33]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_by_accession.sort_values(ascending=True)[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyse same prediction series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the top k predicted label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = 'top_5_lbl_pred_0 top_5_lbl_pred_1 top_5_lbl_pred_2 top_5_lbl_pred_3 top_5_lbl_pred_4'.split(' ')\n",
    "uniques, counts = np.unique(df.loc[:, cols].values.reshape(5 * df.shape[0], -1), return_counts=True)\n",
    "uniques, counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_idxs = np.flip(np.argsort(counts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 15\n",
    "top_k_lbl = uniques[sorted_idxs[:k]].tolist()\n",
    "coverage = (counts[sorted_idxs[:k]]/counts.sum()).sum()\n",
    "print(f\"The following {k} labels represents {coverage*100:2.0f}% of all predicted labels\")\n",
    "print(top_k_lbl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_top_k_lengths(d, top_k):\n",
    "    top_k_dict = {}\n",
    "    for lbl in top_k:\n",
    "        top_k_dict[lbl] = d.get(lbl, [])\n",
    "    return top_k_dict\n",
    "\n",
    "extract_top_k_lengths(df.series.to_list()[0], top_k_lbl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyse prediction probabilities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_label_probs(probs, top_preds, targets):\n",
    "    nb_seq, _ , nb_lbls = probs.shape\n",
    "    assert nb_lbls == 187\n",
    "    fig = plt.figure(figsize=(16, 2 * nb_seq - 1));\n",
    "    # fig.suptitle('Suptitle')\n",
    "    axs = []\n",
    "    for i in range(nb_seq):\n",
    "        if top_preds[i, 0] in targets: cmap = 'YlGn_r'\n",
    "        else: cmap = 'YlOrRd_r'\n",
    "        axs.append(plt.subplot2grid((nb_seq,1), (i,0), rowspan=1, colspan=1))\n",
    "        # axs[i].axis('off')\n",
    "        axs[i].imshow(probs[i,:,:], cmap=cmap, aspect='auto')\n",
    "        axs[i].set_title(f\"Seq {i+1} - Pred: {top_preds[i,0]} - Top Predictions; {top_preds[i]}\")\n",
    "\n",
    "    fig.subplots_adjust(top=1.5, bottom=0.2, hspace=0.5)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handle entire result file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next cell load the entire result file. It takes a while to load.\n",
    "\n",
    "If the file is too big, it may fail. In that case, load the file in chunks and handle each chunck separately (see lower cells)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paths = files_in_tree(path=p2fastq.parent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paths[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# p2resfile = pfs.project_root /'data/ncov_data/reads/yf/yf-mapped-results-2024-04-29_17_31_10.csv'\n",
    "p2resfile = paths[2]\n",
    "\n",
    "df = pd.read_csv(p2resfile, index_col=0)\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# p2probsfile = pfs.project_root /'data/ncov_data/reads/yf/yf-mapped-probs-2024-04-29_17_27_31.csv'\n",
    "# p2probsfile = paths[5]\n",
    "fnbr = 0\n",
    "assert paths[fnbr].is_file()\n",
    "\n",
    "print(f\"Reading file {paths[fnbr]}\")\n",
    "df_probs = pd.read_hdf(paths[fnbr], key='df')\n",
    "print(df_probs.shape)\n",
    "df_probs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_probs.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p2hdf5 = paths[fnbr].parent / f\"{paths[fnbr].stem}.h5\"\n",
    "assert p2hdf5.suffix == '.h5'\n",
    "df_probs.to_hdf(p2hdf5, key='df', mode='w', format='table', complevel=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "187 * 101\n",
    "\n",
    "df_probs.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probs_per_kmer = df_probs[prob_cols].to_numpy().reshape(df_probs.shape[0], -1, 187)\n",
    "top_preds = df[top_pred_cols].to_numpy()\n",
    "preds = top_preds[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_pred_idxs = preds == 118\n",
    "incorrect_pred_idxs = preds != 118\n",
    "true_positives = correct_pred_idxs.sum()\n",
    "false_negatives = incorrect_pred_idxs.sum()\n",
    "accuracy = true_positives/(true_positives + false_negatives)\n",
    "print(f\"True positives:  {true_positives}\")\n",
    "print(f\"False negatives: {false_negatives}\")\n",
    "print(f\"Accuracy:        {accuracy:.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot prediction probabilities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mixed predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show profile of 101 label probabilities of each 50-mer corresponding to a k-mer read"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are about 17k reads, do not use this function for more than 50 reads at the time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_seq = 0\n",
    "nb_seq = 25\n",
    "s = slice(first_seq, first_seq+nb_seq)\n",
    "\n",
    "plot_label_probs(probs_per_kmer[s,:,:], top_preds[s], [118])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### True Positive Only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_seq = 1000\n",
    "nb_seq = 25\n",
    "s = slice(first_seq, first_seq+nb_seq)\n",
    "\n",
    "plot_label_probs(probs_per_kmer[correct_pred_idxs][s,:,:], top_preds[correct_pred_idxs][s], [118])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### False Positive Only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_seq = 1000\n",
    "nb_seq = 25\n",
    "s = slice(first_seq, first_seq+nb_seq)\n",
    "\n",
    "plot_label_probs(probs_per_kmer[incorrect_pred_idxs][s,:,:], top_preds[incorrect_pred_idxs][s], [118])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load result in chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p2resfile = pfs.project_root /'data/ncov_data/reads/yf/yf-mapped-results.csv'\n",
    "\n",
    "def result_generator(p2file, chunksize=1000):\n",
    "    for chunk in pd.read_csv(p2file, chunksize=chunksize, index_col=0):\n",
    "        yield chunk\n",
    "\n",
    "def get_chunk(p2file, chunknb, chunksize=1000):\n",
    "    gen = result_generator(p2file, chunksize=chunksize)\n",
    "    for i in range(chunknb):\n",
    "        df = next(gen)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk = get_chunk(p2resfile, chunknb=4, chunksize=1000)\n",
    "chunk.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probs_per_kmer = chunk[prob_cols].to_numpy().reshape(chunk.shape[0], -1, 187)\n",
    "top_preds = chunk[top_pred_cols].to_numpy()\n",
    "preds = top_preds[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_pred_idxs = preds == 118\n",
    "incorrect_pred_idxs = preds != 118\n",
    "true_positives = correct_pred_idxs.sum()\n",
    "false_negatives = incorrect_pred_idxs.sum()\n",
    "accuracy = true_positives/(true_positives + false_negatives)\n",
    "print(f\"True positives:  {true_positives}\")\n",
    "print(f\"False negatives: {false_negatives}\")\n",
    "print(f\"Accuracy:        {accuracy:.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mixed Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_seq = 0\n",
    "nb_seq = 25\n",
    "s = slice(first_seq, first_seq+nb_seq)\n",
    "\n",
    "plot_label_probs(probs_per_kmer[s,:,:], top_preds[s], [118])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### True Positive Only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_seq = 0\n",
    "nb_seq = 25\n",
    "s = slice(first_seq, first_seq + nb_seq)\n",
    "\n",
    "plot_label_probs(probs_per_kmer[correct_pred_idxs][s,:,:], top_preds[correct_pred_idxs][s], [118])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### False Positive Only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_seq = 0\n",
    "nb_seq = 25\n",
    "s = slice(first_seq, first_seq+nb_seq)\n",
    "\n",
    "plot_label_probs(probs_per_kmer[incorrect_pred_idxs][s,:,:], top_preds[incorrect_pred_idxs][s], [118])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Work with HDF5 Data Stores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a DataFrame from an existing probability file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a `read_store` to read some of the probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paths = files_in_tree(path=p2fastq.parent)\n",
    "paths[4].suffix == '.hdf5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p2probs = paths[4]\n",
    "p2probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "read_store = HDFStore(path=p2probs, mode='r')\n",
    "keys = read_store.keys()\n",
    "keys[:8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_nb_labels = len(read_store.keys())\n",
    "total_nb_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nrows = 4096\n",
    "nblabels = total_nb_labels\n",
    "keys = read_store.keys()\n",
    "df = read_store.select(key=keys[0], start=0, stop=nrows)\n",
    "for k in tqdm(keys[1:]):\n",
    "    df = pd.concat([df, read_store.select(key=k, start=0, stop=nrows)], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p2hdf5 = Path(\"temp.hdf5\")\n",
    "if p2hdf5.exists(): p2hdf5.unlink()\n",
    "\n",
    "nblabels = 10\n",
    "nrows = 32\n",
    "\n",
    "# Store probabilities in hdf5 format, with one label per key\n",
    "\n",
    "with HDFStore(path=p2hdf5, mode='a') as store:\n",
    "\n",
    "    # Replace '/' in index as it is not supported by hdf5\n",
    "    df.index = [idx.replace('/','-') for idx in df.index]\n",
    "    cols = df.columns\n",
    "\n",
    "    for n in trange(nblabels):\n",
    "        label_cols = [c for c in cols if c.endswith(f\"ProbL{n}\")]\n",
    "        store.put(\n",
    "            key=f'label_{n:03d}', \n",
    "            value=df.iloc[:nrows, :].loc[:,label_cols], \n",
    "            format='table', \n",
    "            append=True, \n",
    "            index=True,\n",
    "            data_columns=True\n",
    "        )\n",
    "\n",
    "    print(store.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with HDFStore(path=p2hdf5, mode='r') as store:\n",
    "    print(store.get(key='/label_001').shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with HDFStore(path=p2hdf5, mode='a') as store:\n",
    "\n",
    "    # Replace '/' in index as it is not supported by hdf5\n",
    "    df.index = [idx.replace('/','-') for idx in df.index]\n",
    "    cols = df.columns\n",
    "\n",
    "    for n in trange(nblabels):\n",
    "        label_cols = [c for c in cols if c.endswith(f\"ProbL{n}\")]\n",
    "        store.put(\n",
    "            key=f'label_{n:03d}', \n",
    "            value=df.iloc[100:100+nrows, :].loc[:,label_cols], \n",
    "            format='table', \n",
    "            append=True, \n",
    "            index=True,\n",
    "            data_columns=True\n",
    "        )\n",
    "\n",
    "    print(store.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with HDFStore(path=p2hdf5, mode='r') as store:\n",
    "    print(store.get(key='/label_001').shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with HDFStore(path=p2hdf5, mode='a') as store:\n",
    "\n",
    "    # Replace '/' in index as it is not supported by hdf5\n",
    "    df.index = [idx.replace('/','-') for idx in df.index]\n",
    "    cols = df.columns\n",
    "\n",
    "    for n in trange(nblabels):\n",
    "        label_cols = [c for c in cols if c.endswith(f\"ProbL{n}\")]\n",
    "        store.put(\n",
    "            key=f'label_{n:03d}', \n",
    "            value=df.iloc[300:300+nrows, :].loc[:,label_cols], \n",
    "            format='table', \n",
    "            append=True, \n",
    "            index=True,\n",
    "            data_columns=True\n",
    "        )\n",
    "\n",
    "    print(store.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with HDFStore(path=p2hdf5, mode='r') as store:\n",
    "    print(store.get(key='/label_001').shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('metagentools')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "d79c725d3d254ae089d5edf9eb2dce3237f80d64dd85a8bedc17bd8054b8b312"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
