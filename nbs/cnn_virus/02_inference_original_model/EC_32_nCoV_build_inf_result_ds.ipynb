{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test false positive on one non CoV sequence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Objective**: \n",
    "\n",
    "Evaluate the performance of CNN-V when presented with reads simulated from a non CoV reference sequence but that has some similitudes. We want to identify whether the model generates many false positives."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "Set autoreload mode\n"
     ]
    }
   ],
   "source": [
    "from ecutilities.ipython import nb_setup, pandas_nrows_ncols\n",
    "nb_setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import tempfile\n",
    "\n",
    "from nbdev import show_doc\n",
    "from pathlib import Path\n",
    "from pprint import pprint\n",
    "from tqdm.notebook import trange, tqdm\n",
    "\n",
    "from ecutilities.ipython import pandas_nrows_ncols\n",
    "from metagentools.art import ArtIllumina\n",
    "from metagentools.cnn_virus.data import FastqFileReader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports and paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ecutilities.core import validate_path\n",
    "from metagentools.art import ArtIllumina, _run\n",
    "from metagentools.core import TextFileBaseIterator\n",
    "from metagentools.cnn_virus.architecture import load_model\n",
    "from metagentools.cnn_virus.data import strings_to_tensors\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' # or any {'0', '1', '2'}\n",
    "from tensorflow.data import TextLineDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/vtec/projects/bio/metagentools/data\n",
      "/home/vtec/projects/bio/metagentools/data/ncov_data\n",
      "/home/vtec/projects/bio/metagentools/data/ncov_data/rhinolophus_ferrumequinum/dna\n",
      "/home/vtec/projects/bio/metagentools/data/ncov_data/rhinolophus_ferrumequinum/dna/Rhinolophus_ferrumequinum.mRhiFer1_v1.p.dna_rm.primary_assembly.1.clean.fa\n",
      "/home/vtec/projects/bio/metagentools/data/ncov_data/ncov_simreads/mRhiFer1_v1.p.dna_rm.primary_assembly.1\n"
     ]
    }
   ],
   "source": [
    "# Path to the data directory\n",
    "p2data = Path(f\"../../../data\").resolve()\n",
    "assert p2data.is_dir()\n",
    "print(p2data)\n",
    "\n",
    "# Path to the non corona virus sequence fasta files\n",
    "p2ncov_data = p2data / 'ncov_data'\n",
    "assert p2ncov_data.is_dir()\n",
    "print(p2ncov_data)\n",
    "\n",
    "p2inputs = p2ncov_data / 'rhinolophus_ferrumequinum/dna'\n",
    "assert p2inputs.is_dir()\n",
    "print(p2inputs)\n",
    "\n",
    "# Path to the reference sequence file\n",
    "p2refs = p2inputs/'Rhinolophus_ferrumequinum.mRhiFer1_v1.p.dna_rm.primary_assembly.1.clean.fa'\n",
    "assert p2refs.is_file()\n",
    "print(p2refs)\n",
    "\n",
    "# Path to the simread and input file dir\n",
    "p2simreads = p2ncov_data / 'ncov_simreads/mRhiFer1_v1.p.dna_rm.primary_assembly.1'\n",
    "assert p2simreads.is_dir()\n",
    "print(p2simreads)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create simreads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ready to operate with art: art_illumina\n",
      "Input files from : /home/vtec/projects/bio/metagentools/data/ncov_data/rhinolophus_ferrumequinum/dna\n",
      "Output files to :  /home/vtec/projects/bio/metagentools/data/ncov_data/ncov_simreads/mRhiFer1_v1.p.dna_rm.primary_assembly.1\n"
     ]
    }
   ],
   "source": [
    "app = 'art_illumina'\n",
    "art = ArtIllumina(\n",
    "    path2app=app, \n",
    "    input_dir=p2inputs, \n",
    "    output_dir=p2simreads,\n",
    "    app_in_system_path=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# art.sim_reads(\n",
    "#     input_file='Rhinolophus_ferrumequinum.mRhiFer1_v1.p.dna_rm.primary_assembly.1.clean.fa', \n",
    "#     output_seed='mRhiFer1_v1.p.dna_rm.1',\n",
    "#     sim_type='single', \n",
    "#     read_length=50,\n",
    "#     fold=100, \n",
    "#     ss='HS25',\n",
    "#     overwrite=False\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Path('/home/vtec/projects/bio/metagentools/data/ncov_data/ncov_simreads/mRhiFer1_v1.p.dna_rm.primary_assembly.1/mRhiFer1_v1.p.dna_rm.primary_assembly.1.fq')"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p2fastq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create input file from fastq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def modified_create_infer_ds_from_fastq(\n",
    "    p2fastq: str|Path,             # Path to the fastq file (aln file path is inferred)\n",
    "    output_dir:str|Path|None=None, # Path to directory where ds file will be saved\n",
    "    overwrite_ds:bool=False,       # If True, overwrite existing ds file. If False, error is raised if ds file exists\n",
    "    nsamples:int|None=None         # Used to limit the number of reads to use for inference, use all if None\n",
    ")-> (Path, np.ndarray):      # Path to the dataset file, Array with additional read information\n",
    "    \"\"\"Build a dataset file for inference only, from simreads fastq to text format ready for the CNN Virus model\n",
    "    \n",
    "    > Note: currently also return additional read information as an array. \n",
    "    >\n",
    "    > TODO: consider to save as a file\n",
    "    \"\"\"\n",
    "    if output_dir is None:\n",
    "        p2dir = Path()\n",
    "    else:\n",
    "        validate_path(output_dir, path_type='dir', raise_error=True)\n",
    "        p2outdir = output_dir if isinstance(output_dir, Path) else Path(output_dir)\n",
    "    \n",
    "    p2dataset = p2outdir / f\"{p2fastq.stem}_ds\"\n",
    "    if p2dataset.is_file():\n",
    "        if overwrite_ds: \n",
    "            p2dataset.unlink()\n",
    "        else:\n",
    "            raise ValueError(f\"{p2dataset.name} already exists in {p2dataset.absolute()}\")\n",
    "    p2dataset.touch()\n",
    "    \n",
    "    fastq = FastqFileReader(p2fastq)\n",
    "    \n",
    "    with open(p2dataset, 'a') as fp:\n",
    "        i = 1\n",
    "        for fastq_chunck in fastq.it:\n",
    "            seq = fastq_chunck['sequence']\n",
    "            fp.write(f\"{seq}\\t{0}\\t{0}\\n\")\n",
    "            i += 1\n",
    "            if nsamples:\n",
    "                if i > nsamples: break\n",
    "                    \n",
    "    print(f\"Dataset with {i-1:,d} reads\")    \n",
    "    return p2dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p2aln = p2simreads / 'mRhiFer1_v1.p.dna_rm.primary_assembly.1.aln'\n",
    "p2fastq = p2simreads / 'mRhiFer1_v1.p.dna_rm.primary_assembly.1.fq'\n",
    "\n",
    "\n",
    "# modified_create_infer_ds_from_fastq(p2fastq, p2simreads, overwrite_ds=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get predictions on the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p2saved = p2data / 'saved/cnn_virus_original/pretrained_model.h5'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have 8.3 million reads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# it = TextFileBaseIterator(p2ds)\n",
    "# for i, line in enumerate(it): pass\n",
    "# i"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is too much to handle at once. Quick solution: run the file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inference will require 7,812 batches, i.e. about 156 sec per iteration\n",
      "0\n",
      ">>> Creating small dataset with 250,000 reads\n",
      ">>> Running original model in inference on small dataset\n",
      "7813/7813 [==============================] - 160s 20ms/step\n",
      "False Positives\n",
      "CoV:  Total: 2,791, Ratio 0.011\n",
      "MERS: Total: 2,488, Ratio 0.010\n",
      "1\n",
      ">>> Creating small dataset with 250,000 reads\n",
      ">>> Running original model in inference on small dataset\n",
      "7813/7813 [==============================] - 159s 20ms/step\n",
      "False Positives\n",
      "CoV:  Total: 2,772, Ratio 0.011\n",
      "MERS: Total: 2,519, Ratio 0.010\n",
      "2\n",
      ">>> Creating small dataset with 250,000 reads\n",
      ">>> Running original model in inference on small dataset\n",
      "7813/7813 [==============================] - 159s 20ms/step\n",
      "False Positives\n",
      "CoV:  Total: 2,691, Ratio 0.011\n",
      "MERS: Total: 2,580, Ratio 0.010\n",
      "3\n",
      ">>> Creating small dataset with 250,000 reads\n",
      ">>> Running original model in inference on small dataset\n",
      "7813/7813 [==============================] - 159s 20ms/step\n",
      "False Positives\n",
      "CoV:  Total: 2,721, Ratio 0.011\n",
      "MERS: Total: 2,468, Ratio 0.010\n",
      "4\n",
      ">>> Creating small dataset with 250,000 reads\n",
      ">>> Running original model in inference on small dataset\n",
      "7813/7813 [==============================] - 159s 20ms/step\n",
      "False Positives\n",
      "CoV:  Total: 2,867, Ratio 0.011\n",
      "MERS: Total: 2,540, Ratio 0.010\n",
      "5\n",
      ">>> Creating small dataset with 250,000 reads\n",
      ">>> Running original model in inference on small dataset\n",
      "7813/7813 [==============================] - 159s 20ms/step\n",
      "False Positives\n",
      "CoV:  Total: 2,703, Ratio 0.011\n",
      "MERS: Total: 2,619, Ratio 0.010\n",
      "6\n",
      ">>> Creating small dataset with 250,000 reads\n",
      ">>> Running original model in inference on small dataset\n",
      "7813/7813 [==============================] - 159s 20ms/step\n",
      "False Positives\n",
      "CoV:  Total: 2,708, Ratio 0.011\n",
      "MERS: Total: 2,481, Ratio 0.010\n",
      "7\n",
      ">>> Creating small dataset with 250,000 reads\n",
      ">>> Running original model in inference on small dataset\n",
      "7813/7813 [==============================] - 159s 20ms/step\n",
      "False Positives\n",
      "CoV:  Total: 2,672, Ratio 0.011\n",
      "MERS: Total: 2,602, Ratio 0.010\n",
      "8\n",
      ">>> Creating small dataset with 250,000 reads\n",
      ">>> Running original model in inference on small dataset\n",
      "7813/7813 [==============================] - 159s 20ms/step\n",
      "False Positives\n",
      "CoV:  Total: 2,727, Ratio 0.011\n",
      "MERS: Total: 2,619, Ratio 0.010\n",
      "9\n",
      ">>> Creating small dataset with 250,000 reads\n",
      ">>> Running original model in inference on small dataset\n",
      "7813/7813 [==============================] - 160s 20ms/step\n",
      "False Positives\n",
      "CoV:  Total: 2,779, Ratio 0.011\n",
      "MERS: Total: 2,520, Ratio 0.010\n"
     ]
    }
   ],
   "source": [
    "nreads = 250_000\n",
    "bs = 32\n",
    "nbatches = 10\n",
    "print(f\"Inference will require {nreads//bs:,d} batches, i.e. about {int(20/1000 * nreads//bs):,d} sec per iteration\")\n",
    "\n",
    "p2ds = p2simreads / 'mRhiFer1_v1.p.dna_rm.primary_assembly.1_ds'\n",
    "assert p2ds.is_file()\n",
    "\n",
    "def run_model_per_chunck():\n",
    "    # make smaller dataset:\n",
    "    p2saved = p2data / 'saved/cnn_virus_original/pretrained_model.h5'\n",
    "    model = load_model(p2saved)\n",
    "    it = TextFileBaseIterator(p2ds, nlines=nreads)\n",
    "\n",
    "    sars_fp_all = []\n",
    "    mers_fp_all = []\n",
    "    nsamples_all = []\n",
    "    for i, chunck in enumerate(it):\n",
    "        print(i)\n",
    "        print(f\">>> Creating small dataset with {nreads:,d} reads\")\n",
    "        p2ds_small = p2simreads / f\"{p2ds.stem}-small.{p2ds.suffix}\"\n",
    "        if p2ds_small.is_file(): p2ds_small.unlink()\n",
    "        with open(p2ds_small, 'w') as fp:\n",
    "            fp.write(next(it))\n",
    "\n",
    "        print(f\">>> Running original model in inference on small dataset\")\n",
    "        text_ds = TextLineDataset(p2ds_small).batch(bs)\n",
    "        ds = text_ds.map(strings_to_tensors)\n",
    "        \n",
    "        prob_preds = model.predict(ds, verbose=1)\n",
    "        preds_label = np.argmax(prob_preds[0], axis=1)\n",
    "        preds_pos = np.argmax(prob_preds[1], axis=1)\n",
    "        sars_fp = (preds_label == 117).sum()\n",
    "        mers_fp = (preds_label == 94).sum()\n",
    "        total_samples = preds_label.shape[0]\n",
    "        sars_fp_all.append(sars_fp)\n",
    "        mers_fp_all.append(mers_fp)\n",
    "        nsamples_all.append(total_samples)\n",
    "        print(f\"False Positives\")\n",
    "        print(f\"CoV:  Total: {sars_fp:5,d}, Ratio {sars_fp/total_samples:1.3f}\")\n",
    "        print(f\"MERS: Total: {mers_fp:5,d}, Ratio {mers_fp/total_samples:1.3f}\")\n",
    "        \n",
    "        if i+1 >= nbatches: break\n",
    "            \n",
    "    return sars_fp_all, mers_fp_all, nsamples_all\n",
    "\n",
    "sars_fp_all, mers_fp_all, nsamples_all = run_model_per_chunck()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FP sars: 27,431, FP mers: 25,436, Total Reads: 2,500,000\n"
     ]
    }
   ],
   "source": [
    "print(f\"FP sars: {sum(sars_fp_all):,d}, FP mers: {sum(mers_fp_all):,d}, Total Reads: {sum(nsamples_all):,d}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0109724, 0.0101744)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(sars_fp_all) / sum(nsamples_all), sum(mers_fp_all) / sum(nsamples_all)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Others"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "26b205197a934fdeabb71e65ac11acba": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "514ad0bfcabf4df580a9a872af814af9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "55646397fc9349d3af9e98b1f2b26f5d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "70f6be4247664b708b662c34e7abe3ee": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7179c6cc207941648c348b1bf10cb87f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "LabelModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "LabelModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "LabelView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_70f6be4247664b708b662c34e7abe3ee",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_bdde467d943148ce9bb6355fd7582a5c",
      "value": "0.078 MB of 0.078 MB uploaded (0.020 MB deduped)\r"
     }
    },
    "7849f255e99b4853bdba7f8badf1054a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "VBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "VBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "VBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_7179c6cc207941648c348b1bf10cb87f",
       "IPY_MODEL_e0819a1ddcc64c08a748a2fd88350f09"
      ],
      "layout": "IPY_MODEL_26b205197a934fdeabb71e65ac11acba"
     }
    },
    "bdde467d943148ce9bb6355fd7582a5c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "e0819a1ddcc64c08a748a2fd88350f09": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_55646397fc9349d3af9e98b1f2b26f5d",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_514ad0bfcabf4df580a9a872af814af9",
      "value": 1
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
