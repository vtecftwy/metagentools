[
  {
    "objectID": "data_dev/saved/readme.html",
    "href": "data_dev/saved/readme.html",
    "title": "metagentools",
    "section": "",
    "text": "Saved data related to models\nThis directory includes all data related to models and saved: - saved model parameters - saved datasets\nFor example: - cnn_virus_original/pretrained_model.h5 is the saved model parameters for the CNN Virus model - cnn_virus_datasets/*.tfrecords are the preprocessed datasets used for inference or training, saved in TFRecord format for performance"
  },
  {
    "objectID": "data_dev/CNN_Virus_data/readme.html",
    "href": "data_dev/CNN_Virus_data/readme.html",
    "title": "metagentools",
    "section": "",
    "text": "CNN Virus data\nThis directory includes data used to train and validate the initial CNN Virus model, as well as a few smaller datasets for experimenting.\n\nFile list and description:\n\n50-mer\n50-mer reads and their labels, in text format with one line per sample. Each line consists of three components, separated by tabs: the 50-mer read or sequence, the virus species label and the position label:\n'TTACNAGCTCCAGTCTAAGATTGTAACTGGCCTTTTTAAAGATTGCTCTA    94    5\\n'\nFiles: - 50mer_training: dataset with 50,903,296 reads for training - 50mer_validating: dataset with 1,000,000 reads for validation - 50mer_ds_100_reads: small subset of 100 reads from the validating dataset for experiments\n\n\n150-mer\n150-mer reads and their labels in text format in a similar format as above:\n'TTCTTTCACCACCACAACCAGTCGGCCGTGGAGAGGCGTCGCCGCGTCTCGTTCGTCGAGGCCGATCGACTGCCGCATGAGAGCGGGTGGTATTCTTCCGAAGACGACGGAGACCGGGACGGTGATGAGGAAACTGGAGAGAGCCACAAC    6    0\\n'\nFiles: - ICTV_150mer_benchmarking: dataset with 10,0000 read - 150mer_ds_100_reads: small subset of 100 reads from ICTV_150mer_benchmarking\n\n\nLonger reads\nReads of various length with no labels, in simple fasta format. Each read sequence is preceded by a definition line: &gt; Sequence n, where n is the sequence number.\nFiles: - training_sequences_300bp.fasta: dataset with 9,000 300-mer reads - training_sequences_500bp.fasta: dataset with 9,000 500-mer reads - validation_sequences.fasta: dataset with 564 reads of mixed lengths ranging from 163-mer to 497-mer\n\n\nOther files:\n\nvirus_name_mapping: mapping between virus species and their numerical label\nweight_of_classes: weights for each virus species class in the training dataset"
  },
  {
    "objectID": "data_dev/ncbi/readme.html",
    "href": "data_dev/ncbi/readme.html",
    "title": "metagentools",
    "section": "",
    "text": "NCBI Data\nThis directory includes all data related to the work done with reference sequences from NCBI.\nThe data is organized in the following subfolders:\n\nrefsequences: reference CoV sequences downloaded from NCBI, and related metadata\nsimreads: all data from simulated reads, using ART Illumina simulator and the reference sequences\ninfer_results: results from the inference using models with the simulated reads\nds: datasets in proper format for training or inference/prediction using the CNN Virus model"
  },
  {
    "objectID": "wandb.html",
    "href": "wandb.html",
    "title": "wandb",
    "section": "",
    "text": "Once setup, WandB tracks datasets, models, training runs, evaluation runs across several experiments. The original documentation is here.\nKey concepts we use in this package:",
    "crumbs": [
      "General Code",
      "wandb"
    ]
  },
  {
    "objectID": "wandb.html#steps",
    "href": "wandb.html#steps",
    "title": "wandb",
    "section": "Steps:",
    "text": "Steps:\n\nLogin to wandb:\n\nMay require an API key, which is available at https://wandb.ai/authorize. To access the API key, must be logged in onto WandB.\n\nInitialize a Run with desired parameters and metadata\nPerform operations to be tracked (e.g. train model, load dataset as artifact, …)\nFinish the Run\n\n\nsource\n\nlogin_nb\n\n login_nb (nb_file:str|pathlib.Path=None)\n\nFirst step to setup WandB from notebook. Logs in and logs passed notebook as source of code\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nnb_file\nstr | pathlib.Path\nNone\nname of the notebook (str) or path to the notebook (Path)\n\n\n\nTo allow WandB to store the code used for the session, the name or path of the notebook must be passed as argument nb_file.\nExample:\n\nlogin_nb('01_wandb')\n\nLogging in from notebook: /home/vtec/projects/bio/metagentools/nbs-dev/01_wandb.ipynb\n\n\nwandb: W&B API key is configured. Use `wandb login --relogin` to force relogin\n\n\nlogin_nb raises error in the following cases:\n\nIf nb_file is not passed, the function raises a TypeError\nIf nb_file is not a string or a Path, the function raises a TypeError\nThere must exist a file nb_file or a ValueError is raised\n\n\nsource\n\n\nWandbRun\n\n WandbRun (entity:str='', project:str='', run_name:str='',\n           job_type:str='', notes:str='', logs_dir:str|pathlib.Path=None,\n           testing:bool=False)\n\nManages a WandB run and all logged actions performed while run is active. Close run with .finish()\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nentity\nstr\n\nuser or organization under which the run will be logged. Default: metagenomics_sh\n\n\nproject\nstr\n\nname of the WandB project under which the run will be logged\n\n\nrun_name\nstr\n\nunique name for the run,\n\n\njob_type\nstr\n\ne.g.: load_datasets, train_exp, …\n\n\nnotes\nstr\n\nany text description or additional information to store with the run\n\n\nlogs_dir\nstr | pathlib.Path\nNone\ndefault is project_root/wandb-logs if None, or uses the passed Path\n\n\ntesting\nbool\nFalse\n(optional) If True, will not create a run on WandB. Use for local testing\n\n\nReturns\nRun\n\n\n\n\n\n\nCreate a Run instance\nWandbRun allows to define a set of metadata associated with the run, such as entity, project, name, job_type and additional notes.\nExample:\n\nset the parameters\n\n\nentity = 'metagenomics_sh'\nproject = 'reproduce_cnn_virus'\nrun_name = 'nbdev-test'\njob_type = \"code_testing\"\nnotes = 'any other information of interest for the future'\n\n\ncreate a WandbRun instance called wandb_run\n\n\nwandb_run = WandbRun(\n    entity=entity, \n    project=project, \n    run_name=run_name, \n    job_type=job_type, \n    notes=notes\n    )\n\n\n\n\nTracking run with wandb version 0.13.9\n\n\nRun data is saved locally in /home/vtec/projects/bio/metagentools/wandb-logs/wandb/run-20240809_145852-xjuxt5vv\n\n\nSyncing run nbdev-test to Weights & Biases (docs)\n\n\n View project at https://wandb.ai/metagenomics_sh/reproduce_cnn_virus\n\n\n View run at https://wandb.ai/metagenomics_sh/reproduce_cnn_virus/runs/xjuxt5vv\n\n\nWandbRun instantiation raises an error in the following cases:\n\nIf one of entity, project, run_name or job_type is not passed, the function raises a ValueError\nIf one of entity, project, run_name, job_type or notes is not a string, the function raises a TypeError\n\n\nsource\n\n\n\nWandbRun.upload_dataset\n\n WandbRun.upload_dataset (ds_path:str, ds_name:str, ds_type:str,\n                          ds_descr:str, ds_metadata:dict,\n                          load_type:str='file',\n                          wait_completion:bool=False)\n\nLoad a dataset from a file as WandB artifact, with associated information and metadata\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nds_path\nstr\n\npath to the file or directory to load as dataset artifact\n\n\nds_name\nstr\n\nname for the dataset\n\n\nds_type\nstr\n\ntype of dataset: e.g. raw_data, processed_data, …\n\n\nds_descr\nstr\n\nshort description of the dataset\n\n\nds_metadata\ndict\n\nkeys/values for metadata on the dataset, eg. nb_samples, …\n\n\nload_type\nstr\nfile\nfile to load a single file, dir to load all files in a directory\n\n\nwait_completion\nbool\nFalse\nwhen True, wait completion of the logging before returning artifact\n\n\n\n\nLoad a dataset from a single file\n\nds_fname = str(Path('data_dev/cov_virus_sequence_one.fa').absolute())\nds_name = 'cov_one_sequence'\nds_type = 'cov_sequences'\nds_descr = 'one cov sequence fasta file'\n\nds_metadata = {\n    'nb_sequences': 1,\n    'file type': 'fasta',\n}\n\n\natx_one_file = wandb_run.upload_dataset(\n    ds_path=ds_fname,\n    ds_name=ds_name,\n    ds_type=ds_type,\n    ds_descr=ds_descr,\n    ds_metadata=ds_metadata,\n    load_type='file',\n)\n\nDataset cov_one_sequence is being logged as artifact ...\n\n\n\n\nLoad a dataset with several files from a directory.\n\nds_dirname = str(Path('data_dev/single_1seq_150bp').absolute())\nds_name = 'cov_reads_single_1_sequence_150bp'\nds_type = 'sim_reads'\nds_descr = 'Simulated single reads of one cov sequence'\n\nds_metadata = {\n    'nb_sequences': 1,\n    'sim_type': 'single',\n    'read_length': 150,\n    'fold': 100,\n}\n\n\natx_multi_files = wandb_run.upload_dataset(\n    ds_path=ds_dirname,\n    ds_name=ds_name,\n    ds_type=ds_type,\n    ds_descr=ds_descr,\n    ds_metadata=ds_metadata,\n    load_type='dir',\n)\n\nwandb: Adding directory to artifact (/home/vtec/projects/bio/metagentools/nbs-dev/data_dev/single_1seq_150bp)... Done. 0.0s\n\n\nDataset cov_reads_single_1_sequence_150bp is being logged as artifact ...\n\n\nWandbRun.upload_dataset raises an error in the following cases:\n\nds_path is a file and load_type is dir\nds_path is a directory and load_type is ’file`\nload_type has another value then file or dir\n\n\n\n\nClose a WandB run\n\nwandb_run.finish()\n\nWaiting for W&B process to finish... (success).\n\n\n View run nbdev-test at: https://wandb.ai/metagenomics_sh/reproduce_cnn_virus/runs/xjuxt5vvSynced 7 W&B file(s), 0 media file(s), 6 artifact file(s) and 1 other file(s)\n\n\nFind logs at: /home/vtec/projects/bio/metagentools/wandb-logs/wandb/run-20240809_145852-xjuxt5vv/logs\n\n\n\nsource\n\n\nentity_projects\n\n entity_projects (entity:str)\n\nReturns all projects under ‘entity’, as an iterable collection\n\n\n\n\n\n\n\n\n\nType\nDetails\n\n\n\n\nentity\nstr\nname of the entity from which the projects will be retrieved\n\n\nReturns\nProjects\nProjects iterator\n\n\n\nentity_projects inquires WandB to retrieve all the projects, and returns them as an iterable object.\nEach element in the iterator is a wandb.Project object. Each Project object has the following attributes:\n\n_attrs: dict of attributes associated with the project (id, name, entityName, createdAt). These attributes can be called directly as object.id, …\nentity\nname: project name\npath: as a list [entity, name]\nurl: the url to the project workspace (‘https://wandb.ai/entity/project/workspace’)\n\n\nprojs = entity_projects(entity='vtecftyw')\n\nfor p in projs:\n    print(f\"{p.name}:\")\n    print('  name:   ', p.name)\n    print('  entity  ', p.entity)\n    print('  path:   ', p.path)\n    print()\n    print('  url:    ', p.url)\n    print('  id:     ', p.id)\n    print('  created:', p.createdAt)\n    print('  _attrs: ', p._attrs)\n    print()\n\nhuggingface:\n  name:    huggingface\n  entity   vtecftyw\n  path:    ['vtecftyw', 'huggingface']\n\n  url:     https://wandb.ai/vtecftyw/huggingface/workspace\n  id:      UHJvamVjdDp2MTpodWdnaW5nZmFjZTp2dGVjZnR5dw==\n  created: 2023-06-21T07:34:22\n  _attrs:  {'id': 'UHJvamVjdDp2MTpodWdnaW5nZmFjZTp2dGVjZnR5dw==', 'name': 'huggingface', 'entityName': 'vtecftyw', 'createdAt': '2023-06-21T07:34:22', 'isBenchmark': False}\n\ntut_artifacts:\n  name:    tut_artifacts\n  entity   vtecftyw\n  path:    ['vtecftyw', 'tut_artifacts']\n\n  url:     https://wandb.ai/vtecftyw/tut_artifacts/workspace\n  id:      UHJvamVjdDp2MTp0dXRfYXJ0aWZhY3RzOnZ0ZWNmdHl3\n  created: 2022-09-30T04:39:35\n  _attrs:  {'id': 'UHJvamVjdDp2MTp0dXRfYXJ0aWZhY3RzOnZ0ZWNmdHl3', 'name': 'tut_artifacts', 'entityName': 'vtecftyw', 'createdAt': '2022-09-30T04:39:35', 'isBenchmark': False}\n\nmetagenomics:\n  name:    metagenomics\n  entity   vtecftyw\n  path:    ['vtecftyw', 'metagenomics']\n\n  url:     https://wandb.ai/vtecftyw/metagenomics/workspace\n  id:      UHJvamVjdDp2MTptZXRhZ2Vub21pY3M6dnRlY2Z0eXc=\n  created: 2022-09-09T10:39:00\n  _attrs:  {'id': 'UHJvamVjdDp2MTptZXRhZ2Vub21pY3M6dnRlY2Z0eXc=', 'name': 'metagenomics', 'entityName': 'vtecftyw', 'createdAt': '2022-09-09T10:39:00', 'isBenchmark': False}\n\nwand-hello-world-fastai:\n  name:    wand-hello-world-fastai\n  entity   vtecftyw\n  path:    ['vtecftyw', 'wand-hello-world-fastai']\n\n  url:     https://wandb.ai/vtecftyw/wand-hello-world-fastai/workspace\n  id:      UHJvamVjdDp2MTp3YW5kLWhlbGxvLXdvcmxkLWZhc3RhaTp2dGVjZnR5dw==\n  created: 2022-06-14T15:45:17\n  _attrs:  {'id': 'UHJvamVjdDp2MTp3YW5kLWhlbGxvLXdvcmxkLWZhc3RhaTp2dGVjZnR5dw==', 'name': 'wand-hello-world-fastai', 'entityName': 'vtecftyw', 'createdAt': '2022-06-14T15:45:17', 'isBenchmark': False}\n\n\n\n\nsource\n\n\nget_project\n\n get_project (entity:str, project_name:str)\n\nReturns project object defined by entity and project name\n\n\n\n\n\n\n\n\n\nType\nDetails\n\n\n\n\nentity\nstr\nname of the entity from which the project will be retrieved\n\n\nproject_name\nstr\nname of the project to retrieve\n\n\nReturns\nProject\nProject object\n\n\n\n\np = get_project('vtecftyw', 'tut_artifacts')\n\nprint(type(p))\n\nprint(p.entity,'\\n', p.name,'\\n', p.path,'\\n', p.url)\n\n&lt;class 'wandb.apis.public.Project'&gt;\nvtecftyw \n tut_artifacts \n ['vtecftyw', 'tut_artifacts'] \n https://wandb.ai/vtecftyw/tut_artifacts/workspace\n\n\n\nsource\n\n\nprint_entity_project_list\n\n print_entity_project_list (entity)\n\nPrint the name and url of all projects in entity\n\nprint_entity_project_list('vtecftyw')\n\nList of projects under entity &lt;vtecftyw&gt;\n  0. huggingface                    (url: https://wandb.ai/vtecftyw/huggingface/workspace)\n  1. tut_artifacts                  (url: https://wandb.ai/vtecftyw/tut_artifacts/workspace)\n  2. metagenomics                   (url: https://wandb.ai/vtecftyw/metagenomics/workspace)\n  3. wand-hello-world-fastai        (url: https://wandb.ai/vtecftyw/wand-hello-world-fastai/workspace)\n\n\n\nsource\n\n\nproject_artifacts\n\n project_artifacts (entity:str, project_name:str, by_alias:str='latest',\n                    by_type:str=None, by_version:str=None)\n\nReturns all artifacts in project, w/ key info, filtered by alias, types and version + list of artifact types\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nentity\nstr\n\nname of the entity from which to retrieve the artifacts\n\n\nproject_name\nstr\n\nname of the project from which to retrieve the artifacts\n\n\nby_alias\nstr\nlatest\nname of the alias to filter by\n\n\nby_type\nstr\nNone\nname of the artifact type to filter by (optional)\n\n\nby_version\nstr\nNone\nversion to filter by (optional)\n\n\nReturns\nTuple\n\ndf w/ all artifacts and related info; list of artifact types in the project\n\n\n\nproject_artifacts returns:\n\na DataFrame including all the artifacts available under the project (entity/project_name)\na list of all artifact types in the projects\n\n\natx_df, atx_type_list = project_artifacts(\n    entity='metagenomics_sh', \n    project_name='reproduce_cnn_virus'\n    )\n\natx_type_list\n\n['raw_data', 'code', 'model', 'wandb-history', 'sim_reads', 'cov_sequences']\n\n\n\natx_df\n\n\n\n\n\n\n\n\natx_name\natx_version\natx_type\natx_aliases\nfile_count\ncreated\nupdated\natx_id\n\n\n\n\n0\norigin_validation_20k:v0\nv0\nraw_data\nlatest\n1\n2022-09-19T16:14:44\n2022-09-20T07:30:20\nQXJ0aWZhY3Q6MTk2NjM3ODEx\n\n\n1\norigin_validation_200k:v0\nv0\nraw_data\nlatest\n1\n2022-09-19T16:14:46\n2022-09-20T07:30:20\nQXJ0aWZhY3Q6MTk2NjM3ODMx\n\n\n2\norigin_validation_1M:v0\nv0\nraw_data\nlatest\n1\n2022-09-19T16:14:48\n2022-09-20T07:30:20\nQXJ0aWZhY3Q6MTk2NjM3ODUz\n\n\n3\norigin_training_100k:v0\nv0\nraw_data\nlatest\n1\n2022-09-19T16:15:10\n2022-09-19T16:15:12\nQXJ0aWZhY3Q6MTk2NjM4MDc5\n\n\n4\norigin_training_1M:v0\nv0\nraw_data\nlatest\n1\n2022-09-19T16:15:12\n2022-09-19T16:15:14\nQXJ0aWZhY3Q6MTk2NjM4MDkx\n\n\n5\norigin_training_15M:v0\nv0\nraw_data\nlatest\n1\n2022-09-19T16:15:20\n2022-09-19T16:15:33\nQXJ0aWZhY3Q6MTk2NjM4MTY0\n\n\n6\norigin_training_30M:v0\nv0\nraw_data\nlatest\n1\n2022-09-19T16:15:38\n2022-09-19T16:16:06\nQXJ0aWZhY3Q6MTk2NjM4Mjk2\n\n\n7\norigin_training_50M:v0\nv0\nraw_data\nlatest\n1\n2022-09-19T16:16:10\n2022-09-20T07:30:18\nQXJ0aWZhY3Q6MTk2NjM4NjEw\n\n\n8\nmodel-train_1M-221002-1625:v3\nv3\nmodel\nlatest\n4\n2022-10-02T16:52:58\n2022-10-02T16:53:02\nQXJ0aWZhY3Q6MjExMjY1NzEw\n\n\n9\nmodel-train_15M-221003-0251:v5\nv5\nmodel\nlatest\n4\n2022-10-03T11:25:30\n2022-10-03T11:25:34\nQXJ0aWZhY3Q6MjExODYzNDY5\n\n\n10\nmodel-retrain_15M-221004-1003:v4\nv4\nmodel\nlatest\n4\n2022-10-04T17:07:46\n2022-10-04T17:07:51\nQXJ0aWZhY3Q6MjEyNzA1MDc1\n\n\n11\nmodel-retrain_15M-221005-0600:v4\nv4\nmodel\nlatest\n4\n2022-10-05T12:58:34\n2022-10-05T12:58:39\nQXJ0aWZhY3Q6MjEzNzU2MTY2\n\n\n12\nrun-r6qj2dy2-history:v0\nv0\nwandb-history\nlatest\n1\n2023-01-17T05:59:04\n2023-01-17T05:59:04\nQXJ0aWZhY3Q6MzI5MDAwNzAx\n\n\n13\nrun-3llf3b5y-history:v0\nv0\nwandb-history\nlatest\n1\n2023-01-17T05:59:04\n2023-01-17T05:59:04\nQXJ0aWZhY3Q6MzI5MDAwNzAw\n\n\n14\nrun-12okrxy6-history:v0\nv0\nwandb-history\nlatest\n1\n2023-01-17T05:59:04\n2023-01-17T05:59:04\nQXJ0aWZhY3Q6MzI5MDAwNzAy\n\n\n15\nrun-kwvtsumh-history:v0\nv0\nwandb-history\nlatest\n1\n2024-07-14T15:53:12\n2024-07-14T15:53:12\nQXJ0aWZhY3Q6OTcyNTc2ODY3\n\n\n16\ncov_one_sequence:v0\nv0\ncov_sequences\nlatest\n1\n2024-08-09T07:01:23\n2024-08-09T07:01:56\nQXJ0aWZhY3Q6MTEyMzY3NjU5Mg==\n\n\n17\ncov_reads_single_1_sequence_150bp:v0\nv0\nsim_reads\nlatest\n2\n2024-08-09T07:02:27\n2024-08-09T07:03:04\nQXJ0aWZhY3Q6MTEyMzY4MTU0Mg==\n\n\n18\nsource-reproduce_cnn_virus-None:v151\nv151\ncode\nlatest\n2\n2024-08-09T07:03:48\n2024-08-09T07:04:15\nQXJ0aWZhY3Q6MTEyMzY4NzgyMw==\n\n\n\n\n\n\n\nThe list of artifacts can be filtered, for instance, by artifact type\n\natx_df, atx_type_list = project_artifacts(\n    entity='metagenomics_sh', \n    project_name='reproduce_cnn_virus',\n    by_type='model'\n    )\n\natx_df\n\n\n\n\n\n\n\n\natx_name\natx_version\natx_type\natx_aliases\nfile_count\ncreated\nupdated\natx_id\n\n\n\n\n0\nmodel-train_1M-221002-1625:v3\nv3\nmodel\nlatest\n4\n2022-10-02T16:52:58\n2022-10-02T16:53:02\nQXJ0aWZhY3Q6MjExMjY1NzEw\n\n\n1\nmodel-train_15M-221003-0251:v5\nv5\nmodel\nlatest\n4\n2022-10-03T11:25:30\n2022-10-03T11:25:34\nQXJ0aWZhY3Q6MjExODYzNDY5\n\n\n2\nmodel-retrain_15M-221004-1003:v4\nv4\nmodel\nlatest\n4\n2022-10-04T17:07:46\n2022-10-04T17:07:51\nQXJ0aWZhY3Q6MjEyNzA1MDc1\n\n\n3\nmodel-retrain_15M-221005-0600:v4\nv4\nmodel\nlatest\n4\n2022-10-05T12:58:34\n2022-10-05T12:58:39\nQXJ0aWZhY3Q6MjEzNzU2MTY2\n\n\n\n\n\n\n\n\nsource\n\n\nrun_name_exists\n\n run_name_exists (run_name:str, entity:str, project_name:str)\n\nCheck whether a run with name run_name already exists in entity/project_name\n\n\n\n\n\n\n\n\n\nType\nDetails\n\n\n\n\nrun_name\nstr\nname of the run to check\n\n\nentity\nstr\nname of the entity from which to retrieve the artifacts\n\n\nproject_name\nstr\nname of the project from which to retrieve the artifacts\n\n\nReturns\nbool\nTrue if a run exists with the name run_name, False otherwise\n\n\n\n\nrun_name_exists(\n    run_name='train_1M-221002-1625', \n    entity='metagenomics_sh', \n    project_name='reproduce_cnn_virus'\n    )\n\nTrue\n\n\n\nrun_name_exists(\n    run_name='train_1M', \n    entity='metagenomics_sh', \n    project_name='reproduce_cnn_virus'\n    )\n\nFalse\n\n\n\nsource\n\n\nunique_run_name\n\n unique_run_name (name_seed:str)\n\nCreate a unique run name by adding a timestamp to the passed seed\n\n\n\n\nType\nDetails\n\n\n\n\nname_seed\nstr\nRun name to which a timestamp will be added\n\n\n\n\nunique_run_name('this_is_a_run_name')\n\n'this_is_a_run_name-240810-1522'",
    "crumbs": [
      "General Code",
      "wandb"
    ]
  },
  {
    "objectID": "wandb.html#technical-notes-for-development-with-nbdev",
    "href": "wandb.html#technical-notes-for-development-with-nbdev",
    "title": "wandb",
    "section": "Technical Notes for development with nbdev",
    "text": "Technical Notes for development with nbdev\nResolve problem with nbdev_export() for this notebook\nWhen using nbdev.nbdev_export() in this notebook, the code exported seems to be old code. In particular, the dependency import section in cell is exported as:\n# %% ../nbs-dev/wandb/run-20221123_121523-2z5ycjrb/tmp/code/01_wandb.ipynb 2\n# Imports all dependencies\n\nimport configparser\nimport numpy as np\nimport psutil\nimport os\nThe hint is in the first line:\n# %% ../nbs-dev/wandb/run-20221123_121523-2z5ycjrb/tmp/code/01_wandb.ipynb 2\nIt shows that the notebook used for exporting is not /nbs-dev/01_wandb.ipynb as it should be. This is because the WandB package creates a local directory /nbs-dev/wandb/ where it keeps local logs and artifacts.\nThe solution is to move the directory where WandB stores local logs outside nbs-dev, which can be done with the dir argument in wandb.Run()\nIllustrating by reproducing the functions from nbdev and a few dependencies\n\nfrom nbdev.config import get_config\nfrom fastcore.xtras import globtastic\nfrom fastcore.meta import delegates\n\n\n# from nbdev.doclinks.py\n\n# line 105\n@delegates(globtastic)\ndef nbglob(path=None, skip_folder_re = '^[_.]', file_glob='*.ipynb', skip_file_re='^[_.]', key='nbs_path', as_path=False, **kwargs):\n    \"Find all files in a directory matching an extension given a config key.\"\n    path = Path(path or get_config()[key])\n    recursive=get_config().recursive\n    res = globtastic(path, file_glob=file_glob, skip_folder_re=skip_folder_re,\n                     skip_file_re=skip_file_re, recursive=recursive, **kwargs)\n    return res.map(Path) if as_path else res\n\n\n# line 131 MODIFIED\ndef modified_nbdev_export(\n    path:str=None, # Path or filename\n    **kwargs):\n    \"Export notebooks in `path` to Python modules\"\n    if os.environ.get('IN_TEST',0): return\n    files = nbglob(path=path, as_path=True, **kwargs).sorted('name')\n#     for f in files: nb_export(f)\n    for f in files: print(f)\n#     add_init(get_config().lib_path)\n#     _build_modidx()\n\nBefore the change:\nmodified_nbdev_export()\n/home/vtec/projects/bio/metagentools/nbs-dev/00_core.ipynb\n/home/vtec/projects/bio/metagentools/nbs-dev/01_wandb.ipynb\n/home/vtec/projects/bio/metagentools/nbs-dev/wandb/run-20221122_182641-1eafsab9/tmp/code/01_wandb.ipynb\n/home/vtec/projects/bio/metagentools/nbs-dev/wandb/run-20221122_180513-1vgzoryt/tmp/code/01_wandb.ipynb\n/home/vtec/projects/bio/metagentools/nbs-dev/wandb/run-20221123_121523-2z5ycjrb/tmp/code/01_wandb.ipynb\n/home/vtec/projects/bio/metagentools/nbs-dev/index.ipynb\nAfter the change\n\nmodified_nbdev_export()\n\n/home/vtec/projects/bio/metagentools/nbs-dev/00_core.ipynb\n/home/vtec/projects/bio/metagentools/nbs-dev/01_wandb.ipynb\n/home/vtec/projects/bio/metagentools/nbs-dev/02_art.ipynb\n/home/vtec/projects/bio/metagentools/nbs-dev/03_bio.ipynb\n/home/vtec/projects/bio/metagentools/nbs-dev/03_cnn_virus_architecture.ipynb\n/home/vtec/projects/bio/metagentools/nbs-dev/03_cnn_virus_data.ipynb\n/home/vtec/projects/bio/metagentools/nbs-dev/03_cnn_virus_utils.ipynb\n/home/vtec/projects/bio/metagentools/nbs-dev/index.ipynb",
    "crumbs": [
      "General Code",
      "wandb"
    ]
  },
  {
    "objectID": "cnn_virus_utils.html",
    "href": "cnn_virus_utils.html",
    "title": "utils",
    "section": "",
    "text": "source\n\nsetup_nb\n\n setup_nb (_dev=False)\n\nSets up colab or local environment and corresponding paths to data root directory and cnn virus data\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\n_dev\nbool\nFalse\n\n\n\nReturns\ntuple\n\n(colab, path to data root, path to data)\n\n\n\n\nON_COLAB, p2dataroot, p2data = setup_nb(_dev=True)\nprint('Notebook running on Colab?', ON_COLAB)\nprint(\"Path to data root:        \", p2dataroot.absolute())\nprint(\"Path to cnn virus data    \", p2data.absolute())\n\nRunning locally\nNotebook running on Colab? False\nPath to data root:         /home/vtec/projects/bio/metagentools/nbs-dev/data_dev\nPath to cnn virus data     /home/vtec/projects/bio/metagentools/nbs-dev/data_dev\n\n\n\nassert not ON_COLAB, 'ON_COLAB should be on False'\nassert p2dataroot.name == 'data_dev', f\"Should be 'data_dev` and not {p2dataroot.name}\"\nassert p2data.name == 'data_dev', f\"Should be 'data_dev` and not {p2data.name}\"\n\n\nsource\n\n\nupdate_dev_cfg_file\n\n update_dev_cfg_file ()\n\nUpdate the metagentools configuration file used for development, to point to the correct package root and data directory\n\nupdate_dev_cfg_file()",
    "crumbs": [
      "CNN Virus",
      "utils"
    ]
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "metagentools",
    "section": "",
    "text": "This repo includes the code developed as part of a research project aiming at using deep learning techniques to classify a wide range of viruses based on NG reads.\nThe code is structured into general code and submodules:\nGeneral code is used across the project and can also be reused for other projects:\n\nart: wrapper code to use ART-ILLUMINA read simulator package from a jupyter notebook. MUST BE RUN LOCALLY.\ncore: base classes used accross the package\nwandb: utility classes to open, retrieve, use WandB runs and artifacts accross the project\n\nSubmodules cover code written for a specific part of the project. At the moment, the only submodule is cnn_virus.\n\ncnn_virus: all specific code related to the evaluation and improvement of CNN Virus model\n\narchitecture: all code related to evaluated and trained architectures\ndata: data processing, iterators and parsing functions to handle data\nutils: other utility functions\n\n\nDisclaimer: This repository is currently under development and is offered as-is. Please note that certain functions or modules might raise errors or become deprecated without prior notice across different versions. Efforts will be made to clearly indicate in warnings or error messages how to substitute deprecated code. Support may or may not be available, depending on when the request for assistance is made.\nInstallation:\n\npip install metagentools for the stable version\npip install git+https://github.com/vtecftwy/metagentools.git@main for the latest committed version\n\nRequirements:\n\npython 3.8 or higher is required for this package\npackage tested with python 3.10",
    "crumbs": [
      "metagentools"
    ]
  },
  {
    "objectID": "cnn_virus_architecture.html",
    "href": "cnn_virus_architecture.html",
    "title": "architecture",
    "section": "",
    "text": "The paper “A multi-task CNN learning model for taxonomic assignment of human viruses” proposes a CNN model applied to virus.\nThe module architecture includes:",
    "crumbs": [
      "CNN Virus",
      "architecture"
    ]
  },
  {
    "objectID": "cnn_virus_architecture.html#original-architecture",
    "href": "cnn_virus_architecture.html#original-architecture",
    "title": "architecture",
    "section": "Original Architecture",
    "text": "Original Architecture\nBelow are the functions to create model with the same architecture as the original paper.\n\nsource\n\ncreate_model_original\n\n create_model_original (load_parameters:bool=True,\n                        path2parameters:pathlib.Path=None)\n\nBuild a CNN model as per CNN Virus paper\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nload_parameters\nbool\nTrue\nLoad pretrained weights when True\n\n\npath2parameters\nPath\nNone\nPath to pretrained weights, defaults to project CNN Virus weights\n\n\nReturns\ntf.keras.Model\n\nNew instance of an original paper architecture\n\n\n\nThis is the original paper’s model, taking 50-mer sequences and predicting:\n\nthe logits for 187 viruses\nthe logits for one of 10 regions in the original virus genome\n\n\nmodel = create_model_original(load_parameters=False)\n\nCreating CNN Model (Original)\nCreated randomly initialized model\n\n\n\nmodel.summary()\n\nModel: \"CNN_Virus\"\n__________________________________________________________________________________________________\n Layer (type)                   Output Shape         Param #     Connected to                     \n==================================================================================================\n input-seq (InputLayer)         [(None, 50, 5)]      0           []                               \n                                                                                                  \n conv-1 (Conv1D)                (None, 50, 512)      13312       ['input-seq[0][0]']              \n                                                                                                  \n bn-1 (BatchNormalization)      (None, 50, 512)      2048        ['conv-1[0][0]']                 \n                                                                                                  \n maxpool-1 (MaxPooling1D)       (None, 25, 512)      0           ['bn-1[0][0]']                   \n                                                                                                  \n conv-2 (Conv1D)                (None, 25, 512)      1311232     ['maxpool-1[0][0]']              \n                                                                                                  \n bn-2 (BatchNormalization)      (None, 25, 512)      2048        ['conv-2[0][0]']                 \n                                                                                                  \n maxpool-2 (MaxPooling1D)       (None, 13, 512)      0           ['bn-2[0][0]']                   \n                                                                                                  \n conv-3 (Conv1D)                (None, 13, 1024)     3671040     ['maxpool-2[0][0]']              \n                                                                                                  \n conv-4 (Conv1D)                (None, 13, 1024)     7341056     ['conv-3[0][0]']                 \n                                                                                                  \n bn-3 (BatchNormalization)      (None, 13, 1024)     4096        ['conv-4[0][0]']                 \n                                                                                                  \n maxpool-3 (MaxPooling1D)       (None, 7, 1024)      0           ['bn-3[0][0]']                   \n                                                                                                  \n flatten (Flatten)              (None, 7168)         0           ['maxpool-3[0][0]']              \n                                                                                                  \n dense-1 (Dense)                (None, 1024)         7341056     ['flatten[0][0]']                \n                                                                                                  \n bn-4 (BatchNormalization)      (None, 1024)         4096        ['dense-1[0][0]']                \n                                                                                                  \n do-1 (Dropout)                 (None, 1024)         0           ['bn-4[0][0]']                   \n                                                                                                  \n labels (Dense)                 (None, 187)          191675      ['do-1[0][0]']                   \n                                                                                                  \n concat (Concatenate)           (None, 1211)         0           ['do-1[0][0]',                   \n                                                                  'labels[0][0]']                 \n                                                                                                  \n dense-2 (Dense)                (None, 1024)         1241088     ['concat[0][0]']                 \n                                                                                                  \n bn-5 (BatchNormalization)      (None, 1024)         4096        ['dense-2[0][0]']                \n                                                                                                  \n pos (Dense)                    (None, 10)           10250       ['bn-5[0][0]']                   \n                                                                                                  \n==================================================================================================\nTotal params: 21,137,093\nTrainable params: 21,128,901\nNon-trainable params: 8,192\n__________________________________________________________________________________________________\n\n\n\nmodel = create_model_original(load_parameters=True)\n\nCreating CNN Model (Original)\nLoading parameters from pretrained_model.h5\nCreated pretrained model",
    "crumbs": [
      "CNN Virus",
      "architecture"
    ]
  },
  {
    "objectID": "core.html",
    "href": "core.html",
    "title": "core",
    "section": "",
    "text": "This module includes all base classes, functions and other objects that are used across the package. It is imported by all other modules in the package.\ncore includes utility classes and functions to make it easier to work with the complex file systems adopted for the project, as well as base classes such as a file reader with additional functionality.",
    "crumbs": [
      "General Code",
      "core"
    ]
  },
  {
    "objectID": "core.html#handling-files-and-file-structure",
    "href": "core.html#handling-files-and-file-structure",
    "title": "core",
    "section": "Handling files and file structure",
    "text": "Handling files and file structure\nUtility classes to represent\n\nsource\n\nProjectFileSystem\n\n ProjectFileSystem (*args, **kwargs)\n\n*Represent a project file system, return paths to key directories, provide methods to manage the file system.\n\nPaths to key directories are based on whether the code is running locally or in the cloud.\nFirst time it is used on a local computer, it must be registered as local and a project root path must be set.\nA user configuration file is created in the user’s home directory to store the project root path and whether the machine is local or not.\n\n\nTechnical note: ProjectFileSystem is a simpleton class*\n\nReference Project File System:\nThis project adopts a unified file structure to make coding and colaboration easier. In addition, we can run the code locally (from a project-root directory) or in the cloud (colab, kaggle, others).\nThe unified file structure when running localy is:\n    project-root   \n        |--- data\n        |      |--- CNN_Virus_data  (all data from CNN Virus original paper)\n        |      |--- saved           (trained and finetuned models, saved preprocessed datasets)\n        |      |--- ....            (raw or pre-processed data from various sources, results, ... )  \n        |      \n        |--- nbs  (all reference and work notebooks)\n        |      |--- cnn_virus\n        |      |        |--- notebooks.ipynb\nWhen running on google colab, it is assumed that a google drive is mounted on the colab server instance, and that this google drive root includes a shortcut named Metagenomics and pointing to the project shared directory. The project shared directory is accessible here if you are an authorized project member.\nProjectFileSystem at work:\nIf you use this class for the first time on a local computer, read the two Important Notes below.\n\npfs = ProjectFileSystem()\n\nOnce created, the instance of ProjectFileSystem gives access to key directories’ paths:\n\nproject root: Path to the project root directory\ndata: Path to the data directory\nnbs: Path to the notebooks directory\n\nIt also provides additional information regarding the computer on which the code is running:\n\nos: a string providing the name of the operating system the code is running on\nis_colab: True if the code is running on google colab\nis_kaggle: True if the code is running on kaggle server (NOT IMPLEMENTED YET)\nis_local: True if the code is running on a computer registered as local\n\n\nfor p in [pfs.project_root, pfs.data, pfs.nbs]:\n    print(p)\n\n/home/vtec/projects/bio/metagentools\n/home/vtec/projects/bio/metagentools/data\n/home/vtec/projects/bio/metagentools/nbs\n\n\n\nprint(f\"OSL {pfs.os}\")\nprint(f\"Local: {pfs.is_local}, Colab: {pfs.is_colab}, Kaggle: {pfs.is_kaggle}\")\n\nOSL linux\nLocal: True, Colab: False, Kaggle: False\n\n\n\nsource\n\n\nProjectFileSystem.info\n\n ProjectFileSystem.info ()\n\nPrint basic info on the file system and the device\n\npfs.info()\n\nRunning linux on local computer\nDevice's home directory: /home/vtec\nProject file structure:\n - Root ........ /home/vtec/projects/bio/metagentools \n - Data Dir .... /home/vtec/projects/bio/metagentools/data \n - Notebooks ... /home/vtec/projects/bio/metagentools/nbs\n\n\n\nsource\n\n\nProjectFileSystem.readme\n\n ProjectFileSystem.readme (dir_path:pathlib.Path=None)\n\n*Display readme.md file or any other .md file in dir_path.\nThis provides a convenient way to get information on each direcotry content*\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\ndir_path\nPath\nNone\nPath to the directory to inquire. If None, display readme file from project_root.\n\n\n\n\npfs.readme(Path('data_dev'))\n\n\n\n\nReadMe file for directory /home/vtec/projects/bio/metagentools/nbs-dev/data_dev:\n\n\n\n\n\nData directory for metagentools development\nThis directory includes all the data required to test and validate metagentools code.\ndata_dev\n |--- CNN_Virus_data\n |     |--- 50mer_ds_100_seq\n |     |--- 150mer_ds_100_seq\n |     |--- train_short\n |     |--- val_short\n |     |--- weight_of_classes\n |--- ncbi\n |     |--- infer_results\n |     |     |--- cnn_virus\n |     |     |--- csv\n |     |     |--- xlsx\n |     |--- refsequences\n |     |     |--- cov\n |     |     |     |--- another_sequence.fa\n |     |     |     |--- cov_virus_sequences_one.fa\n |     |     |     |--- cov_virus_sequences_two.fa\n |     |     |     |--- sequences_two_no_matching_rule.fa\n |     |--- simreads\n |     |     |--- cov\n |     |     |     |--- paired_1seq_50bp\n |     |     |     |      |--- paired_1seq_50bp_1.aln\n |     |     |     |      |--- paired_1seq_50bp_1.fq\n |     |     |     |--- single_1seq_50bp\n |     |     |     |      |--- single_1seq_50bp_1.aln\n |     |     |     |      |--- single_1seq_50bp_1.fq\n |--- ....           \n |--- readme.md               \n\n\n\n\n\n\nImportant Note 1:\nWhen using the package on a local computer for the first time, you must register the computer as a local computer. Otherwise, ProjectFileSystem will raise an error. Once registered, the configuration file will be updated and ProjectFileSystem will detect that and run without error.\n\n\nsource\n\n\nProjectFileSystem.register_as_local\n\n ProjectFileSystem.register_as_local ()\n\nUpdate the configuration file to register the machine as local machine\n\ncfg = pfs.register_as_local()\n\n\nImportant Note 2:\nWhen using the package on a local computer for the first time, it is also required to set the project root directory. This is necessary to allow users to locate their local project folder anywhere they want. Once set, the path to the project root will be saved in the configuratin file.\n\n\nsource\n\n\nProjectFileSystem.set_project_root\n\n ProjectFileSystem.set_project_root (p2project:str|pathlib.Path,\n                                     data_dir:str='data')\n\nUpdate the configuration file to set the project root\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\np2project\nstr | pathlib.Path\n\nstring or Path to the project directory. Can be absolute or relative to home\n\n\ndata_dir\nstr\ndata\nDirectory name for data under project root\n\n\n\n\npfs.set_project_root('/home/vtec/projects/bio/metagentools/');\n\nProject Root set to:   /home/vtec/projects/bio/metagentools\nData directory set to: /home/vtec/projects/bio/metagentools/data\n\n\n\nsource\n\n\nProjectFileSystem.read_config\n\n ProjectFileSystem.read_config ()\n\nRead config from the configuration file if it exists and return an empty config if does not\n\ncfg = pfs.read_config()\ncfg['Infra']['registered_as_local']\n\n'True'\n\n\n\ncfg['Infra']['project_root']\n\n'/home/vtec/projects/bio/metagentools'\n\n\n\ncfg['Infra']['data_dir']\n\n'data'\n\n\nTechnical Note for Developpers\nThe current notebook and all other development notebooks use a minimum set of data that comes with the repository under nbs-dev/data_dev instead of the standard data directory which is much too large for testing and developing.\nTherefore, when creating the instance of ProjectFileSystem, use the parameter config_file to pass a specific development configuration, also coming with the repository.\n\np2dev_cfg = PACKAGE_ROOT / 'nbs-dev/metagentools-dev.cfg'\npfs = ProjectFileSystem(config_fname=p2dev_cfg)\npfs.info()\n\nRunning linux on local computer\nDevice's home directory: /home/vtec\nProject file structure:\n - Root ........ /home/vtec/projects/bio/metagentools \n - Data Dir .... /home/vtec/projects/bio/metagentools/nbs-dev/data_dev \n - Notebooks ... /home/vtec/projects/bio/metagentools/nbs",
    "crumbs": [
      "General Code",
      "core"
    ]
  },
  {
    "objectID": "core.html#other-utility-classes",
    "href": "core.html#other-utility-classes",
    "title": "core",
    "section": "Other utility classes",
    "text": "Other utility classes\n\nsource\n\nJsonDict\n\n JsonDict (p2json:str|pathlib.Path, dictionary:dict=None)\n\n*Dictionary whose current value is mirrored in a json file and can be initated from a json file\nJsonDict requires a path to json file at creation. An optional dict can be passed as argument.\nBehavior at creation:\n\nJsonDict(p2json, dict) will create a JsonDict with key-values from dict, and mirrored in p2json\nJsonDict(p2json) will create a JsonDict with empty dictionary and load json content if file exists\n\nOnce created, JsonDict instances behave exactly as a dictionary*\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\np2json\nstr | pathlib.Path\n\npath to the json file to mirror with the dictionary\n\n\ndictionary\ndict\nNone\noptional dictionary to initialize the JsonDict\n\n\n\nCreate a new dictionary mirrored to a JSON file:\n\nd = {'a': 1, 'b': 2, 'c': 3}\np2json = pfs.data / 'jsondict-test.json'\njsond = JsonDict(p2json, d)\njsond\n\n{'a': 1, 'b': 2, 'c': 3}\ndict mirrored in /home/vtec/projects/bio/metagentools/nbs-dev/data_dev/jsondict-test.json\n\n\nOnce created, the JsonFile instance behaves exactly like a dictionary, with the added benefit that any change to the dictionary is automatically saved to the JSON file.\n\njsond['a'], jsond['b'], jsond['c']\n\n(1, 2, 3)\n\n\n\nfor k, v in jsond.items():\n    print(f\"key: {k}; value: {v}\")\n\nkey: a; value: 1\nkey: b; value: 2\nkey: c; value: 3\n\n\nAdding or removing a value from the dictionary works in the same way as for a normal dictionary. But the json file is automatically updated.\n\njsond['d'] = 4\njsond\n\n{'a': 1, 'b': 2, 'c': 3, 'd': 4}\ndict mirrored in /home/vtec/projects/bio/metagentools/nbs-dev/data_dev/jsondict-test.json\n\n\n\nwith open(p2json, 'r') as fp:\n    print(fp.read())\n\n{\n    \"a\": 1,\n    \"b\": 2,\n    \"c\": 3,\n    \"d\": 4\n}\n\n\n\ndel jsond['a']\njsond\n\n{'b': 2, 'c': 3, 'd': 4}\ndict mirrored in /home/vtec/projects/bio/metagentools/nbs-dev/data_dev/jsondict-test.json\n\n\n\nwith open(p2json, 'r') as fp:\n    print(fp.read())\n\n{\n    \"b\": 2,\n    \"c\": 3,\n    \"d\": 4\n}\n\n\n\nsource\n\n\nJsonFileReader\n\n JsonFileReader (path:str|pathlib.Path)\n\nMirror a JSON file and a dictionary\n\n\n\n\nType\nDetails\n\n\n\n\npath\nstr | pathlib.Path\npath to the json file\n\n\n\n\njd = JsonFileReader(pfs.data / 'test.json')\npprint(jd.d)\n\n{'item 1': {'keys': 'key key key key', 'pattern': 'pattern 1'},\n 'item 2': {'keys': 'key key key key', 'pattern': 'pattern 2'},\n 'item 3': {'keys': 'key key key key', 'pattern': 'pattern 3'}}\n\n\nNow we can add an item to the dictionary/json\n\nnew_item = {'keys': 'key key key key', 'pattern': 'another pattern'}\njd.add_item(key='another item', item=new_item)\n\n{'item 1': {'keys': 'key key key key', 'pattern': 'pattern 1'},\n 'item 2': {'keys': 'key key key key', 'pattern': 'pattern 2'},\n 'item 3': {'keys': 'key key key key', 'pattern': 'pattern 3'},\n 'another item': {'keys': 'key key key key', 'pattern': 'another pattern'}}\n\n\nAfter saving the updated JSON file, we can load it again and see the changes.\n\njd.save_to_file()\n\n\njd = JsonFileReader(pfs.data / 'test.json')\npprint(jd.d)\n\n{'another item': {'keys': 'key key key key', 'pattern': 'another pattern'},\n 'item 1': {'keys': 'key key key key', 'pattern': 'pattern 1'},\n 'item 2': {'keys': 'key key key key', 'pattern': 'pattern 2'},\n 'item 3': {'keys': 'key key key key', 'pattern': 'pattern 3'}}",
    "crumbs": [
      "General Code",
      "core"
    ]
  },
  {
    "objectID": "core.html#file-readers",
    "href": "core.html#file-readers",
    "title": "core",
    "section": "File Readers",
    "text": "File Readers\nBase classes to be extended in order to create readers for specific file formats.\n\nsource\n\nTextFileBaseReader\n\n TextFileBaseReader (path:str|pathlib.Path, nlines:int=1)\n\n*Iterator going through a text file by chunks of nlines lines. Iterator can be reset to file start.\nThe class is mainly intented to be extended, as it is for handling sequence files of various formats such as FastaFileReader.*\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\npath\nstr | pathlib.Path\n\npath to the file\n\n\nnlines\nint\n1\nnumber of lines on one chunk\n\n\n\nOnce initialized, the iterator runs over each chunk of line(s) in the text file, sequentially.\n\npfs.data\n\nPath('/home/vtec/projects/bio/metagentools/nbs-dev/data_dev')\n\n\n\np2textfile = pfs.data / 'CNN_Virus_data/train_short'\nit = TextFileBaseReader(path=p2textfile, nlines=3)\n\none_iteration = next(it)\n\nprint(one_iteration)\n\nTCAAAATAATCAGAAATGTTGAACCTAGGGTTGGACACATAATGACCAGC  76  0\nATTGTTTAACAATTTGTGCTCGTCCCGGTCACCCGCATCCAATCTTGATG  4   9\nAATCTTGTCCTATCCTACCCGCAGGGGAATTGATGATAGANGTGCTTTTA  181 0\n\n\n\nLet’s create a new instance of the file reader, and get several iterations.\n\nit = TextFileBaseReader(path=p2textfile, nlines=3)\n\none_iteration = next(it)\nprint(one_iteration)\n\nTCAAAATAATCAGAAATGTTGAACCTAGGGTTGGACACATAATGACCAGC  76  0\nATTGTTTAACAATTTGTGCTCGTCCCGGTCACCCGCATCCAATCTTGATG  4   9\nAATCTTGTCCTATCCTACCCGCAGGGGAATTGATGATAGANGTGCTTTTA  181 0\n\n\n\n\nanother_iteration = next(it)\nprint(another_iteration)\none_more_iteration = next(it)\nprint(one_more_iteration)\n\nGGAGCGGAGCCAACCCCTATGCTCACTTGCAACCCAAGGGGCGTTCCAGT  74  3\nTGGATCCTGCGCGGGACGTCCTTTGTCTACGTCCCGTCGGCGCATCCCGC  60  3\nGAGAGACTTACTAAAAAGCTGGCACTTACCATCAGTGTTTCACCTACATG  44  0\n\nACACACGACACTAGAGATAATGTGTCAGTGGATTATAAACAAACCAAGTT  43  7\nTTGTAGCATAAGAACTGGTCTTCGCTGAAATTCTTGTCTTGATCTCATCT  35  2\nTGGCCCTGCGGTCTGGGGCCCAGAAGCATATGTCAAGTCCTTTGAGAAGT  73  4\n\n\n\nIf we want to access the start of the file again, we need to re-initialize the file handle.\n\nsource\n\n\nTextFileBaseReader.reset_iterator\n\n TextFileBaseReader.reset_iterator ()\n\nReset the iterator to point to the first line in the file.\n\nit.reset_iterator()\none_iteration = next(it)\nprint(one_iteration)\nanother_iteration = next(it)\nprint(another_iteration)\n\nTCAAAATAATCAGAAATGTTGAACCTAGGGTTGGACACATAATGACCAGC  76  0\nATTGTTTAACAATTTGTGCTCGTCCCGGTCACCCGCATCCAATCTTGATG  4   9\nAATCTTGTCCTATCCTACCCGCAGGGGAATTGATGATAGANGTGCTTTTA  181 0\n\nGGAGCGGAGCCAACCCCTATGCTCACTTGCAACCCAAGGGGCGTTCCAGT  74  3\nTGGATCCTGCGCGGGACGTCCTTTGTCTACGTCCCGTCGGCGCATCCCGC  60  3\nGAGAGACTTACTAAAAAGCTGGCACTTACCATCAGTGTTTCACCTACATG  44  0\n\n\n\n\nsource\n\n\nTextFileBaseReader.print_first_chunks\n\n TextFileBaseReader.print_first_chunks (nchunks:int=3)\n\n*Print the first nchunk chunks of text from the file.\nAfter printing, the iterator is reset again to its first line.*\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nnchunks\nint\n3\nnumber of chunks to print\n\n\n\n\nit = TextFileBaseReader(path=p2textfile, nlines=3)\n\nit.print_first_chunks(nchunks=3)\n\n3-line chunk 1\nTCAAAATAATCAGAAATGTTGAACCTAGGGTTGGACACATAATGACCAGC  76  0\nATTGTTTAACAATTTGTGCTCGTCCCGGTCACCCGCATCCAATCTTGATG  4   9\nAATCTTGTCCTATCCTACCCGCAGGGGAATTGATGATAGANGTGCTTTTA  181 0\n\n3-line chunk 2\nGGAGCGGAGCCAACCCCTATGCTCACTTGCAACCCAAGGGGCGTTCCAGT  74  3\nTGGATCCTGCGCGGGACGTCCTTTGTCTACGTCCCGTCGGCGCATCCCGC  60  3\nGAGAGACTTACTAAAAAGCTGGCACTTACCATCAGTGTTTCACCTACATG  44  0\n\n3-line chunk 3\nACACACGACACTAGAGATAATGTGTCAGTGGATTATAAACAAACCAAGTT  43  7\nTTGTAGCATAAGAACTGGTCTTCGCTGAAATTCTTGTCTTGATCTCATCT  35  2\nTGGCCCTGCGGTCTGGGGCCCAGAAGCATATGTCAAGTCCTTTGAGAAGT  73  4\n\n\n\n\nsource\n\n\nTextFileBaseReader.parse_text\n\n TextFileBaseReader.parse_text (txt:str, pattern:str=None,\n                                keys:list[str]=None)\n\n*Parse text using regex pattern and keys. Return a metadata dictionary.\nThe passed text is parsed using the regex pattern. The method return a dictionary in the format:\n{\n    'key_1': 'metadata 1',\n    'key_2': 'metadata 2',\n    ...\n}*\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\ntxt\nstr\n\ntext to parse\n\n\npattern\nstr\nNone\nIf None, uses standard regex pattern to extract metadata, otherwise, uses passed regex\n\n\nkeys\nlist\nNone\nIf None, uses standard regex list of keys, otherwise, uses passed list of keys (str)\n\n\nReturns\ndict\n\nparsed metadata in key/value format\n\n\n\n\ntext = '&gt;2591237:ncbi:1'\npattern = r\"^&gt;(?P&lt;id&gt;\\d+):(?P&lt;source&gt;ncbi):(?P&lt;nb&gt;\\d*)\"\nkeys = \"id source nb\".split(' ')\n\nit.parse_text(text, pattern, keys)\n\n{'id': '2591237', 'nb': '1', 'source': 'ncbi'}",
    "crumbs": [
      "General Code",
      "core"
    ]
  },
  {
    "objectID": "core.html#extending-the-base-class",
    "href": "core.html#extending-the-base-class",
    "title": "core",
    "section": "Extending the base class",
    "text": "Extending the base class\nTextFileBaseReader is a base class, intended to be extended into specific file format readers.\nThe following methods will typically be extended to match data file and other structured text files formats:\n\n__next__ method in order to customize how the iterator parses files into “elements”. For instance, in a FASTA file, one element consists of two lines: a “definition line” and the sequence itself. Extending TextFileBaseReader allows to read pairs of lines sequentially and return an element as a dictionary. For instance, FastaFileReader iterates over each pairs of lines in a Fasta file and return each pair as a dictionary as follows:\n\n    {\n    'definition line': '&gt;2591237:ncbi:1 [MK211378]\\t2591237\\tncbi\\t1 [MK211378] '\n                       '2591237\\tCoronavirus BtRs-BetaCoV/YN2018D\\t\\tscientific '\n                       'name\\n',\n    'sequence':        'TATTAGGTTTTCTACCTACCCAGGA'\n    }\n\nMethods for parsing metadata from the file. For instance, parse_file method will handle how the reader will iterate over the full file and return a dictionary for the entire file.\nExtended classes will also define a specific attributes (text_to_parse_key, re_pattern, re_keys, …)\n\n\nsource\n\nTextFileBaseReader.set_parsing_rules\n\n TextFileBaseReader.set_parsing_rules (pattern:str|bool=None,\n                                       keys:list[str]=None,\n                                       verbose:bool=False)\n\n*Set the standard regex parsing rule for the file.\nRules can be set:\n\nmanually by passing specific custom values for pattern and keys\nautomatically, by testing all parsing rules saved in parsing_rule.json\n\nAutomatic selection of parsing rules works by testing each rule saved in parsing_rule.json on the first definition line of the fasta file, and selecting the one rule that generates the most metadata matches.\nRules consists of two parameters:\n\nThe regex pattern including one group for each metadata item, e.g (?P&lt;group_name&gt;regex_code)\nThe list of keys, i.e. the list with the name of each regex groups, used as key in the metadata dictionary\n\nThis method updates the three following class attributes: re_rule_name, re_pattern, re_keys*\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\npattern\nstr | bool\nNone\nregex pattern to apply to parse the text, search in parsing rules json if None\n\n\nkeys\nlist\nNone\nlist of keys/group for regex, search in parsing rules json if None\n\n\nverbose\nbool\nFalse\nwhen True, provides information on each rule\n\n\nReturns\nNone\n\n\n\n\n\n\nImportant Note to Developpers\nMethod set_parsing_rules is there to allow TextFileBaseReader’s descendant classes to automatically select parsing rule by applying rules saved in a json file to a string extracted from the first element in the file.\nIt assumes that the iterator returns its elements as dictionaries {section_name:section, ...} and not as a pure string. The key self.text_to_parse_key will then be used to extract the text to parse for testing the rules. The base class iterator returns a simple string and self.text_to_parse_key is set to None.\nTo make setting up a default parsing rule for the reader instance, the iterator must return a dictionary and self.text_to_parse_key must be set to the key in the dictionary corresponding the the text to parse.\nSee implementation in FastaFileReader.\nCalling set_parsing_rules on a class that does not satisfy with these characteristics will do nothing and return a warning.\n\n\nit.set_parsing_rules()\n\n/tmp/ipykernel_2808/3478964930.py:154: UserWarning: \n            `text_to_parse_key` is not defined in this class. \n            It is not possible to set a parsing rule.\n            \n  warnings.warn(msg, category=UserWarning)",
    "crumbs": [
      "General Code",
      "core"
    ]
  },
  {
    "objectID": "cnn_virus_data.html",
    "href": "cnn_virus_data.html",
    "title": "data",
    "section": "",
    "text": "There are many different types of files and datasets for this project. All data are located in directory data, under the project root. The following is an overview of the main types of data and in which directory they sit in the tree.\nA description of the content of each directory can be stored in a file readme.md or another *.md file.\nThese readme.md files can be conveniently accessed using the .readme(path) method on ProjectFileSystem.\n\n\n\npfs = ProjectFileSystem()\npfs.info()\n\nRunning linux on local computer\nDevice's home directory: /home/vtec\nProject file structure:\n - Root ........ /home/vtec/projects/bio/metagentools \n - Data Dir .... /home/vtec/projects/bio/metagentools/nbs-dev/data_dev \n - Notebooks ... /home/vtec/projects/bio/metagentools/nbs\n\n\nNote that we have setup this notebook to use the development data directory metagentools/nbs-dev/data_dev and not the standard metagentools/data.\n\npfs.readme()\n\n\n\n\nReadMe file for directory nbs-dev/data_dev:\n\n\n\n\n\n\nThis directory includes all the data required to test and validate metagentools code.\ndata_dev\n |--- CNN_Virus_data\n |     |--- 50mer_ds_100_seq\n |     |--- 150mer_ds_100_seq\n |     |--- train_short\n |     |--- val_short\n |     |--- weight_of_classes\n |--- ncbi\n |     |--- infer_results\n |     |     |--- cnn_virus\n |     |     |--- csv\n |     |     |--- xlsx\n |     |--- refsequences\n |     |     |--- cov\n |     |     |     |--- another_sequence.fa\n |     |     |     |--- cov_virus_sequences_one.fa\n |     |     |     |--- cov_virus_sequences_two.fa\n |     |     |     |--- sequences_two_no_matching_rule.fa\n |     |--- simreads\n |     |     |--- cov\n |     |     |     |--- paired_1seq_50bp\n |     |     |     |      |--- paired_1seq_50bp_1.aln\n |     |     |     |      |--- paired_1seq_50bp_1.fq\n |     |     |     |--- single_1seq_50bp\n |     |     |     |      |--- single_1seq_50bp_1.aln\n |     |     |     |      |--- single_1seq_50bp_1.fq\n |--- ....           \n |--- readme.md               \n\n\n\n\n\n\n\n\n\npfs.readme(pfs.data/'CNN_Virus_data')\n\n\n\n\nReadMe file for directory nbs-dev/data_dev/CNN_Virus_data:\n\n\n\n\n\n\nThis directory includes data used to train and validate the initial CNN Virus model, as well as a few smaller datasets for experimenting.\n\n\n\n\n50-mer reads and their labels, in text format with one line per sample. Each line consists of three components, separated by tabs: the 50-mer read or sequence, the virus species label and the position label:\n'TTACNAGCTCCAGTCTAAGATTGTAACTGGCCTTTTTAAAGATTGCTCTA    94    5\\n'\nFiles: - 50mer_training: dataset with 50,903,296 reads for training - 50mer_validating: dataset with 1,000,000 reads for validation - 50mer_ds_100_reads: small subset of 100 reads from the validating dataset for experiments\n\n\n\n150-mer reads and their labels in text format in a similar format as above:\n'TTCTTTCACCACCACAACCAGTCGGCCGTGGAGAGGCGTCGCCGCGTCTCGTTCGTCGAGGCCGATCGACTGCCGCATGAGAGCGGGTGGTATTCTTCCGAAGACGACGGAGACCGGGACGGTGATGAGGAAACTGGAGAGAGCCACAAC    6    0\\n'\nFiles: - ICTV_150mer_benchmarking: dataset with 10,0000 read - 150mer_ds_100_reads: small subset of 100 reads from ICTV_150mer_benchmarking\n\n\n\nReads of various length with no labels, in simple fasta format. Each read sequence is preceded by a definition line: &gt; Sequence n, where n is the sequence number.\nFiles: - training_sequences_300bp.fasta: dataset with 9,000 300-mer reads - training_sequences_500bp.fasta: dataset with 9,000 500-mer reads - validation_sequences.fasta: dataset with 564 reads of mixed lengths ranging from 163-mer to 497-mer\n\n\n\n\nvirus_name_mapping: mapping between virus species and their numerical label\nweight_of_classes: weights for each virus species class in the training dataset\n\n\n\n\n\n\n\n\n\n\n\nsource\n\n\n\n\n OriginalLabels (p2mapping=None)\n\nConverts labels to species name for original data\nOriginal data include 187 viruses, with label from 0 to 186.\n\nlbls = OriginalLabels()\nfor n in [0, 94, 117, 118]:\n    print(f\"{n:3d}: {lbls.label2species(n)}\")\n\n  0: Variola_virus\n 94: Middle_East_respiratory_syndrome-related_coronavirus\n117: Severe_acute_respiratory_syndrome-related_coronavirus\n118: Yellow_fever_virus\n\n\n\n\n\n\n\npfs = ProjectFileSystem()\n\n\npfs.readme(pfs.data / 'ncbi')\n\n\n\n\nReadMe file for directory nbs-dev/data_dev/ncbi:\n\n\n\n\n\n\nThis directory includes all data related to the work done with reference sequences from NCBI.\nThe data is organized in the following subfolders:\n\nrefsequences: reference CoV sequences downloaded from NCBI, and related metadata\nsimreads: all data from simulated reads, using ART Illumina simulator and the reference sequences\ninfer_results: results from the inference using models with the simulated reads\nds: datasets in proper format for training or inference/prediction using the CNN Virus model\n\n\n\n\n\n\n\npfs.readme(pfs.data / 'ncbi/refsequences')\n\n\n\n\nReadMe file for directory nbs-dev/data_dev/ncbi/refsequences:\n\n\nNo markdown file in this folder\n\n\n\npfs.readme(pfs.data / 'ncbi/simreads')\n\n\n\n\nReadMe file for directory nbs-dev/data_dev/ncbi/simreads:\n\n\n\n\n\n\nThis directory includes all sets of simulated read sequence files generated from NCBI viral sequences using ARC Illumina.\nthis-directory\n    |--cov\n    |    |\n    |    |--single_10seq_50bp\n    |    |    |--single_10seq_50bp.fq\n    |    |    |--single_10seq_50bp.alnEnd\n    |    |-- ...\n    |    |--single_100seq_150bp\n    |    |    |--single_100seq_150bp.fq\n    |    |    |--single_100seq_150bp.aln\n    |    |--paired_100seq_50bp\n    |    |    |--paired_100seq_50bp2.aln\n    |    |    |--paired_100seq_50bp1.aln\n    |    |    |--paired_100seq_50bp2.fq\n    |    |    |--paired_100seq_50bp1.fq\n    |    |-- ...\n    |    |\n    |---yf\n    |    |\n    |    |--yf_AY968064-single-150bp\n    |    |    |--yf_AY968064-single-1seq-150bp.fq\n    |    |    |--yf_AY968064-single-1seq-150bp.aln\n    |    |\n    |--mRhiFer1\n    |    |--mRhiFer1_v1.p.dna_rm.primary_assembly.1\n    |    |    |--mRhiFer1_v1.p.dna_rm.primary_assembly.1.fq\n    |    |    |--mRhiFer1_v1.p.dna_rm.primary_assembly.1.aln\n    |    |\n\nThis directory includes several subdirectories, each for one virus, e.g. cov for corona, yf for yellow fever.\nIn each virus subdirectory, several simreads directory includes simulated reads with various parameters, named as &lt;method&gt;_&lt;nb-seq&gt;_&lt;nb-bp&gt; where” - &lt;method&gt; is either single or paired depending on the simulation method - &lt;nb-seq&gt; is the number of reference sequences used for simulation, and refers to the fa file used - &lt;nb-bp&gt; is the number of base pairs used to simulate reads\nEach sub-directory includes simreads files made using a simulation method and a specific number of reference sequences. - xxx.fq and xxx.aln files when method is single - xxx1.fq, xxx2.fq, xxx1.aln and xxx2.aln files when method is paired.\nExample: - paired_10seq_50bp means that the simreads were generated by using the paired method to simulate 50-bp reads, and using the fa file cov_virus_sequences_010-seqs.fa. - single_100seq_50bp means that the simreads were generated by using the single method to simulate 50-bp reads, and using the fa file cov_virus_sequences_100-seqs.fa. Note that this generated 20,660,104 reads !\n\n\nSimulated reads information is split between two files: - FASTQ (.fq) files providing the read sequences and their ASCII quality scores - ALN (.aln) files with alignment information\n\n\nFASTQ files generated by ART Illumina have the following structure (showing 5 reads), with 4 lines for each read:\n@2591237:ncbi:1-60400\nACAACTCCTATTCGTAGTTGAAGTTGTTGACAAATACTTTGATTGTTACG\n+\nCCCBCGFGBGGGGGGGBGGGGGGGGG&gt;GGG1G=/GGGGGGGGGGGGGGGG\n@2591237:ncbi:1-60399\nGATCAATGTGGCATCTACAATACAGACAGCATGAAGCACCACCAAAGGAC\n+\nBCBCCFGGGGGGGG1CGGGG&lt;GGBGGGGGFGCGGGGGGDGGG/GG1GGGG\n@2591237:ncbi:1-60398\nATCTACCAGTGGTAGATGGGTTCTTAATAATGAACATTATAGAGCTCTAC\n+\nCCCCCGGGEGG1GGF1G/GGEGGGGGGGGGGGGFFGGGGGGGGGGDGGDG\n@2591237:ncbi:1-60397\nCGTAAAGTAGAGGCTGTATGGTAGCTAGCACAAATGCCAGCACCAATAGG\n+\nBCCCCGGGFGGGGGGFGGGGFGG1GGGGGGG&gt;GG1GGGGGGGGGGE&lt;GGG\n@2591237:ncbi:1-60396\nGGTATCGGGTATCTCCTGCATCAATGCAAGGTCTTACAAAGATAAATACT\n+\nCBCCCGGG@CGGGGGGGGGGGG=GFGGGGDGGGFG1GGGGGGGG@GGGGG\nThe following information can be parsed from the each read sequence in the FASTQ file:\n\nLine 1: readid, a unique ID for the read, under for format @readid\nLine 2: readseq, the sequence of the read\nLine 3: a separator +\nLine 4: read_qscores, the base quality scores encoded in ASCII\n\nExample:\n@2591237:ncbi:1-60400\nACAACTCCTATTCGTAGTTGAAGTTGTTGACAAATACTTTGATTGTTACG\n+\nCCCBCGFGBGGGGGGGBGGGGGGGGG&gt;GGG1G=/GGGGGGGGGGGGGGGG\n\nreadid = 2591237:ncbi:1-60400\nreadseq = ACAACTCCTATTCGTAGTTGAAGTTGTTGACAAATACTTTGATTGTTACG, a 50 bp read\nread_qscores = CCCBCGFGBGGGGGGGBGGGGGGGGG&gt;GGG1G=/GGGGGGGGGGGGGGGG\n\n\n\n\n\nALN files generated by ART Illumina consist of : - a header with the ART-Ilumina command used for the simulation (@CM) and info on each of the reference sequences used for the simulations (@SQ). Header always starts with ##ART_Illumina and ends with ##Header End : - the body with 3 lines for each read: 1. definition line with readid, - reference sequence identification number refseqid, - the position in the read in the reference sequence aln_start_pos - the strand the read was taken from ref_seq_strand. + for coding strand and - for template strand 2. aligned reference sequence, that is the sequence segment in the original reference corresponding to the read 3. aligned read sequence, that is the simmulated read sequence, where each bp corresponds to the reference sequence bp in the same position.\nExample of a ALN file generated by ART Illumina (showing 5 reads):\n##ART_Illumina    read_length    50\n@CM    /bin/art_illumina -i /home/vtec/projects/bio/metagentools/data/cov_data/cov_virus_sequences_ten.fa -ss HS25 -l 50 -f 100 -o /home/vtec/projects/bio/metagentools/data/cov_simreads/single_10seq_50bp/single_10seq_50bp -rs 1674660835\n@SQ    2591237:ncbi:1 1   MK211378    2591237    ncbi    1     Coronavirus BtRs-BetaCoV/YN2018D    30213\n@SQ    11128:ncbi:2   2   LC494191    11128    ncbi    2     Bovine coronavirus    30942\n@SQ    31631:ncbi:3   3   KY967361    31631    ncbi    3     Human coronavirus OC43        30661\n@SQ    277944:ncbi:4  4   LC654455    277944    ncbi    4     Human coronavirus NL63    27516\n@SQ    11120:ncbi:5   5   MN987231    11120    ncbi    5     Infectious bronchitis virus    27617\n@SQ    28295:ncbi:6   6   KU893866    28295    ncbi    6     Porcine epidemic diarrhea virus    28043\n@SQ    28295:ncbi:7   7   KJ645638    28295    ncbi    7     Porcine epidemic diarrhea virus    27998\n@SQ    28295:ncbi:8   8   KJ645678    28295    ncbi    8     Porcine epidemic diarrhea virus    27998\n@SQ    28295:ncbi:9   9   KR873434    28295    ncbi    9     Porcine epidemic diarrhea virus    28038\n@SQ    1699095:ncbi:10 10  KT368904    1699095    ncbi    10     Camel alphacoronavirus    27395\n##Header End\n&gt;2591237:ncbi:1    2591237:ncbi:1-60400    14770    +\nACAACTCCTATTCGTAGTTGAAGTTGTTGACAAATACTTTGATTGTTACG\nACAACTCCTATTCGTAGTTGAAGTTGTTGACAAATACTTTGATTGTTACG\n&gt;2591237:ncbi:1    2591237:ncbi:1-60399    17012    -\nGATCAATGTGGCATCTACAATACAGACAGCATGAAGCACCACCAAAGGAC\nGATCAATGTGGCATCTACAATACAGACAGCATGAAGCACCACCAAAGGAC\n&gt;2591237:ncbi:1    2591237:ncbi:1-60398    9188    +\nATCTACCAGTGGTAGATGGGTTCTTAATAATGAACATTATAGAGCTCTAC\nATCTACCAGTGGTAGATGGGTTCTTAATAATGAACATTATAGAGCTCTAC\n.....\n\n\n\n\n\n\n\n\n\n\npfs = ProjectFileSystem()\n\n\npfs.readme(pfs.data / 'saved')\n\n\n\n\nReadMe file for directory nbs-dev/data_dev/saved:\n\n\n\n\n\n\nThis directory includes all data related to models and saved: - saved model parameters - saved datasets\nFor example: - cnn_virus_original/pretrained_model.h5 is the saved model parameters for the CNN Virus model - cnn_virus_datasets/*.tfrecords are the preprocessed datasets used for inference or training, saved in TFRecord format for performance",
    "crumbs": [
      "CNN Virus",
      "data"
    ]
  },
  {
    "objectID": "cnn_virus_data.html#data-directory",
    "href": "cnn_virus_data.html#data-directory",
    "title": "data",
    "section": "",
    "text": "pfs = ProjectFileSystem()\npfs.info()\n\nRunning linux on local computer\nDevice's home directory: /home/vtec\nProject file structure:\n - Root ........ /home/vtec/projects/bio/metagentools \n - Data Dir .... /home/vtec/projects/bio/metagentools/nbs-dev/data_dev \n - Notebooks ... /home/vtec/projects/bio/metagentools/nbs\n\n\nNote that we have setup this notebook to use the development data directory metagentools/nbs-dev/data_dev and not the standard metagentools/data.\n\npfs.readme()\n\n\n\n\nReadMe file for directory nbs-dev/data_dev:\n\n\n\n\n\n\nThis directory includes all the data required to test and validate metagentools code.\ndata_dev\n |--- CNN_Virus_data\n |     |--- 50mer_ds_100_seq\n |     |--- 150mer_ds_100_seq\n |     |--- train_short\n |     |--- val_short\n |     |--- weight_of_classes\n |--- ncbi\n |     |--- infer_results\n |     |     |--- cnn_virus\n |     |     |--- csv\n |     |     |--- xlsx\n |     |--- refsequences\n |     |     |--- cov\n |     |     |     |--- another_sequence.fa\n |     |     |     |--- cov_virus_sequences_one.fa\n |     |     |     |--- cov_virus_sequences_two.fa\n |     |     |     |--- sequences_two_no_matching_rule.fa\n |     |--- simreads\n |     |     |--- cov\n |     |     |     |--- paired_1seq_50bp\n |     |     |     |      |--- paired_1seq_50bp_1.aln\n |     |     |     |      |--- paired_1seq_50bp_1.fq\n |     |     |     |--- single_1seq_50bp\n |     |     |     |      |--- single_1seq_50bp_1.aln\n |     |     |     |      |--- single_1seq_50bp_1.fq\n |--- ....           \n |--- readme.md",
    "crumbs": [
      "CNN Virus",
      "data"
    ]
  },
  {
    "objectID": "cnn_virus_data.html#original-datasets",
    "href": "cnn_virus_data.html#original-datasets",
    "title": "data",
    "section": "",
    "text": "pfs.readme(pfs.data/'CNN_Virus_data')\n\n\n\n\nReadMe file for directory nbs-dev/data_dev/CNN_Virus_data:\n\n\n\n\n\n\nThis directory includes data used to train and validate the initial CNN Virus model, as well as a few smaller datasets for experimenting.\n\n\n\n\n50-mer reads and their labels, in text format with one line per sample. Each line consists of three components, separated by tabs: the 50-mer read or sequence, the virus species label and the position label:\n'TTACNAGCTCCAGTCTAAGATTGTAACTGGCCTTTTTAAAGATTGCTCTA    94    5\\n'\nFiles: - 50mer_training: dataset with 50,903,296 reads for training - 50mer_validating: dataset with 1,000,000 reads for validation - 50mer_ds_100_reads: small subset of 100 reads from the validating dataset for experiments\n\n\n\n150-mer reads and their labels in text format in a similar format as above:\n'TTCTTTCACCACCACAACCAGTCGGCCGTGGAGAGGCGTCGCCGCGTCTCGTTCGTCGAGGCCGATCGACTGCCGCATGAGAGCGGGTGGTATTCTTCCGAAGACGACGGAGACCGGGACGGTGATGAGGAAACTGGAGAGAGCCACAAC    6    0\\n'\nFiles: - ICTV_150mer_benchmarking: dataset with 10,0000 read - 150mer_ds_100_reads: small subset of 100 reads from ICTV_150mer_benchmarking\n\n\n\nReads of various length with no labels, in simple fasta format. Each read sequence is preceded by a definition line: &gt; Sequence n, where n is the sequence number.\nFiles: - training_sequences_300bp.fasta: dataset with 9,000 300-mer reads - training_sequences_500bp.fasta: dataset with 9,000 500-mer reads - validation_sequences.fasta: dataset with 564 reads of mixed lengths ranging from 163-mer to 497-mer\n\n\n\n\nvirus_name_mapping: mapping between virus species and their numerical label\nweight_of_classes: weights for each virus species class in the training dataset\n\n\n\n\n\n\n\n\n\n\n\nsource\n\n\n\n\n OriginalLabels (p2mapping=None)\n\nConverts labels to species name for original data\nOriginal data include 187 viruses, with label from 0 to 186.\n\nlbls = OriginalLabels()\nfor n in [0, 94, 117, 118]:\n    print(f\"{n:3d}: {lbls.label2species(n)}\")\n\n  0: Variola_virus\n 94: Middle_East_respiratory_syndrome-related_coronavirus\n117: Severe_acute_respiratory_syndrome-related_coronavirus\n118: Yellow_fever_virus",
    "crumbs": [
      "CNN Virus",
      "data"
    ]
  },
  {
    "objectID": "cnn_virus_data.html#ncbi-reference-sequences-for-simulated-reads",
    "href": "cnn_virus_data.html#ncbi-reference-sequences-for-simulated-reads",
    "title": "data",
    "section": "",
    "text": "pfs = ProjectFileSystem()\n\n\npfs.readme(pfs.data / 'ncbi')\n\n\n\n\nReadMe file for directory nbs-dev/data_dev/ncbi:\n\n\n\n\n\n\nThis directory includes all data related to the work done with reference sequences from NCBI.\nThe data is organized in the following subfolders:\n\nrefsequences: reference CoV sequences downloaded from NCBI, and related metadata\nsimreads: all data from simulated reads, using ART Illumina simulator and the reference sequences\ninfer_results: results from the inference using models with the simulated reads\nds: datasets in proper format for training or inference/prediction using the CNN Virus model\n\n\n\n\n\n\n\npfs.readme(pfs.data / 'ncbi/refsequences')\n\n\n\n\nReadMe file for directory nbs-dev/data_dev/ncbi/refsequences:\n\n\nNo markdown file in this folder\n\n\n\npfs.readme(pfs.data / 'ncbi/simreads')\n\n\n\n\nReadMe file for directory nbs-dev/data_dev/ncbi/simreads:\n\n\n\n\n\n\nThis directory includes all sets of simulated read sequence files generated from NCBI viral sequences using ARC Illumina.\nthis-directory\n    |--cov\n    |    |\n    |    |--single_10seq_50bp\n    |    |    |--single_10seq_50bp.fq\n    |    |    |--single_10seq_50bp.alnEnd\n    |    |-- ...\n    |    |--single_100seq_150bp\n    |    |    |--single_100seq_150bp.fq\n    |    |    |--single_100seq_150bp.aln\n    |    |--paired_100seq_50bp\n    |    |    |--paired_100seq_50bp2.aln\n    |    |    |--paired_100seq_50bp1.aln\n    |    |    |--paired_100seq_50bp2.fq\n    |    |    |--paired_100seq_50bp1.fq\n    |    |-- ...\n    |    |\n    |---yf\n    |    |\n    |    |--yf_AY968064-single-150bp\n    |    |    |--yf_AY968064-single-1seq-150bp.fq\n    |    |    |--yf_AY968064-single-1seq-150bp.aln\n    |    |\n    |--mRhiFer1\n    |    |--mRhiFer1_v1.p.dna_rm.primary_assembly.1\n    |    |    |--mRhiFer1_v1.p.dna_rm.primary_assembly.1.fq\n    |    |    |--mRhiFer1_v1.p.dna_rm.primary_assembly.1.aln\n    |    |\n\nThis directory includes several subdirectories, each for one virus, e.g. cov for corona, yf for yellow fever.\nIn each virus subdirectory, several simreads directory includes simulated reads with various parameters, named as &lt;method&gt;_&lt;nb-seq&gt;_&lt;nb-bp&gt; where” - &lt;method&gt; is either single or paired depending on the simulation method - &lt;nb-seq&gt; is the number of reference sequences used for simulation, and refers to the fa file used - &lt;nb-bp&gt; is the number of base pairs used to simulate reads\nEach sub-directory includes simreads files made using a simulation method and a specific number of reference sequences. - xxx.fq and xxx.aln files when method is single - xxx1.fq, xxx2.fq, xxx1.aln and xxx2.aln files when method is paired.\nExample: - paired_10seq_50bp means that the simreads were generated by using the paired method to simulate 50-bp reads, and using the fa file cov_virus_sequences_010-seqs.fa. - single_100seq_50bp means that the simreads were generated by using the single method to simulate 50-bp reads, and using the fa file cov_virus_sequences_100-seqs.fa. Note that this generated 20,660,104 reads !\n\n\nSimulated reads information is split between two files: - FASTQ (.fq) files providing the read sequences and their ASCII quality scores - ALN (.aln) files with alignment information\n\n\nFASTQ files generated by ART Illumina have the following structure (showing 5 reads), with 4 lines for each read:\n@2591237:ncbi:1-60400\nACAACTCCTATTCGTAGTTGAAGTTGTTGACAAATACTTTGATTGTTACG\n+\nCCCBCGFGBGGGGGGGBGGGGGGGGG&gt;GGG1G=/GGGGGGGGGGGGGGGG\n@2591237:ncbi:1-60399\nGATCAATGTGGCATCTACAATACAGACAGCATGAAGCACCACCAAAGGAC\n+\nBCBCCFGGGGGGGG1CGGGG&lt;GGBGGGGGFGCGGGGGGDGGG/GG1GGGG\n@2591237:ncbi:1-60398\nATCTACCAGTGGTAGATGGGTTCTTAATAATGAACATTATAGAGCTCTAC\n+\nCCCCCGGGEGG1GGF1G/GGEGGGGGGGGGGGGFFGGGGGGGGGGDGGDG\n@2591237:ncbi:1-60397\nCGTAAAGTAGAGGCTGTATGGTAGCTAGCACAAATGCCAGCACCAATAGG\n+\nBCCCCGGGFGGGGGGFGGGGFGG1GGGGGGG&gt;GG1GGGGGGGGGGE&lt;GGG\n@2591237:ncbi:1-60396\nGGTATCGGGTATCTCCTGCATCAATGCAAGGTCTTACAAAGATAAATACT\n+\nCBCCCGGG@CGGGGGGGGGGGG=GFGGGGDGGGFG1GGGGGGGG@GGGGG\nThe following information can be parsed from the each read sequence in the FASTQ file:\n\nLine 1: readid, a unique ID for the read, under for format @readid\nLine 2: readseq, the sequence of the read\nLine 3: a separator +\nLine 4: read_qscores, the base quality scores encoded in ASCII\n\nExample:\n@2591237:ncbi:1-60400\nACAACTCCTATTCGTAGTTGAAGTTGTTGACAAATACTTTGATTGTTACG\n+\nCCCBCGFGBGGGGGGGBGGGGGGGGG&gt;GGG1G=/GGGGGGGGGGGGGGGG\n\nreadid = 2591237:ncbi:1-60400\nreadseq = ACAACTCCTATTCGTAGTTGAAGTTGTTGACAAATACTTTGATTGTTACG, a 50 bp read\nread_qscores = CCCBCGFGBGGGGGGGBGGGGGGGGG&gt;GGG1G=/GGGGGGGGGGGGGGGG\n\n\n\n\n\nALN files generated by ART Illumina consist of : - a header with the ART-Ilumina command used for the simulation (@CM) and info on each of the reference sequences used for the simulations (@SQ). Header always starts with ##ART_Illumina and ends with ##Header End : - the body with 3 lines for each read: 1. definition line with readid, - reference sequence identification number refseqid, - the position in the read in the reference sequence aln_start_pos - the strand the read was taken from ref_seq_strand. + for coding strand and - for template strand 2. aligned reference sequence, that is the sequence segment in the original reference corresponding to the read 3. aligned read sequence, that is the simmulated read sequence, where each bp corresponds to the reference sequence bp in the same position.\nExample of a ALN file generated by ART Illumina (showing 5 reads):\n##ART_Illumina    read_length    50\n@CM    /bin/art_illumina -i /home/vtec/projects/bio/metagentools/data/cov_data/cov_virus_sequences_ten.fa -ss HS25 -l 50 -f 100 -o /home/vtec/projects/bio/metagentools/data/cov_simreads/single_10seq_50bp/single_10seq_50bp -rs 1674660835\n@SQ    2591237:ncbi:1 1   MK211378    2591237    ncbi    1     Coronavirus BtRs-BetaCoV/YN2018D    30213\n@SQ    11128:ncbi:2   2   LC494191    11128    ncbi    2     Bovine coronavirus    30942\n@SQ    31631:ncbi:3   3   KY967361    31631    ncbi    3     Human coronavirus OC43        30661\n@SQ    277944:ncbi:4  4   LC654455    277944    ncbi    4     Human coronavirus NL63    27516\n@SQ    11120:ncbi:5   5   MN987231    11120    ncbi    5     Infectious bronchitis virus    27617\n@SQ    28295:ncbi:6   6   KU893866    28295    ncbi    6     Porcine epidemic diarrhea virus    28043\n@SQ    28295:ncbi:7   7   KJ645638    28295    ncbi    7     Porcine epidemic diarrhea virus    27998\n@SQ    28295:ncbi:8   8   KJ645678    28295    ncbi    8     Porcine epidemic diarrhea virus    27998\n@SQ    28295:ncbi:9   9   KR873434    28295    ncbi    9     Porcine epidemic diarrhea virus    28038\n@SQ    1699095:ncbi:10 10  KT368904    1699095    ncbi    10     Camel alphacoronavirus    27395\n##Header End\n&gt;2591237:ncbi:1    2591237:ncbi:1-60400    14770    +\nACAACTCCTATTCGTAGTTGAAGTTGTTGACAAATACTTTGATTGTTACG\nACAACTCCTATTCGTAGTTGAAGTTGTTGACAAATACTTTGATTGTTACG\n&gt;2591237:ncbi:1    2591237:ncbi:1-60399    17012    -\nGATCAATGTGGCATCTACAATACAGACAGCATGAAGCACCACCAAAGGAC\nGATCAATGTGGCATCTACAATACAGACAGCATGAAGCACCACCAAAGGAC\n&gt;2591237:ncbi:1    2591237:ncbi:1-60398    9188    +\nATCTACCAGTGGTAGATGGGTTCTTAATAATGAACATTATAGAGCTCTAC\nATCTACCAGTGGTAGATGGGTTCTTAATAATGAACATTATAGAGCTCTAC\n.....",
    "crumbs": [
      "CNN Virus",
      "data"
    ]
  },
  {
    "objectID": "cnn_virus_data.html#model-related-data",
    "href": "cnn_virus_data.html#model-related-data",
    "title": "data",
    "section": "",
    "text": "pfs = ProjectFileSystem()\n\n\npfs.readme(pfs.data / 'saved')\n\n\n\n\nReadMe file for directory nbs-dev/data_dev/saved:\n\n\n\n\n\n\nThis directory includes all data related to models and saved: - saved model parameters - saved datasets\nFor example: - cnn_virus_original/pretrained_model.h5 is the saved model parameters for the CNN Virus model - cnn_virus_datasets/*.tfrecords are the preprocessed datasets used for inference or training, saved in TFRecord format for performance",
    "crumbs": [
      "CNN Virus",
      "data"
    ]
  },
  {
    "objectID": "cnn_virus_data.html#fasta-file",
    "href": "cnn_virus_data.html#fasta-file",
    "title": "data",
    "section": "FASTA file",
    "text": "FASTA file\nExtension of TextFileBaseReader class for fasta sequence files.\nStructure of a FASTA sequence file:\n&gt;definition line - format varies from dataset to dataset\nsequence line: sequence of bases\nExample for the NCBI datasets:\n&gt;seqid accession taxonomyid source seqnb organism\nTATTAGGTTTTCTACCTACCCAGGAAAAGCCAACCAACCTCGATCTCTTGTAGATCTGTTCTCTAAACGAACTTTAAAAT ...\n&gt;2591237:ncbi:1 MK211378    2591237 ncbi    1 Coronavirus BtRs-BetaCoV/YN2018D\nTATTAGGTTTTCTACCTACCCAGGAAAAGCCAACCAACCTCGATCTCTTGTAGATCTGTTCTCTAAACGAACTTTAAAAT ...\n\np2fasta = pfs.data / 'ncbi/refsequences/cov/cov_virus_sequences_two.fa'\n\nfasta = TextFileBaseReader(p2fasta, nlines=1)\nfor i, t in enumerate(fasta):\n    txt = t.replace('\\n', '')[:80] + ' ...'\n    print(f\"{txt}\")\n\n&gt;2591237:ncbi:1 1   MK211378    2591237 ncbi    Coronavirus BtRs-BetaCoV/YN2018D ...\nTATTAGGTTTTCTACCTACCCAGGAAAAGCCAACCAACCTCGATCTCTTGTAGATCTGTTCTCTAAACGAACTTTAAAAT ...\n&gt;11128:ncbi:2   2   LC494191    11128   ncbi    Bovine coronavirus ...\nCATCCCGCTTCACTGATCTCTTGTTAGATCTTTTCATAATCTAAACTTTATAAAAACATCCACTCCCTGTAGTCTATGCC ...\n\n\n\nsource\n\nFastaFileReader\n\n FastaFileReader (path:str|pathlib.Path)\n\nWrap a FASTA file and retrieve its content in raw format and parsed format\n\n\n\n\nType\nDetails\n\n\n\n\npath\nstr | Path\npath to the Fasta file\n\n\n\nAs an iterator, FastaFileReader returns a dict at each step, as follows:\n{\n    'definition line': 'string in file as the definition line for the sequence',\n    'sequence': 'the full sequence'\n}\nIllustration:\n\np2fasta = pfs.data / 'ncbi/refsequences/cov/cov_virus_sequences_two.fa'\nfasta = FastaFileReader(p2fasta)\niteration_output = next(fasta)\n\nprint(iteration_output['definition line'][:80], '...')\nprint(iteration_output['sequence'][:80], '...')\n\n&gt;2591237:ncbi:1 1   MK211378    2591237 ncbi    Coronavirus BtRs-BetaCoV/YN2018D ...\nTATTAGGTTTTCTACCTACCCAGGAAAAGCCAACCAACCTCGATCTCTTGTAGATCTGTTCTCTAAACGAACTTTAAAAT ...\n\n\n\nprint(f\"output type :     {type(iteration_output)}\")\nprint(f\"keys :            {iteration_output.keys()}\")\nprint(f\"definition line : {iteration_output['definition line'][:80]} ...'\")\nprint(f\"sequence :       '{iteration_output['sequence'][:100]} ...'\")\n\noutput type :     &lt;class 'dict'&gt;\nkeys :            dict_keys(['definition line', 'sequence'])\ndefinition line : &gt;2591237:ncbi:1   1   MK211378    2591237 ncbi    Coronavirus BtRs-BetaCoV/YN2018D ...'\nsequence :       'TATTAGGTTTTCTACCTACCCAGGAAAAGCCAACCAACCTCGATCTCTTGTAGATCTGTTCTCTAAACGAACTTTAAAATCTGTGTAGCTGTCGCTCGGC ...'\n\n\nThe definition line is a string, with tab separated values.\n\ndisplay(iteration_output['definition line'])\n\n'&gt;2591237:ncbi:1\\t1\\tMK211378\\t2591237\\tncbi\\tCoronavirus BtRs-BetaCoV/YN2018D'\n\n\n\nsource\n\n\nFastaFileReader.print_first_chunks\n\n FastaFileReader.print_first_chunks (nchunks:int=3)\n\nPrint the first nchunks chunks of text from the file\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nnchunks\nint\n3\nnumber of chunks to print out\n\n\n\nThis is convenient to quickly discover and explore new fasta files in raw text format:\n\nfasta = FastaFileReader(p2fasta)\nfasta.print_first_chunks(nchunks=2)\n\n\nSequence 1:\n&gt;2591237:ncbi:1 1   MK211378    2591237 ncbi    Coronavirus BtRs-BetaCoV/YN2018D\nTATTAGGTTTTCTACCTACCCAGGAAAAGCCAACCAACCTCGATCTCTTGTAGATCTGTTCTCTAAACGAACTTTAAAAT ...\n\nSequence 2:\n&gt;11128:ncbi:2   2   LC494191    11128   ncbi    Bovine coronavirus\nCATCCCGCTTCACTGATCTCTTGTTAGATCTTTTCATAATCTAAACTTTATAAAAACATCCACTCCCTGTAGTCTATGCC ...\n\n\n\n\nParsing metadata\nThe class also provides methods to parse metadata from the file content (definition line, headers, …).\nA regex pattern is used for parsing metadata fom the definition lines in the reference sequence fasta file.\nBelow, we parse the data from the definition line of our Corona virus NCBI dataset (rule fasta_ncbi_std):\nSequence 1:\n\nDefinition Line:\n\n&gt;2591237:ncbi:1 [MK211378]  2591237 ncbi    1 [MK211378] 2591237    Coronavirus YN2018D     scientific name\n\nMetadata:\n\nseqid = 2591237:ncbi:1\ntaxonomyid = 2591237\nsource = ncbi\nseqnb = 1\naccession = MK211378\nspecies = Coronavirus BtRs-BetaCoV/YN2018D\n\n\nSequence 2:\n\nDefinition Line\n\n    &gt;11128:ncbi:2 [LC494191]\n\nMetadata:\n\nseqid = 11128:ncbi:2\ntaxonomyid = 11128\nsource = ncbi\nseqnb = 2\naccession = LC494191\nspecies = ''\n\n\nFastaFileReader offers: - parse_text a method to parse the metadata - an option to set a default “parsing rule” for one instance with set_parsing_rules. - parse_file a method to parse the metadata from all sequences in the file and save it as a json file.\n\nsource\n\n\nTextFileBaseReader.parse_text\n\n TextFileBaseReader.parse_text (txt:str, pattern:str=None,\n                                keys:list[str]=None)\n\n*Parse text using regex pattern and keys. Return a metadata dictionary.\nThe passed text is parsed using the regex pattern. The method return a dictionary in the format:\n{\n    'key_1': 'metadata 1',\n    'key_2': 'metadata 2',\n    ...\n}*\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\ntxt\nstr\n\ntext to parse\n\n\npattern\nstr\nNone\nIf None, uses standard regex pattern to extract metadata, otherwise, uses passed regex\n\n\nkeys\nlist\nNone\nIf None, uses standard regex list of keys, otherwise, uses passed list of keys (str)\n\n\nReturns\ndict\n\nparsed metadata in key/value format\n\n\n\nRunning the parser function with specifically defined pattern and keys.\n\nfasta = FastaFileReader(p2fasta)\ndfn_line, sequence = next(fasta).values()\nprint(dfn_line.replace('\\n', ''))\n\n&gt;2591237:ncbi:1 1   MK211378    2591237 ncbi    Coronavirus BtRs-BetaCoV/YN2018D\n\n\n\n# pattern = r\"^&gt;(?P&lt;seqid&gt;(?P&lt;taxonomyid&gt;\\d+):(?P&lt;source&gt;ncbi):(?P&lt;seqnb&gt;\\d*))[\\s\\t]*\\[(?P&lt;accession&gt;[\\w\\d]*)\\]([\\s\\t]*(?P=taxonomyid)[\\s\\t]*(?P=source)[\\s\\t]*(?P=seqnb)[\\s\\t]*\\[(?P=accession)\\][\\s\\t]*(?P=taxonomyid)[\\s\\t]*(?P&lt;species&gt;[\\w\\s\\-\\_\\/]*))?\"\npattern = r\"^&gt;(?P&lt;seqid&gt;(?P&lt;taxonomyid&gt;\\d+):(?P&lt;source&gt;ncbi):(?P&lt;seqnb&gt;\\d*))[\\s\\t]*(?P=seqnb)[\\s\\t](?P&lt;accession&gt;[\\w\\d]*)([\\s\\t]*(?P=taxonomyid)[\\s\\t]*(?P=source)[\\s\\t][\\s\\t]*(?P&lt;organism&gt;[\\w\\s\\-\\_\\/]*))?\"\n\nkeys = 'seqid taxonomyid accession source seqnb organism'.split(' ')\n\n\nfasta.parse_text(dfn_line, pattern=pattern, keys=keys)\n\n{'accession': 'MK211378',\n 'organism': 'Coronavirus BtRs-BetaCoV/YN2018D',\n 'seqid': '2591237:ncbi:1',\n 'seqnb': '1',\n 'source': 'ncbi',\n 'taxonomyid': '2591237'}\n\n\nWhen a FastaFileReader instance is created, all existing rules in the file default_parsing_rules.json are tested on the first definition line of the fasta file and the one rule that parses the most matches will be selected automatically and saved in instance attributes re_rule_name, re_pattern and re_keys.\nparse_file extract metadata from each definition line in the fasta file and return a dictionary with all metadata.\n\nprint(fasta.re_rule_name)\nprint(fasta.re_pattern)\nprint(fasta.re_keys)\n\nfasta_ncbi_std\n^&gt;(?P&lt;seqid&gt;(?P&lt;taxonomyid&gt;\\d+):(?P&lt;source&gt;ncbi):(?P&lt;seqnb&gt;\\d*))[\\s\\t]*(?P=seqnb)[\\s\\t](?P&lt;accession&gt;[\\w\\d]*)([\\s\\t]*(?P=taxonomyid)[\\s\\t]*(?P=source)[\\s\\t][\\s\\t]*(?P&lt;organism&gt;[\\w\\s\\-\\_/]*))?\n['seqid', 'taxonomyid', 'source', 'accession', 'seqnb', 'organism']\n\n\n\nfasta.parse_text(dfn_line)\n\n{'accession': 'MK211378',\n 'organism': 'Coronavirus BtRs-BetaCoV/YN2018D',\n 'seqid': '2591237:ncbi:1',\n 'seqnb': '1',\n 'source': 'ncbi',\n 'taxonomyid': '2591237'}\n\n\nWhen another fasta file, which has another definition line structure, is used, another parsing rule is selected.\n\np2other = pfs.data / 'ncbi/refsequences/cov/another_sequence.fa'\nassert p2other.is_file()\n\nit2 = FastaFileReader(path=p2other)\n\ndfn_line, sequence = next(it2).values()\nprint(dfn_line.replace('\\n', ''))\n\n&gt;1 dna_rm:primary_assembly primary_assembly:mRhiFer1_v1.p:1:1:124933378:1 REF\n\n\n\nprint(it2.re_rule_name)\nprint(it2.re_pattern)\nprint(it2.re_keys)\n\nfasta_rhinolophus_ferrumequinum\n^&gt;\\d[\\s\\t](?P&lt;seq_type&gt;dna_rm):(?P&lt;id_type&gt;[\\w\\_]*)[\\s\\w](?P=id_type):(?P&lt;assy&gt;[\\w\\d\\_]*)\\.(?P&lt;seq_level&gt;[\\w]*):\\d*:\\d*:(?P&lt;taxonomy&gt;\\d*):(?P&lt;id&gt;\\d*)[\\s    ]REF$\n['seq_type', 'id_type', 'assy', 'seq_level', 'taxonomy', 'id']\n\n\n\npprint(it2.parse_text(dfn_line))\n\n{'assy': 'mRhiFer1_v1',\n 'id': '1',\n 'id_type': 'primary_assembly',\n 'seq_level': 'p',\n 'seq_type': 'dna_rm',\n 'taxonomy': '124933378'}\n\n\nThis rule selection is performed by the class method set_parsing_rule. The method can also be called with specific pattern and keys to force parsing rule not yet saved in the json file.\n\nsource\n\n\nTextFileBaseReader.set_parsing_rules\n\n TextFileBaseReader.set_parsing_rules (pattern:str|bool=None,\n                                       keys:list[str]=None,\n                                       verbose:bool=False)\n\n*Set the standard regex parsing rule for the file.\nRules can be set:\n\nmanually by passing specific custom values for pattern and keys\nautomatically, by testing all parsing rules saved in parsing_rule.json\n\nAutomatic selection of parsing rules works by testing each rule saved in parsing_rule.json on the first definition line of the fasta file, and selecting the one rule that generates the most metadata matches.\nRules consists of two parameters:\n\nThe regex pattern including one group for each metadata item, e.g (?P&lt;group_name&gt;regex_code)\nThe list of keys, i.e. the list with the name of each regex groups, used as key in the metadata dictionary\n\nThis method updates the three following class attributes: re_rule_name, re_pattern, re_keys*\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\npattern\nstr | bool\nNone\nregex pattern to apply to parse the text, search in parsing rules json if None\n\n\nkeys\nlist\nNone\nlist of keys/group for regex, search in parsing rules json if None\n\n\nverbose\nbool\nFalse\nwhen True, provides information on each rule\n\n\nReturns\nNone\n\n\n\n\n\n\nfasta = FastaFileReader(p2fasta)\ndfn_line, sequence = next(fasta).values()\nprint(f\"definition line: '{dfn_line[:-1]}'\")\n\ndefinition line: '&gt;2591237:ncbi:1   1   MK211378    2591237 ncbi    Coronavirus BtRs-BetaCoV/YN2018'\n\n\nAutomatic parsing works by testing each saved rule for the value of definition line in the first sequence in the fasta file.\n\nprint(f\"key for text to parse: {fasta.text_to_parse_key}\\n\")\nfasta.reset_iterator()\nprint('Text to parse for testing (extracted from first iteration):')\nprint(next(fasta)[fasta.text_to_parse_key])\nprint()\nfasta.set_parsing_rules(verbose=True)\n\nkey for text to parse: definition line\n\nText to parse for testing (extracted from first iteration):\n&gt;2591237:ncbi:1 1   MK211378    2591237 ncbi    Coronavirus BtRs-BetaCoV/YN2018D\n\n--------------------------------------------------------------------------------\nRule &lt;fasta_ncbi_std&gt; generated 6 matches\n--------------------------------------------------------------------------------\n^&gt;(?P&lt;seqid&gt;(?P&lt;taxonomyid&gt;\\d+):(?P&lt;source&gt;ncbi):(?P&lt;seqnb&gt;\\d*))[\\s\\t]*(?P=seqnb)[\\s\\t](?P&lt;accession&gt;[\\w\\d]*)([\\s\\t]*(?P=taxonomyid)[\\s\\t]*(?P=source)[\\s\\t][\\s\\t]*(?P&lt;organism&gt;[\\w\\s\\-\\_/]*))?\n['seqid', 'taxonomyid', 'source', 'accession', 'seqnb', 'organism']\n--------------------------------------------------------------------------------\nRule &lt;fastq_art_illumina_ncbi_std&gt; generated an error\nNo match on this line\n--------------------------------------------------------------------------------\nRule &lt;aln_art_illumina_ncbi_std&gt; generated an error\nNo match on this line\n--------------------------------------------------------------------------------\nRule &lt;aln_art_illumina-refseq-ncbi-std&gt; generated an error\nNo match on this line\n--------------------------------------------------------------------------------\nRule &lt;fasta_ncbi_cov&gt; generated an error\nNo match on this line\n--------------------------------------------------------------------------------\nRule &lt;fasta_rhinolophus_ferrumequinum&gt; generated an error\nNo match on this line\n--------------------------------------------------------------------------------\nSelected rule with most matches: fasta_ncbi_std\n\n\nIf no saved rule generates a match, re_rule_name, re_pattern and re_keys remain None and a warning message is issued to ask user to add a parsing rule manually.\n\np2nomatch = pfs.data / 'ncbi/refsequences/cov/sequences_two_no_matching_rule.fa'\nfasta2 = FastaFileReader(p2nomatch)\n\n/home/vtec/projects/bio/metagentools/metagentools/core.py:520: UserWarning: \n        None of the saved parsing rules were able to extract metadata from the first line in this file.\n        You must set a custom rule (pattern + keys) before parsing text, by using:\n            `self.set_parsing_rules(custom_pattern, custom_list_of_keys)`\n                \n  warnings.warn(msg, category=UserWarning)\n\n\n\nfasta2.re_rule_name is None\n\nTrue\n\n\nBut we still can set a standard rule manually, by passing a re pattern and the corresponding list of keys.\n\npat = r\"^&gt;(?P&lt;seqid&gt;(?P&lt;taxonomyid&gt;\\d+):(?P&lt;source&gt;ncbi):(?P&lt;seqnb&gt;\\d*))\\s*(?P&lt;text&gt;[\\w\\s]*)$\"\nkeys = \"seqid taxonomyid source seqnb text\".split()\nfasta2.set_parsing_rules(pattern=pat, keys=keys)\n\nprint(fasta2.re_rule_name)\nprint(fasta2.re_pattern)\nprint(fasta2.re_keys)\n\nCustom Rule\n^&gt;(?P&lt;seqid&gt;(?P&lt;taxonomyid&gt;\\d+):(?P&lt;source&gt;ncbi):(?P&lt;seqnb&gt;\\d*))\\s*(?P&lt;text&gt;[\\w\\s]*)$\n['seqid', 'taxonomyid', 'source', 'seqnb', 'text']\n\n\n\nfasta2.reset_iterator()\ndfn_line, sequence = next(fasta2).values()\nprint(f\"definition line: '{dfn_line[:-1]}'\")\nfasta2.parse_text(dfn_line)\n\ndefinition line: '&gt;2591237:ncbi:1 this sequence does not match any saved parsing rul'\n\n\n{'seqid': '2591237:ncbi:1',\n 'seqnb': '1',\n 'source': 'ncbi',\n 'taxonomyid': '2591237',\n 'text': 'this sequence does not match any saved parsing rule'}\n\n\n\nsource\n\n\nFastaFileReader.parse_file\n\n FastaFileReader.parse_file (add_seq:bool=False, save_json:bool=False)\n\nRead fasta file and return a dictionary with definition line metadata and optionally sequences\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nadd_seq\nbool\nFalse\nWhen True, add the full sequence to the parsed metadata dictionary\n\n\nsave_json\nbool\nFalse\nWhen True, save the file metadata as a json file of same stem name\n\n\nReturns\ndict[str]\n\nMetadata as Key/Values pairs\n\n\n\n\nfasta = FastaFileReader(p2fasta)\npprint(fasta.parse_file())\n\n{'11128:ncbi:2': {'accession': 'LC494191',\n                  'organism': 'Bovine coronavirus',\n                  'seqid': '11128:ncbi:2',\n                  'seqnb': '2',\n                  'source': 'ncbi',\n                  'taxonomyid': '11128'},\n '2591237:ncbi:1': {'accession': 'MK211378',\n                    'organism': 'Coronavirus BtRs-BetaCoV/YN2018D',\n                    'seqid': '2591237:ncbi:1',\n                    'seqnb': '1',\n                    'source': 'ncbi',\n                    'taxonomyid': '2591237'}}\n\n\n\nfasta.parse_file(save_json=True);\n\nMetadata for 'cov_virus_sequences_two.fa'&gt; saved as &lt;cov_virus_sequences_two_metadata.json&gt; in  \n/home/vtec/projects/bio/metagentools/nbs-dev/data_dev/ncbi/refsequences/cov\n\n\n\n\nwith open('../default_parsing_rules.json', 'r') as fp:\n    pprint(json.load(fp), width=20)\n\n{'aln_art_illumina-refseq-ncbi-std': {'keys': 'refseqid '\n                                              'reftaxonomyid '\n                                              'refsource '\n                                              'refseqnb '\n                                              'refseq_accession '\n                                              'organism '\n                                              'refseq_length',\n                                      'pattern': '^@SQ[\\\\t\\\\s]*(?P&lt;refseqid&gt;(?P&lt;reftaxonomyid&gt;\\\\d*):(?P&lt;refsource&gt;\\\\w*):(?P&lt;refseqnb&gt;\\\\d*))[\\\\t\\\\s]*(?P=refseqnb)[\\\\t\\\\s]*(?P&lt;refseq_accession&gt;[\\\\w\\\\d]*)[\\\\t\\\\s]*(?P=reftaxonomyid)[\\\\t\\\\s]*(?P=refsource)[\\\\t\\\\s](?P&lt;organism&gt;.*)[\\\\t\\\\s](?P&lt;refseq_length&gt;\\\\d*)$'},\n 'aln_art_illumina_ncbi_std': {'keys': 'refseqid '\n                                       'reftaxonomyid '\n                                       'refsource '\n                                       'refseqnb '\n                                       'readid '\n                                       'readnb '\n                                       'aln_start_pos '\n                                       'refseq_strand',\n                               'pattern': '^&gt;(?P&lt;refseqid&gt;(?P&lt;reftaxonomyid&gt;\\\\d*):(?P&lt;refsource&gt;\\\\w*):(?P&lt;refseqnb&gt;\\\\d*))(\\\\s|\\t'\n                                          ')*(?P&lt;readid&gt;(?P=reftaxonomyid):(?P=refsource):(?P=refseqnb)-(?P&lt;readnb&gt;\\\\d*(\\\\/\\\\d(-\\\\d)?)?))(\\\\s|\\\\t)(?P&lt;aln_start_pos&gt;\\\\d*)(\\\\s|\\\\t)(?P&lt;refseq_strand&gt;(-|\\\\+))$'},\n 'fasta_ncbi_cov': {'keys': 'seqid '\n                            'taxonomyid '\n                            'source '\n                            'accession '\n                            'seqnb '\n                            'organism',\n                    'pattern': '^&gt;(?P&lt;seqid&gt;(?P&lt;taxonomyid&gt;\\\\d+):(?P&lt;source&gt;ncbi):(?P&lt;seqnb&gt;\\\\d*))[\\\\s\\\\t]*\\\\[(?P&lt;accession&gt;[\\\\w\\\\d]*)\\\\]([\\\\s\\\\t]*(?P=taxonomyid)[\\\\s\\\\t]*(?P=source)[\\\\s\\\\t]*(?P=seqnb)[\\\\s\\\\t]*\\\\[(?P=accession)\\\\][\\\\s\\\\t]*(?P=taxonomyid)[\\\\s\\\\t]*(?P&lt;organism&gt;[\\\\w\\\\s\\\\-\\\\_\\\\/]*))?'},\n 'fasta_ncbi_std': {'keys': 'seqid '\n                            'taxonomyid '\n                            'source '\n                            'accession '\n                            'seqnb '\n                            'organism',\n                    'pattern': '^&gt;(?P&lt;seqid&gt;(?P&lt;taxonomyid&gt;\\\\d+):(?P&lt;source&gt;ncbi):(?P&lt;seqnb&gt;\\\\d*))[\\\\s\\\\t]*(?P=seqnb)[\\\\s\\\\t](?P&lt;accession&gt;[\\\\w\\\\d]*)([\\\\s\\\\t]*(?P=taxonomyid)[\\\\s\\\\t]*(?P=source)[\\\\s\\\\t][\\\\s\\\\t]*(?P&lt;organism&gt;[\\\\w\\\\s\\\\-\\\\_/]*))?'},\n 'fasta_rhinolophus_ferrumequinum': {'keys': 'seq_type '\n                                             'id_type '\n                                             'assy '\n                                             'seq_level '\n                                             'taxonomy '\n                                             'id',\n                                     'pattern': '^&gt;\\\\d[\\\\s\\\\t](?P&lt;seq_type&gt;dna_rm):(?P&lt;id_type&gt;[\\\\w\\\\_]*)[\\\\s\\\\w](?P=id_type):(?P&lt;assy&gt;[\\\\w\\\\d\\\\_]*)\\\\.(?P&lt;seq_level&gt;[\\\\w]*):\\\\d*:\\\\d*:(?P&lt;taxonomy&gt;\\\\d*):(?P&lt;id&gt;\\\\d*)[\\\\s\\t'\n                                                ']REF$'},\n 'fastq_art_illumina_ncbi_std': {'keys': 'readid '\n                                         'reftaxonomyid '\n                                         'refsource '\n                                         'refseqnb '\n                                         'readnb',\n                                 'pattern': '^@(?P&lt;readid&gt;(?P&lt;reftaxonomyid&gt;\\\\d*):(?P&lt;refsource&gt;\\\\w*):(?P&lt;refseqnb&gt;\\\\d*)-(?P&lt;readnb&gt;\\\\d*(\\\\/\\\\d)?))$'}}\n\n\n\np2fasta = pfs.data / 'ncbi/refsequences/cov/cov_virus_sequence_one.fa'\nfasta = FastaFileReader(p2fasta)\nfasta_meta = fasta.parse_file(save_json=True)\npprint(fasta_meta)\n\nMetadata for 'cov_virus_sequence_one.fa'&gt; saved as &lt;cov_virus_sequence_one_metadata.json&gt; in  \n/home/vtec/projects/bio/metagentools/nbs-dev/data_dev/ncbi/refsequences/cov\n\n{'2591237:ncbi:1': {'accession': 'MK211378',\n                    'organism': 'Coronavirus BtRs-BetaCoV/YN2018D',\n                    'seqid': '2591237:ncbi:1',\n                    'seqnb': '1',\n                    'source': 'ncbi',\n                    'taxonomyid': '2591237'}}",
    "crumbs": [
      "CNN Virus",
      "data"
    ]
  },
  {
    "objectID": "cnn_virus_data.html#fastq-file",
    "href": "cnn_virus_data.html#fastq-file",
    "title": "data",
    "section": "FASTQ file",
    "text": "FASTQ file\nExtension of TextFileBaseReader class for fastq sequence files.\nStructure of a FASTQ sequence file:\n\np2fastq = pfs.data / 'ncbi/simreads/cov/single_1seq_150bp/single_1seq_150bp.fq'\n\nfastq = TextFileBaseReader(p2fastq, nlines=1)\nfor i, t in enumerate(fastq):\n    txt = t.replace('\\n', '')[:80]\n    print(f\"{txt}\")\n    if i &gt;= 11: break\n\n@2591237:ncbi:1-40200\nTTGTAGATGGTGTTCCTTTTGTTGTTTCAACTGGATACCATTTTCGTGAGTTAGGAGTTGTACATAATCAGGATGTAAAC\n+\nCCCGGGCGGGGGCJGJJJGJJGJJJGJGGJGJJJGJGGGGGGGGCJGJGGGGGJJJJGCCGGGGGJCGCGJGJCG=GGGG\n@2591237:ncbi:1-40199\nTCATAGTACTACAGATAGAGACACCAGCTACGGTGCGAGCTCTATTCTTTGCACTAATGGCGTACTTAAGAGTCATTTGA\n+\n=CCGGGGCGGGGGJJGJJGJGJG=GJJGJCGJJJCJ=JJJJGGJJCJGJGG=JGC1JJGG8GCJCGGGCGG(GCGGCGC=\n@2591237:ncbi:1-40198\nTAACATAGTGGTTCGTTTATCAAGGATAATCTATCTCCATAGGTTCTTCATCATCTAACTCTGAATATTTATTCTTAGTT\n+\nC=CGGGGGGGGGGCJJJJ=JJJJJJJJJJJGGJJJJ1GJJ8GJJGGGJGGJJC=JJGGGCCGG88GG=GGGGGGCJGGGG\n\n\n\nsource\n\nFastqFileReader\n\n FastqFileReader (path:str|pathlib.Path)\n\nIterator going through a fastq file’s sequences and return each section + prob error as a dict\n\n\n\n\n\n\n\n\n\nType\nDetails\n\n\n\n\npath\nstr | Path\npath to the fastq file\n\n\nReturns\ndict\nkey/value with keys: definition line; sequence; q score; prob error\n\n\n\n\nfastq = FastqFileReader(p2fastq)\niteration_output = next(fastq)\n\nprint(type(iteration_output))\nprint(iteration_output.keys())\nprint(f\"Definition line:  {iteration_output['definition line']}\")\nprint(f\"Read sequence:    {iteration_output['sequence']}\")\nprint(f\"Q scores (ASCII): {iteration_output['read_qscores']}\")\nprint(f\"Prob error:       {','.join([f'{p:.4f}' for p in iteration_output['probs error']])}\")\n\n&lt;class 'dict'&gt;\ndict_keys(['definition line', 'sequence', 'read_qscores', 'probs error'])\nDefinition line:  @2591237:ncbi:1-40200\nRead sequence:    TTGTAGATGGTGTTCCTTTTGTTGTTTCAACTGGATACCATTTTCGTGAGTTAGGAGTTGTACATAATCAGGATGTAAACTTACATAGCTCGCGTCTCAGTTTCAAGGAACTTTTAGTGTATGCTGCTGATCCAGCCATGCATGCAGCTT\nQ scores (ASCII): CCCGGGCGGGGGCJGJJJGJJGJJJGJGGJGJJJGJGGGGGGGGCJGJGGGGGJJJJGCCGGGGGJCGCGJGJCG=GGGG=CGGGGGG1GCGCGGGGCCGJC8GGGGGGGGGGGCGGGGGGGGGGGC8GGGGGGCGGC1GGGCGGGGGCC\nProb error:       0.0004,0.0004,0.0004,0.0002,0.0002,0.0002,0.0004,0.0002,0.0002,0.0002,0.0002,0.0002,0.0004,0.0001,0.0002,0.0001,0.0001,0.0001,0.0002,0.0001,0.0001,0.0002,0.0001,0.0001,0.0001,0.0002,0.0001,0.0002,0.0002,0.0001,0.0002,0.0001,0.0001,0.0001,0.0002,0.0001,0.0002,0.0002,0.0002,0.0002,0.0002,0.0002,0.0002,0.0002,0.0004,0.0001,0.0002,0.0001,0.0002,0.0002,0.0002,0.0002,0.0002,0.0001,0.0001,0.0001,0.0001,0.0002,0.0004,0.0004,0.0002,0.0002,0.0002,0.0002,0.0002,0.0001,0.0004,0.0002,0.0004,0.0002,0.0001,0.0002,0.0001,0.0004,0.0002,0.0016,0.0002,0.0002,0.0002,0.0002,0.0016,0.0004,0.0002,0.0002,0.0002,0.0002,0.0002,0.0002,0.0251,0.0002,0.0004,0.0002,0.0004,0.0002,0.0002,0.0002,0.0002,0.0004,0.0004,0.0002,0.0001,0.0004,0.0050,0.0002,0.0002,0.0002,0.0002,0.0002,0.0002,0.0002,0.0002,0.0002,0.0002,0.0002,0.0004,0.0002,0.0002,0.0002,0.0002,0.0002,0.0002,0.0002,0.0002,0.0002,0.0002,0.0002,0.0004,0.0050,0.0002,0.0002,0.0002,0.0002,0.0002,0.0002,0.0004,0.0002,0.0002,0.0004,0.0251,0.0002,0.0002,0.0002,0.0004,0.0002,0.0002,0.0002,0.0002,0.0002,0.0004,0.0004\n\n\nFive largest probabilities of error:\n\nnp.sort(iteration_output['probs error'])[-5:]\n\narray([0.00158489, 0.00501187, 0.00501187, 0.02511886, 0.02511886])\n\n\n\nnp.argsort(iteration_output['probs error'])[-5:]\n\narray([ 80, 127, 102, 138,  88])\n\n\n\ndfn_line = iteration_output['definition line']\nmeta = fastq.parse_text(dfn_line)\nmeta\n\n{'readid': '2591237:ncbi:1-40200',\n 'readnb': '40200',\n 'refseqnb': '1',\n 'refsource': 'ncbi',\n 'reftaxonomyid': '2591237'}\n\n\n\nfastq = FastqFileReader(p2fastq)\nnext(fastq).keys()\n\ndict_keys(['definition line', 'sequence', 'read_qscores', 'probs error'])\n\n\n\nsource\n\n\nFastqFileReader.parse_file\n\n FastqFileReader.parse_file (add_readseq:bool=False,\n                             add_qscores:bool=False,\n                             add_probs_error:bool=False,\n                             save_json:bool=False)\n\nRead fastq file, return a dict with definition line metadata and optionally read sequence and q scores, …\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nadd_readseq\nbool\nFalse\nWhen True, add the full sequence to the parsed metadata dictionary\n\n\nadd_qscores\nbool\nFalse\nAdd the read ASCII Q Scores to the parsed dictionary when True\n\n\nadd_probs_error\nbool\nFalse\nAdd the read probability of error to the parsed dictionary when True\n\n\nsave_json\nbool\nFalse\nWhen True, save the file metadata as a json file of same stem name\n\n\nReturns\ndict[str]\n\nMetadata as Key/Values pairs\n\n\n\n\nparsed = fastq.parse_file(add_readseq=False, add_qscores=False, add_probs_error=False)\nfor i, (k, v) in enumerate(parsed.items()):\n    print(k)\n    pprint(v)\n    if i &gt;=3: break\n\n2591237:ncbi:1-40200\n{'readid': '2591237:ncbi:1-40200',\n 'readnb': '40200',\n 'refseqnb': '1',\n 'refsource': 'ncbi',\n 'reftaxonomyid': '2591237'}\n2591237:ncbi:1-40199\n{'readid': '2591237:ncbi:1-40199',\n 'readnb': '40199',\n 'refseqnb': '1',\n 'refsource': 'ncbi',\n 'reftaxonomyid': '2591237'}\n2591237:ncbi:1-40198\n{'readid': '2591237:ncbi:1-40198',\n 'readnb': '40198',\n 'refseqnb': '1',\n 'refsource': 'ncbi',\n 'reftaxonomyid': '2591237'}\n2591237:ncbi:1-40197\n{'readid': '2591237:ncbi:1-40197',\n 'readnb': '40197',\n 'refseqnb': '1',\n 'refsource': 'ncbi',\n 'reftaxonomyid': '2591237'}\n\n\n\nmetadata = fastq.parse_file(add_readseq=True)\ndf = pd.DataFrame(metadata).T\ndf.head(10)\n\n\n\n\n\n\n\n\nreadid\nreadnb\nrefseqnb\nrefsource\nreftaxonomyid\nreadseq\n\n\n\n\n2591237:ncbi:1-40200\n2591237:ncbi:1-40200\n40200\n1\nncbi\n2591237\nTTGTAGATGGTGTTCCTTTTGTTGTTTCAACTGGATACCATTTTCG...\n\n\n2591237:ncbi:1-40199\n2591237:ncbi:1-40199\n40199\n1\nncbi\n2591237\nTCATAGTACTACAGATAGAGACACCAGCTACGGTGCGAGCTCTATT...\n\n\n2591237:ncbi:1-40198\n2591237:ncbi:1-40198\n40198\n1\nncbi\n2591237\nTAACATAGTGGTTCGTTTATCAAGGATAATCTATCTCCATAGGTTC...\n\n\n2591237:ncbi:1-40197\n2591237:ncbi:1-40197\n40197\n1\nncbi\n2591237\nTAATCACTGATAGCAGCATTGCCATCCTGAGCAAAGAAGAAGTGTT...\n\n\n2591237:ncbi:1-40196\n2591237:ncbi:1-40196\n40196\n1\nncbi\n2591237\nCTAATGTCAGTACGCCTACAATGCCTGCATCACGCATAGCATCGCA...\n\n\n2591237:ncbi:1-40195\n2591237:ncbi:1-40195\n40195\n1\nncbi\n2591237\nAAGCTGAAGCATACATAACACAGTCCTTAAGCCGATAACCAGACAA...\n\n\n2591237:ncbi:1-40194\n2591237:ncbi:1-40194\n40194\n1\nncbi\n2591237\nAGTGGAAGAACTTCACCGTCAAGATGAAACTCGACGGGGCTCTCCA...\n\n\n2591237:ncbi:1-40193\n2591237:ncbi:1-40193\n40193\n1\nncbi\n2591237\nGCGTCTCGAGTGCTTCGAGTTCACCGTTCTTGAGAACAACCTCCTC...\n\n\n2591237:ncbi:1-40192\n2591237:ncbi:1-40192\n40192\n1\nncbi\n2591237\nCTGGTAGTATCTAAGGCTCCACTGAAATACTTGTACTTGTTATATA...\n\n\n2591237:ncbi:1-40191\n2591237:ncbi:1-40191\n40191\n1\nncbi\n2591237\nGTCTCTATCTGTAGTACTATGACAAATAGACAGTTTCATCAGAAAT...\n\n\n\n\n\n\n\n\nfastq.set_parsing_rules(verbose=True)\n\n--------------------------------------------------------------------------------\nRule &lt;fasta_ncbi_std&gt; generated an error\nNo match on this line\n--------------------------------------------------------------------------------\nRule &lt;fastq_art_illumina_ncbi_std&gt; generated 5 matches\n--------------------------------------------------------------------------------\n^@(?P&lt;readid&gt;(?P&lt;reftaxonomyid&gt;\\d*):(?P&lt;refsource&gt;\\w*):(?P&lt;refseqnb&gt;\\d*)-(?P&lt;readnb&gt;\\d*(\\/\\d)?))$\n['readid', 'reftaxonomyid', 'refsource', 'refseqnb', 'readnb']\n--------------------------------------------------------------------------------\nRule &lt;aln_art_illumina_ncbi_std&gt; generated an error\nNo match on this line\n--------------------------------------------------------------------------------\nRule &lt;aln_art_illumina-refseq-ncbi-std&gt; generated an error\nNo match on this line\n--------------------------------------------------------------------------------\nRule &lt;fasta_ncbi_cov&gt; generated an error\nNo match on this line\n--------------------------------------------------------------------------------\nRule &lt;fasta_rhinolophus_ferrumequinum&gt; generated an error\nNo match on this line\n--------------------------------------------------------------------------------\nSelected rule with most matches: fastq_art_illumina_ncbi_std",
    "crumbs": [
      "CNN Virus",
      "data"
    ]
  },
  {
    "objectID": "cnn_virus_data.html#aln-alignment-files",
    "href": "cnn_virus_data.html#aln-alignment-files",
    "title": "data",
    "section": "ALN Alignment Files",
    "text": "ALN Alignment Files\nExtension of TextFileBaseReader class for ALN read/sequence alignment files.\nStructure of a ALN sequence file:\n\np2aln = pfs.data / 'ncbi/simreads/cov/single_1seq_150bp/single_1seq_150bp.aln'\nassert p2aln.is_file()\n\naln = TextFileBaseReader(p2aln, nlines=1)\nfor i, t in enumerate(aln):\n    txt = t.replace('\\n', '')[:80]\n    print(f\"{txt}\")\n    if i &gt;= 12: break\n\n##ART_Illumina  read_length 150\n@CM /usr/bin/art_illumina -i /home/vtec/projects/bio/metagentools/data/ncbi/refs\n@SQ 2591237:ncbi:1  1   MK211378    2591237 ncbi    Coronavirus BtRs-BetaCoV/YN2018D    3021\n##Header End\n&gt;2591237:ncbi:1 2591237:ncbi:1-40200    14370   +\nTTGTAGATGGTGTTCCTTTTGTTGTTTCAACTGGATACCATTTTCGTGAGTTAGGAGTTGTACATAATCAGGATGTAAAC\nTTGTAGATGGTGTTCCTTTTGTTGTTTCAACTGGATACCATTTTCGTGAGTTAGGAGTTGTACATAATCAGGATGTAAAC\n&gt;2591237:ncbi:1 2591237:ncbi:1-40199    15144   -\nTCATAGTACTACAGATAGAGACACCAGCTACGGTGCGAGCTCTATTCTTTGCACTAATGGCGTACTTAAGATTCATTTGA\nTCATAGTACTACAGATAGAGACACCAGCTACGGTGCGAGCTCTATTCTTTGCACTAATGGCGTACTTAAGAGTCATTTGA\n&gt;2591237:ncbi:1 2591237:ncbi:1-40198    2971    -\nTAACATAGTGGTTCGTTTATCAAGGATAATCTATCTCCATAGGTTCTTCATCATCTAACTCTGAATATTTATTCTTAGTT\nTAACATAGTGGTTCGTTTATCAAGGATAATCTATCTCCATAGGTTCTTCATCATCTAACTCTGAATATTTATTCTTAGTT\n\n\n\nsource\n\nAlnFileReader\n\n AlnFileReader (path:str|pathlib.Path)\n\nIterator going through an ALN file\n\n\n\n\nType\nDetails\n\n\n\n\npath\nstr | Path\npath to the aln file\n\n\nReturns\ndict\nkey/value with keys:\n\n\n\n\naln = AlnFileReader(p2aln)\n\nAlnFileReader iterator returns elements one by one, as dictionaries with each data line related to the read, accessible through the following keys:\n\nkey 'definition line': read definition line, including read metadata\nkey 'ref_seq_aligned': aligned reference sequence, that is the sequence segment in the original reference corresponding to the read\nkey 'read_seq_aligned': aligned read, that is the simmulated read sequence, where each bp corresponds to the reference sequence bp in the same position.\n\n\none_iteration = next(aln)\none_iteration.keys()\n\ndict_keys(['definition line', 'ref_seq_aligned', 'read_seq_aligned'])\n\n\n\npprint(one_iteration)\n\n{'definition line': '&gt;2591237:ncbi:1\\t2591237:ncbi:1-40200\\t14370\\t+',\n 'read_seq_aligned': 'TTGTAGATGGTGTTCCTTTTGTTGTTTCAACTGGATACCATTTTCGTGAGTTAGGAGTTGTACATAATCAGGATGTAAACTTACATAGCTCGCGTCTCAGTTTCAAGGAACTTTTAGTGTATGCTGCTGATCCAGCCATGCATGCAGCTT',\n 'ref_seq_aligned': 'TTGTAGATGGTGTTCCTTTTGTTGTTTCAACTGGATACCATTTTCGTGAGTTAGGAGTTGTACATAATCAGGATGTAAACTTACATAGCTCGCGTCTCAGTTTCAAGGAACTTTTAGTGTATGCTGCTGATCCAGCCATGCATGCAGCTT'}\n\n\n\ndfn_line, ref_seq_aligned, read_seq_aligned = one_iteration.values()\n\n\ndfn_line\n\n'&gt;2591237:ncbi:1\\t2591237:ncbi:1-40200\\t14370\\t+'\n\n\n\nref_seq_aligned[:100]\n\n'TTGTAGATGGTGTTCCTTTTGTTGTTTCAACTGGATACCATTTTCGTGAGTTAGGAGTTGTACATAATCAGGATGTAAACTTACATAGCTCGCGTCTCAG'\n\n\n\nread_seq_aligned[:100]\n\n'TTGTAGATGGTGTTCCTTTTGTTGTTTCAACTGGATACCATTTTCGTGAGTTAGGAGTTGTACATAATCAGGATGTAAACTTACATAGCTCGCGTCTCAG'\n\n\n\nanother_iteration = next(aln)\npprint(another_iteration)\n\n{'definition line': '&gt;2591237:ncbi:1\\t2591237:ncbi:1-40199\\t15144\\t-',\n 'read_seq_aligned': 'TCATAGTACTACAGATAGAGACACCAGCTACGGTGCGAGCTCTATTCTTTGCACTAATGGCGTACTTAAGAGTCATTTGAGTTATAGTAGGGATGACATTACGCTTAGTATACGCGAAAAGTGCATCTTGATCCTCATAACTCATTGAGT',\n 'ref_seq_aligned': 'TCATAGTACTACAGATAGAGACACCAGCTACGGTGCGAGCTCTATTCTTTGCACTAATGGCGTACTTAAGATTCATTTGAGTTATAGTAGGGATGACATTACGCTTAGTATACGCGAAAAGTGCATCTTGATCCTCATAACTCATTGAGT'}\n\n\n\naln.reset_iterator()\nfor i, d in enumerate(aln):\n    print(d['definition line'])\n    print(d['ref_seq_aligned'][:80], '...')\n    print(d['read_seq_aligned'][:80], '...\\n')\n    if i &gt;= 3: break\n\n&gt;2591237:ncbi:1 2591237:ncbi:1-40200    14370   +\nTTGTAGATGGTGTTCCTTTTGTTGTTTCAACTGGATACCATTTTCGTGAGTTAGGAGTTGTACATAATCAGGATGTAAAC ...\nTTGTAGATGGTGTTCCTTTTGTTGTTTCAACTGGATACCATTTTCGTGAGTTAGGAGTTGTACATAATCAGGATGTAAAC ...\n\n&gt;2591237:ncbi:1 2591237:ncbi:1-40199    15144   -\nTCATAGTACTACAGATAGAGACACCAGCTACGGTGCGAGCTCTATTCTTTGCACTAATGGCGTACTTAAGATTCATTTGA ...\nTCATAGTACTACAGATAGAGACACCAGCTACGGTGCGAGCTCTATTCTTTGCACTAATGGCGTACTTAAGAGTCATTTGA ...\n\n&gt;2591237:ncbi:1 2591237:ncbi:1-40198    2971    -\nTAACATAGTGGTTCGTTTATCAAGGATAATCTATCTCCATAGGTTCTTCATCATCTAACTCTGAATATTTATTCTTAGTT ...\nTAACATAGTGGTTCGTTTATCAAGGATAATCTATCTCCATAGGTTCTTCATCATCTAACTCTGAATATTTATTCTTAGTT ...\n\n&gt;2591237:ncbi:1 2591237:ncbi:1-40197    15485   -\nTAATCACTGATAGCAGCATTGCCATCCTGAGCAAAGAAGAAGTGTTTTAGTTCAACAGAACTTCCTTCCTTAAAGAAACC ...\nTAATCACTGATAGCAGCATTGCCATCCTGAGCAAAGAAGAAGTGTTTTAGTTCAACAGAACTTCCTTCCTTAAAGAAACC ...\n\n\n\nOnce instantiated, the AlnFileReader iterator gives access to the file’s header information through header instance attribute. It is a dictionary with two keys: 'command' and 'reference sequences':\n    {'command':             'art-illumina command used to create the reads',\n     'reference sequences': ['@SQ metadata on reference sequence 1 used for the reads',\n                             '@SQ metadata on reference sequence 2 used for the reads', \n                             ...\n                            ]\n    }\n\nprint(aln.header['command'])\n\n/usr/bin/art_illumina -i /home/vtec/projects/bio/metagentools/data/ncbi/refsequences/cov/cov_refseq_001-seq1.fa -ss HS25 -l 150 -f 200 -o /home/vtec/projects/bio/metagentools/data/ncbi/simreads/cov/single_1seq_150bp/single_1seq_150bp -rs 1723893089\n\n\n\nfor seq_info in aln.header['reference sequences']:\n    print(seq_info)\n\n@SQ 2591237:ncbi:1  1   MK211378    2591237 ncbi    Coronavirus BtRs-BetaCoV/YN2018D    30213\n\n\nThe read definition line includes key metadata, which need to be parsed using the appropriate parsing rule.\n\nsource\n\n\nTextFileBaseReader.parse_text\n\n TextFileBaseReader.parse_text (txt:str, pattern:str=None,\n                                keys:list[str]=None)\n\n*Parse text using regex pattern and keys. Return a metadata dictionary.\nThe passed text is parsed using the regex pattern. The method return a dictionary in the format:\n{\n    'key_1': 'metadata 1',\n    'key_2': 'metadata 2',\n    ...\n}*\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\ntxt\nstr\n\ntext to parse\n\n\npattern\nstr\nNone\nIf None, uses standard regex pattern to extract metadata, otherwise, uses passed regex\n\n\nkeys\nlist\nNone\nIf None, uses standard regex list of keys, otherwise, uses passed list of keys (str)\n\n\nReturns\ndict\n\nparsed metadata in key/value format\n\n\n\n\naln.parse_text(dfn_line, pattern, keys)\n\n{'aln_start_pos': '14370',\n 'readid': '2591237:ncbi:1-40200',\n 'readnb': '40200',\n 'refseq_strand': '+',\n 'refseqid': '2591237:ncbi:1',\n 'refseqnb': '1',\n 'refsource': 'ncbi',\n 'reftaxonomyid': '2591237'}\n\n\n\nsource\n\n\nAlnFileReader.parse_definition_line_with_position\n\n AlnFileReader.parse_definition_line_with_position (dfn_line:str)\n\nParse definition line and adds relative position\n\n\n\n\n\n\n\n\n\nType\nDetails\n\n\n\n\ndfn_line\nstr\nfefinition line string to be parsed\n\n\nReturns\ndict\nparsed metadata in key/value format + relative position of the read\n\n\n\nUpon instance creation, AlnFileReader automatically checks the default_parsing_rules.json file for a workable rule among saved rules. Saved rules include the rule for ART Illumina ALN files.\n\naln.re_rule_name\n\n'aln_art_illumina_ncbi_std'\n\n\nIt is therefore not required to pass a specific pattern and keys parameter.\n\naln.parse_text(dfn_line)\n\n{'aln_start_pos': '14370',\n 'readid': '2591237:ncbi:1-40200',\n 'readnb': '40200',\n 'refseq_strand': '+',\n 'refseqid': '2591237:ncbi:1',\n 'refseqnb': '1',\n 'refsource': 'ncbi',\n 'reftaxonomyid': '2591237'}\n\n\nART Ilumina ALN files definition lines consist of:\n\nThe read ID: readid, e.g. 2591237:ncbi:1-20100\nthe read number (order in the file): readnb, e.g. 20100\nThe read start position in the reference sequence: aln_start_pos, e.g. 23878\nThe reference sequence ID: readid, e.g. 2591237:ncbi:1-20100\nThe reference sequence number: refseqnb, e.g. 1\nThe reference sequence source: refsource, e.g. ncbi\nThe reference sequence taxonomy: reftaxonomyid, e.g. 2591237\nThe reference sequence strand: refseq_strand wich is either + or -,\n\n\nsource\n\n\nAlnFileReader.parse_file\n\n AlnFileReader.parse_file (add_ref_seq_aligned:bool=False,\n                           add_read_seq_aligned:bool=False)\n\nRead ALN file, return a dict w/ alignment info for each read and optionaly aligned reference sequence & read\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nadd_ref_seq_aligned\nbool\nFalse\nAdd the reference sequence aligned to the parsed dictionary when True\n\n\nadd_read_seq_aligned\nbool\nFalse\nAdd the read sequence aligned to the parsed dictionary when True\n\n\nReturns\ndict[str]\n\n\n\n\n\n\nparsed = aln.parse_file()\n\nfor i, (k, v) in enumerate(parsed.items()):\n    print(k)\n    pprint(v)\n    if i &gt; 3: break\n\n2591237:ncbi:1-40200\n{'aln_start_pos': '14370',\n 'readid': '2591237:ncbi:1-40200',\n 'readnb': '40200',\n 'refseq_strand': '+',\n 'refseqid': '2591237:ncbi:1',\n 'refseqnb': '1',\n 'refsource': 'ncbi',\n 'reftaxonomyid': '2591237'}\n2591237:ncbi:1-40199\n{'aln_start_pos': '15144',\n 'readid': '2591237:ncbi:1-40199',\n 'readnb': '40199',\n 'refseq_strand': '-',\n 'refseqid': '2591237:ncbi:1',\n 'refseqnb': '1',\n 'refsource': 'ncbi',\n 'reftaxonomyid': '2591237'}\n2591237:ncbi:1-40198\n{'aln_start_pos': '2971',\n 'readid': '2591237:ncbi:1-40198',\n 'readnb': '40198',\n 'refseq_strand': '-',\n 'refseqid': '2591237:ncbi:1',\n 'refseqnb': '1',\n 'refsource': 'ncbi',\n 'reftaxonomyid': '2591237'}\n2591237:ncbi:1-40197\n{'aln_start_pos': '15485',\n 'readid': '2591237:ncbi:1-40197',\n 'readnb': '40197',\n 'refseq_strand': '-',\n 'refseqid': '2591237:ncbi:1',\n 'refseqnb': '1',\n 'refsource': 'ncbi',\n 'reftaxonomyid': '2591237'}\n2591237:ncbi:1-40196\n{'aln_start_pos': '16221',\n 'readid': '2591237:ncbi:1-40196',\n 'readnb': '40196',\n 'refseq_strand': '-',\n 'refseqid': '2591237:ncbi:1',\n 'refseqnb': '1',\n 'refsource': 'ncbi',\n 'reftaxonomyid': '2591237'}\n\n\n\nsource\n\n\nAlnFileReader.parse_header_reference_sequences\n\n AlnFileReader.parse_header_reference_sequences (pattern:str|None=None,\n                                                 keys:list[str]|None=None)\n\nExtract metadata from all header reference sequences\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\npattern\nstr | None\nNone\nregex pattern to apply to parse the reference sequence info\n\n\nkeys\nlist[str] | None\nNone\nlist of keys: keys are both regex match group names and corresponding output dict keys\n\n\nReturns\ndict[str]\n\nparsed metadata in key/value format\n\n\n\n\npprint(aln.parse_header_reference_sequences())\n\n{'2591237:ncbi:1': {'organism': 'Coronavirus BtRs-BetaCoV/YN2018D',\n                    'refseq_accession': 'MK211378',\n                    'refseq_length': '30213',\n                    'refseqid': '2591237:ncbi:1',\n                    'refseqnb': '1',\n                    'refsource': 'ncbi',\n                    'reftaxonomyid': '2591237'}}\n\n\n\nsource\n\n\nAlnFileReader.set_header_parsing_rules\n\n AlnFileReader.set_header_parsing_rules (pattern:str|bool=None,\n                                         keys:list[str]=None,\n                                         verbose:bool=False)\n\n*Set the regex parsing rule for reference sequence in ALN header.\nUpdates 3 class attributes: re_header_rule_name, re_header_pattern, re_header_keys\nTODO: refactor this and the method in Core: to use a single function for the common part and a parameter for the text_to_parse*\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\npattern\nstr | bool\nNone\nregex pattern to apply to parse the text, search in parsing rules json if None\n\n\nkeys\nlist[str]\nNone\nlist of keys/group for regex, search in parsing rules json if None\n\n\nverbose\nbool\nFalse\nwhen True, provides information on each rule\n\n\nReturns\nNone\n\n\n\n\n\n\naln.set_header_parsing_rules(verbose=True)\n\n--------------------------------------------------------------------------------\nRule &lt;fasta_ncbi_std&gt; generated an error\nNo match on this line\n--------------------------------------------------------------------------------\nRule &lt;fastq_art_illumina_ncbi_std&gt; generated an error\nNo match on this line\n--------------------------------------------------------------------------------\nRule &lt;aln_art_illumina_ncbi_std&gt; generated an error\nNo match on this line\n--------------------------------------------------------------------------------\nRule &lt;aln_art_illumina-refseq-ncbi-std&gt; generated 7 matches\n--------------------------------------------------------------------------------\n^@SQ[\\t\\s]*(?P&lt;refseqid&gt;(?P&lt;reftaxonomyid&gt;\\d*):(?P&lt;refsource&gt;\\w*):(?P&lt;refseqnb&gt;\\d*))[\\t\\s]*(?P=refseqnb)[\\t\\s]*(?P&lt;refseq_accession&gt;[\\w\\d]*)[\\t\\s]*(?P=reftaxonomyid)[\\t\\s]*(?P=refsource)[\\t\\s](?P&lt;organism&gt;.*)[\\t\\s](?P&lt;refseq_length&gt;\\d*)$\n['refseqid', 'reftaxonomyid', 'refsource', 'refseqnb', 'refseq_accession', 'organism', 'refseq_length']\n--------------------------------------------------------------------------------\nRule &lt;fasta_ncbi_cov&gt; generated an error\nNo match on this line\n--------------------------------------------------------------------------------\nRule &lt;fasta_rhinolophus_ferrumequinum&gt; generated an error\nNo match on this line\n--------------------------------------------------------------------------------\nSelected rule with most matches: aln_art_illumina-refseq-ncbi-std\n\n\n\nprint(aln.re_header_rule_name)\nprint(aln.re_header_pattern)\nprint(aln.re_header_keys)\n\naln_art_illumina-refseq-ncbi-std\n^@SQ[\\t\\s]*(?P&lt;refseqid&gt;(?P&lt;reftaxonomyid&gt;\\d*):(?P&lt;refsource&gt;\\w*):(?P&lt;refseqnb&gt;\\d*))[\\t\\s]*(?P=refseqnb)[\\t\\s]*(?P&lt;refseq_accession&gt;[\\w\\d]*)[\\t\\s]*(?P=reftaxonomyid)[\\t\\s]*(?P=refsource)[\\t\\s](?P&lt;organism&gt;.*)[\\t\\s](?P&lt;refseq_length&gt;\\d*)$\n['refseqid', 'reftaxonomyid', 'refsource', 'refseqnb', 'refseq_accession', 'organism', 'refseq_length']",
    "crumbs": [
      "CNN Virus",
      "data"
    ]
  },
  {
    "objectID": "cnn_virus_data.html#text-based-inference-datasets",
    "href": "cnn_virus_data.html#text-based-inference-datasets",
    "title": "data",
    "section": "Text based inference datasets",
    "text": "Text based inference datasets\nIn this pipeline, the steps are:\n\nCreate a text inference file and a metadata file from FASTQ and ALN with create_infer_ds_from_fastq\nCreate a tf.data.TextLineDataset from the text inference dataset\nTransform it into an inference/training dataset with .map and strings_to_tensors)\n\n\ndef _map_read_to_label(read, refseq_meta, p2mapping=None):\n    \"\"\"\"\"\"\n    if p2mapping is None:\n        p2mapping = PACKAGE_ROOT / 'data/ncbi/refsequences/taxonomyid-label-mapping.json'\n        assert p2mapping.is_file()\n\n\nsource\n\ncreate_infer_ds_from_fastq\n\n create_infer_ds_from_fastq (p2fastq:str|pathlib.Path,\n                             output_dir:str|pathlib.Path|None=None,\n                             overwrite_ds:bool=False,\n                             nsamples:int|None=None)\n\n*Build an inference dataset file as required by the CNN Virus model from a simreads fastq (ART format).\nAlso extract the fastq read sequence metadata, saves it in a metadata file and returns them as a DataFrame*\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\np2fastq\nstr | Path\n\nPath to the fastq file (aln file path is inferred)\n\n\noutput_dir\nstr | Path | None\nNone\nPath to directory where ds file will be saved\n\n\noverwrite_ds\nbool\nFalse\nIf True, overwrite existing ds file. If False, error is raised if ds file exists\n\n\nnsamples\nint | None\nNone\nUsed to limit the number of reads to use for inference, use all if None\n\n\nReturns\n(Path, Path, pd.DataFrame)\n\nPaths to dataset file, path to metadata file, dataframe with metadata\n\n\n\n\npath2ds, path2meta, meta = create_infer_ds_from_fastq(\n    p2fastq=p2fastq, \n    output_dir=pfs.data / 'ncbi/ds/cov',\n    overwrite_ds=True, \n    nsamples=100\n)\n\n\n\n\nDataset with 100 reads\n\n\n\nprint(f\"FASTAQ file name: {p2fastq.absolute()}\")\nprint(f\"Path to dataset:  {path2ds.absolute()} \\nPath to metadata: {path2meta.absolute()}\")\n\nFASTAQ file name: /home/vtec/projects/bio/metagentools/nbs-dev/data_dev/ncbi/simreads/cov/single_1seq_150bp/single_1seq_150bp.fq\nPath to dataset:  /home/vtec/projects/bio/metagentools/nbs-dev/data_dev/ncbi/ds/cov/single_1seq_150bp_ds \nPath to metadata: /home/vtec/projects/bio/metagentools/nbs-dev/data_dev/ncbi/ds/cov/single_1seq_150bp_metadata.csv\n\n\n\nTextFileBaseReader(path2ds, nlines=5).print_first_chunks(nchunks=1)\n\n5-line chunk 1\nTTGTAGATGGTGTTCCTTTTGTTGTTTCAACTGGATACCATTTTCGTGAGTTAGGAGTTGTACATAATCAGGATGTAAACTTACATAGCTCGCGTCTCAGTTTCAAGGAACTTTTAGTGTATGCTGCTGATCCAGCCATGCATGCAGCTT  0   0\nTCATAGTACTACAGATAGAGACACCAGCTACGGTGCGAGCTCTATTCTTTGCACTAATGGCGTACTTAAGAGTCATTTGAGTTATAGTAGGGATGACATTACGCTTAGTATACGCGAAAAGTGCATCTTGATCCTCATAACTCATTGAGT  0   0\nTAACATAGTGGTTCGTTTATCAAGGATAATCTATCTCCATAGGTTCTTCATCATCTAACTCTGAATATTTATTCTTAGTTAGAGGCTTAAATAACTGTCTCACTATTGAACTTATTATCATGTCAAGATTCCAAATAGCAATCCTGAAAG  0   0\nTAATCACTGATAGCAGCATTGCCATCCTGAGCAAAGAAGAAGTGTTTTAGTTCAACAGAACTTCCTTCCTTAAAGAAACCTTTAGACACAGCAAAGTCATAAAAGTCTTTGTTAAAATTACCGGGTTTGACAGTTTGAAAAGCAACATTG  0   0\nCTAATGTCAGTACGCCTACAATGCCTGCATCACGCATAGCATCGCAGAATTGTACAGTCTTTAATAATGCTTGGCGTACACGTTCACCTAAGTTAGCATATACGCGCAAGATGTCAGGATTCTCTACGAAGTCATACCAATCCTTCTTAT  0   0\n\n\n\n\nmeta.head()\n\n\n\n\n\n\n\n\nread_ids\nread_refseqs\nread_start_pos\nread_strand\n\n\n\n\n0\n2591237:ncbi:1-40200\n2591237:ncbi:1\n14370\n+\n\n\n1\n2591237:ncbi:1-40199\n2591237:ncbi:1\n15144\n-\n\n\n2\n2591237:ncbi:1-40198\n2591237:ncbi:1\n2971\n-\n\n\n3\n2591237:ncbi:1-40197\n2591237:ncbi:1\n15485\n-\n\n\n4\n2591237:ncbi:1-40196\n2591237:ncbi:1\n16221\n-\n\n\n\n\n\n\n\n\nsource\n\n\nstrings_to_tensors\n\n strings_to_tensors (b:tensorflow.python.framework.tensor.Tensor)\n\nFunction converting a batch of bp strings into three tensors: (x_seqs, (y_labels, y_pos))\n\n\n\n\nType\nDetails\n\n\n\n\nb\ntf.Tensor\nbatch of strings",
    "crumbs": [
      "CNN Virus",
      "data"
    ]
  },
  {
    "objectID": "cnn_virus_data.html#tfrecord-based-inference-datasets",
    "href": "cnn_virus_data.html#tfrecord-based-inference-datasets",
    "title": "data",
    "section": "TFRecord based inference datasets",
    "text": "TFRecord based inference datasets\nIn this pipeline, the steps are:\n\nGo from FASTQ and ALN to a RFRecord file and a metadata file with tfrecord_from_fastq or tfrecord_from_text\nCreate a tf.data.TFRecordDataset from the saved TFRecord file\nTransform it into an inference/training dataset with .map and tfr_to_tensors\n\n\nsource\n\nsplit_kmer_into_50mers\n\n split_kmer_into_50mers (kmer:tensorflow.python.framework.tensor.Tensor)\n\nConverts a k-mer read into several 50-mer reads, by shifting the k-mer one base at a time.\n\n\n\n\n\n\n\n\n\nType\nDetails\n\n\n\n\nkmer\ntf.Tensor\ntensor representing a single k-mer read, after base\n\n\n\n\nsource\n\n\nbase_string_kmers_to_tensors\n\n base_string_kmers_to_tensors\n                               (b:tensorflow.python.framework.tensor.Tenso\n                               r, k:int=50)\n\nFunction converting a batch of bp strings into three tensors: (x_seqs, (y_labels, y_pos))\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nb\ntf.Tensor\n\nbatch of strings\n\n\nk\nint\n50\nmaximum read length in the batch\n\n\n\n\nsource\n\n\nsplit_kmer_batch_into_50mers\n\n split_kmer_batch_into_50mers\n                               (kmer:tensorflow.python.framework.tensor.Te\n                               nsor)\n\n*Converts a batch of k-mer reads into several 50-mer reads, by shifting the k-mer one base at a time.\nfor a batch of b k-mer reads, returns a batch of b - 49 50-mer reads*\n\n\n\n\n\n\n\n\n\nType\nDetails\n\n\n\n\nkmer\ntf.Tensor\ntensor representing a batch of k-mer reads, after base encoding\n\n\n\n\nsource\n\n\ntfrecord_from_fastq\n\n tfrecord_from_fastq (p2fastq:pathlib.Path,\n                      p2tfrds:pathlib.Path|None=None,\n                      overwrite:bool=False)\n\n*Creates a TFRecord dataset for inference from fastq and aln files, as well as a csv metadata file\nThe TFRecord dataset can be used for training or prediction, using the original CNN Virus model. The metadata file is a Pandas DataFrame converted into csv*\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\np2fastq\nPath\n\nPath to the fastaq file (should be associated with a aln file)\n\n\np2tfrds\nPath | None\nNone\nPath to the TFRecord file, default creates a file in saved directory\n\n\noverwrite\nbool\nFalse\nWhen True, overides any existing file, When False, raises an error\n\n\nReturns\n(Path, Path)\n\nPaths to the saved TFRecord file and the metadata csv file\n\n\n\n\nsource\n\n\ntfrecord_from_text\n\n tfrecord_from_text (p2ds, p2tfrds:pathlib.Path|None=None,\n                     overwrite:bool=False)\n\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\np2ds\n\n\nPath to the text dataset, in the format of original CNN Virus data\n\n\np2tfrds\nPath | None\nNone\nPath to the TFRecord file, default creates a file in savec directory\n\n\noverwrite\nbool\nFalse\nWhen True, overides any existing file, When False, raises an error\n\n\nReturns\nPath\n\nPath to the saved TFRecord file\n\n\n\n\nsource\n\n\nget_dataset_from_tfr\n\n get_dataset_from_tfr (p2tfrds:pathlib.Path, batch_size:int=1)\n\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\np2tfrds\nPath\n\nPath to the TFRecord dataset\n\n\nbatch_size\nint\n1\nDesired batch side for the dataset\n\n\nReturns\ntf.data.Dataset\n\ndataset, formated with the batch size\n\n\n\nCreate a dataset from an existing TFRecord file\n\n# TODO: Check how to define shape of the elements\np2ds = pfs.data / 'ncbi/ds/cov/single_1seq_50bp-10reads.tfrecords'\nassert p2ds.exists()\nds = get_dataset_from_tfr(p2ds)\nds.element_spec\n\n(TensorSpec(shape=&lt;unknown&gt;, dtype=tf.float32, name=None),\n (TensorSpec(shape=&lt;unknown&gt;, dtype=tf.float32, name=None),\n  TensorSpec(shape=&lt;unknown&gt;, dtype=tf.float32, name=None)))\n\n\n\nfor r, (l, p) in ds.take(8):\n    print(r.shape, l.shape, p.shape)\n\n(1, 50, 5) (1, 187) (1, 10)\n(1, 50, 5) (1, 187) (1, 10)\n(1, 50, 5) (1, 187) (1, 10)\n(1, 50, 5) (1, 187) (1, 10)\n(1, 50, 5) (1, 187) (1, 10)\n(1, 50, 5) (1, 187) (1, 10)\n(1, 50, 5) (1, 187) (1, 10)\n(1, 50, 5) (1, 187) (1, 10)\n\n\nWe can convert this dataset into a batch dataset\n\nds_batched = ds.batch(2)\nfor r, (l, p) in ds_batched.take(8):\n    print(r.shape, l.shape, p.shape)\n\n(2, 1, 50, 5) (2, 1, 187) (2, 1, 10)\n(2, 1, 50, 5) (2, 1, 187) (2, 1, 10)\n(2, 1, 50, 5) (2, 1, 187) (2, 1, 10)\n(2, 1, 50, 5) (2, 1, 187) (2, 1, 10)\n(2, 1, 50, 5) (2, 1, 187) (2, 1, 10)",
    "crumbs": [
      "CNN Virus",
      "data"
    ]
  },
  {
    "objectID": "cnn_virus_data.html#postprocessing",
    "href": "cnn_virus_data.html#postprocessing",
    "title": "data",
    "section": "Postprocessing",
    "text": "Postprocessing\n\nsource\n\ncombine_predictions\n\n combine_predictions (labels:tensorflow.python.framework.tensor.Tensor,\n                      label_probs:tensorflow.python.framework.tensor.Tenso\n                      r,\n                      positions:tensorflow.python.framework.tensor.Tensor)\n\nCombine set of 50-mer predictions into one final prediction for label and position\n\n\n\n\n\n\n\n\n\nType\nDetails\n\n\n\n\nlabels\ntf.Tensor\nLabel predictions for a set of 50-mer corresponding to a single k-mer\n\n\nlabel_probs\ntf.Tensor\nProbabilities for the labels\n\n\npositions\ntf.Tensor\nPosition predictions for a set of 50-mer corresponding to a single k-mer\n\n\n\n\nsource\n\n\ncombine_prediction_batch\n\n combine_prediction_batch (probs_elements:tuple[tensorflow.python.framewor\n                           k.tensor.Tensor,tensorflow.python.framework.ten\n                           sor.Tensor])\n\n*Combine a batch of 50-mer probabilities into one batch of final prediction for label and position\nNote: the input must be reshape to (batch_size, k, n) where n is the number of labels or positions*\n\n\n\n\n\n\n\n\n\nType\nDetails\n\n\n\n\nprobs_elements\ntuple[tf.Tensor, tf.Tensor]\nTuple of label and position probabilities for a batch of 50-mer",
    "crumbs": [
      "CNN Virus",
      "data"
    ]
  },
  {
    "objectID": "art.html",
    "href": "art.html",
    "title": "art",
    "section": "",
    "text": "ART is an open source package simmulation next generation read of genomes, available on the website of the National Institute of Environmental Health Sciences here. It is a command line interface package. This module makes the package accessible from a jupyter notebook\nTypical usage\n\nread simulation with paired reads:\n\nart_illumina -ss HS25 -sam -i file.fa -p -l 150 -f 20 -m 200 -s 10 -o paired_seq_1\n\nread simulation with single reads:\n\nart_illumina -ss HS25 -sam -i file.fa -l 150 -f 10 -o single_seq_1\n\n\nWhere the parameters are:\n  -f   --fcov   the fold of read coverage to be simulated or number of reads/read pairs generated for each amplicon\n  -i   --in     the filename of input DNA/RNA reference\n  -l   --len    the length of reads to be simulated\n  -m   --mflen  the mean size of DNA/RNA fragments for paired-end simulations\n  -o   --out    the prefix of output filename\n  -p   --paired indicate a paired-end read simulation or to generate reads from both ends of amplicons\n                NOTE: art will automatically switch to a mate-pair simulation if the given mean fragment size &gt;= 2000\n  -s   --sdev   the standard deviation of DNA/RNA fragment size for paired-end simulations.\n  -sam --samout indicate to generate SAM alignment file\n  -ss  --seqSys The name of Illumina sequencing system of the built-in profile used for simulation\n                NOTE: sequencing system ID names are:\n                GA1 - GenomeAnalyzer I (36bp,44bp), GA2 - GenomeAnalyzer II (50bp, 75bp)\n                HS10 - HiSeq 1000 (100bp),          HS20 - HiSeq 2000 (100bp),      HS25 - HiSeq 2500 (125bp, 150bp)\n                HSXn - HiSeqX PCR free (150bp),     HSXt - HiSeqX TruSeq (150bp),   MinS - MiniSeq TruSeq (50bp)\n                MSv1 - MiSeq v1 (250bp),            MSv3 - MiSeq v3 (250bp),        NS50 - NextSeq500 v2 (75bp)\nNotes:\n\nFor single-end simulation, ART requires input sequence file, output file prefix, read length, and read count/fold coverage.\nFor paired-end simulation (except for amplicon sequencing), ART also requires the parameter values of the mean and standard deviation of DNA/RNA fragment lengths\n\n\nsource\n\nArtIllumina\n\n ArtIllumina (path2app:str|pathlib.Path, input_dir:str|pathlib.Path,\n              output_dir:str|pathlib.Path=None,\n              app_in_system_path:bool=False)\n\nClass to handle all aspects of simulating sequencing with art_illumina\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\npath2app\nstr | pathlib.Path\n\nfull path to art_illumina application on the system\n\n\ninput_dir\nstr | pathlib.Path\n\nfull path to dir where input files are\n\n\noutput_dir\nstr | pathlib.Path\nNone\nfull path to dir where to save output files, if different from input_dir\n\n\napp_in_system_path\nbool\nFalse\nwhether art_illumina is in the system path or not\n\n\n\n\nUsage\n\nCreate an instance of ArtIllumina\nRun a simulation\nExport output files\n\nCreate an instance of ArtIllumina with: - the path to the application on the local system - the directories for input and output files (optional)\n\np2art = Path('/bin/art_illumina')\np2data = Path('data_dev')\n\n\nart = ArtIllumina(\n    path2app=p2art,\n    input_dir=p2data,\n    )\n\nReady to operate with art: /bin/art_illumina\nInput files from : /home/vtec/projects/bio/metagentools/nbs-dev/data_dev\nOutput files to :  /home/vtec/projects/bio/metagentools/nbs-dev/data_dev\n\n\n\nnbdev.show_doc(ArtIllumina.sim_reads)\n\n\nsource\n\nArtIllumina.sim_reads\n\n ArtIllumina.sim_reads (input_file:str, output_seed:str,\n                        sim_type:str='single', read_length:int=150,\n                        fold:int=10, mean_read:int=None,\n                        std_read:int=None, ss:str='HS25',\n                        overwrite:bool=False, print_output:bool=True)\n\nSimulates reads with art_illumina. Output files saved in a separate directory\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\ninput_file\nstr\n\nname of the fasta file to use as input\n\n\noutput_seed\nstr\n\nseed to use for the output files\n\n\nsim_type\nstr\nsingle\ntype of read simmulation: ‘single’ or ‘paired’\n\n\nread_length\nint\n150\nlength of the read in bp\n\n\nfold\nint\n10\nfold\n\n\nmean_read\nint\nNone\nmean length of the read for paired reads\n\n\nstd_read\nint\nNone\nstd of the read length, for paired reads\n\n\nss\nstr\nHS25\nquality profile to use for simulation,\n\n\noverwrite\nbool\nFalse\noverwrite existing output files if true, raise error if false\n\n\nprint_output\nbool\nTrue\nif True, prints art ilumina’s CLI output\n\n\n\n\n\n\n\n\nRun a single read simulations\n\nProvide an input file and a seed for the names of the output files\nPrints out the log messages issued by art_illumina\n\n\ninput_fname = 'cov_virus_sequence_one.fa'\noutput_seed = 'single_1seq_150bp'\n\nart.sim_reads(\n    input_file=input_fname,\n    output_seed=output_seed,\n    sim_type=\"single\",\n    read_length=150,\n    fold=100,\n    overwrite=True\n)\n\nreturn code:  0 \n\n\n    ====================ART====================\n             ART_Illumina (2008-2016)          \n          Q Version 2.5.8 (June 6, 2016)       \n     Contact: Weichun Huang &lt;whduke@gmail.com&gt; \n    -------------------------------------------\n\n                  Single-end Simulation\n\nTotal CPU time used: 0.813896\n\nThe random seed for the run: 1723274635\n\nParameters used during run\n    Read Length:    150\n    Genome masking 'N' cutoff frequency:    1 in 150\n    Fold Coverage:            100X\n    Profile Type:             Combined\n    ID Tag:                   \n\nQuality Profile(s)\n    First Read:   HiSeq 2500 Length 150 R1 (built-in profile) \n\nOutput files\n\n  FASTQ Sequence File:\n    /home/vtec/projects/bio/metagentools/nbs-dev/data_dev/single_1seq_150bp/single_1seq_150bp.fq\n\n  ALN Alignment File:\n    /home/vtec/projects/bio/metagentools/nbs-dev/data_dev/single_1seq_150bp/single_1seq_150bp.aln\n\n\n\n\nRun a paired read simulations with the input file.\n\nart.print_last_output_file_excerpts()\n\n========================================================================================================================\nFile Name: single_1seq_150bp.fq.\n--------------------------------------------------------------------------------\n@2591237:ncbi:1-20100\nAAACCATCTTCTCGAAAGCTTCAGTTGTGTCTTTTGCAAGAAGAATATCATTGTGGAGTTGTACACATTGTGCCCACAATTTAGAAGATGACTCTACTCTAAGTTGTTGAAGAACCGAGAGCATTACCACAGATGTGCACTTTACGTCAG\n+\nCCCGCCGGGCGGCJJGJJJGGGJJ8JGGGGJGJGGGJJJCJJJJGGJJJGJCGGJGJJJCCGGC=GCG==GGJCGCGGGGGGGCCCGGCG=GCGGGGGG8JCGGGCCCGCGCGCG(GGGGG8CCGGGGGGGGGCGGGGGGCGCGGGG=CG\n@2591237:ncbi:1-20099\nTCGTACTCCGCGTGGCCTCGGTGAAAATGTGGTGGCTCTTTCAAGTCCTCCCTAATGTTACACATTGATTAAAGATTGCTATGTGAGATTAAAGTTAACTAAACCTACTTGTGCTGTTTAGCTACGAGAATTCATTCTGCACAAGAGTAG\n+\nCC=GGCGGGCGGGGJJJGJJJJJJGJJJJJJJJJGJJJJGJG=JJJGC8JJJJGJJGGGJGJG=GGGGGGGCGG1GGGGGCGG=GC(CGGGCGCC1G=CCJ8CGGGGCGGGCGCCGGCG=GGCCCGC1GGCCGGGG=GGGGGCGGGC8GC\n@2591237:ncbi:1-20098\nTTCTTGGCTCACCTTCAATGGTTTGCCATGTTTTCTCCTATTGTGCCTTTTTGGATAACAGCAATCTATGTATTCTGTATTTCTCTGAAGCACTGCCATTGGTTCTTTAACAACTATCTTAGGAAAAGAGTCATGTTTAATGGAGTTACA\n+\nCCCGGCGGGGGGGGJJJJJCGJJCJJGJGCJJGJJJJCGJJJ=GJJGJGJJJGJJCGCJJCGGGGCGGGGCCGCGGCGCGG8GGGCGCGGCGGGCGGGG=CGCG(GCCGG8CGG8CGGGCGGGCC==GGG11CCGCGCGGGGGC8GGGG=\n\n\n\n\ninput_fname = 'cov_virus_sequence_one.fa'\n\nart.sim_reads(\n    input_file=input_fname,\n    output_seed='paired_1seq_150bp',\n    sim_type=\"paired\",\n    read_length=150,\n    fold=100,\n    mean_read=200,\n    std_read=10,\n    overwrite=True\n)\n\nreturn code:  0 \n\n\n    ====================ART====================\n             ART_Illumina (2008-2016)          \n          Q Version 2.5.8 (June 6, 2016)       \n     Contact: Weichun Huang &lt;whduke@gmail.com&gt; \n    -------------------------------------------\n\n                  Paired-end sequencing simulation\n\nTotal CPU time used: 0.785862\n\nThe random seed for the run: 1723274637\n\nParameters used during run\n    Read Length:    150\n    Genome masking 'N' cutoff frequency:    1 in 150\n    Fold Coverage:            100X\n    Mean Fragment Length:     200\n    Standard Deviation:       10\n    Profile Type:             Combined\n    ID Tag:                   \n\nQuality Profile(s)\n    First Read:   HiSeq 2500 Length 150 R1 (built-in profile) \n    First Read:   HiSeq 2500 Length 150 R2 (built-in profile) \n\nOutput files\n\n  FASTQ Sequence Files:\n     the 1st reads: /home/vtec/projects/bio/metagentools/nbs-dev/data_dev/paired_1seq_150bp/paired_1seq_150bp1.fq\n     the 2nd reads: /home/vtec/projects/bio/metagentools/nbs-dev/data_dev/paired_1seq_150bp/paired_1seq_150bp2.fq\n\n  ALN Alignment Files:\n     the 1st reads: /home/vtec/projects/bio/metagentools/nbs-dev/data_dev/paired_1seq_150bp/paired_1seq_150bp1.aln\n     the 2nd reads: /home/vtec/projects/bio/metagentools/nbs-dev/data_dev/paired_1seq_150bp/paired_1seq_150bp2.aln\n\n\n\n\n\nart.print_last_output_file_excerpts()\n\n========================================================================================================================\nFile Name: paired_1seq_150bp2.fq.\n--------------------------------------------------------------------------------\n@2591237:ncbi:1-20100/2\nTTAGGATTAAGCATGTCTTCTGCTGTGCAAATGACATGTCTTGGACAGTATACTGAGTCATCTAACCACAATCCATTAAGAGTTGTAGTTCCACAGGTTACTTGTACCATGCACACTTCAACTTTGCCTGATGGGAATGCCATTTTCCTA\n+\nCCCGGGGGGGGG1JGJ=GJGGJJGJJJGJJJCJGJJJJJGGCJGJJJJ=G8G=JJ(JGGGCGJJCGGG=G(GGGGCGGJGC18C1GC1CGGCCG=C8G8CC8CJJ=JCGGGGGG1GGCGGGGCGCCCC=CCCCGG=GGCGGCCGCCG=GC\n@2591237:ncbi:1-20098/2\nGACTTGAAAGGTAAGTACGTCCAAATACCTACCACTTGTGCTAATGACCCAGTTGGTTTTACACTTAGAAACACAGTCTGTACCGTCTGCGGAATGTGGAAAGGTTATGGCTGTAGTTGTGATCAACTCCGCGAACCCATGATGCAGTCT\n+\nC=CGGGGGGGGGCJGCJJCJGJJGCJGJJJJG8JGJJJGJ=JJCCGGJJGGCC(GCJJJGGGGGCJC=GGGGCGGG8C=GGG8GGCGC=GGGC8GGGGGGCCCJ88==CC8GG=CCGCGGG8CC=GGGGGGGGGCGGGGGGGGC=GGGC1\n@2591237:ncbi:1-20096/2\nCAGCATCTGGTGATGATACTGACACTACGGCAGGAGCTTTAAGAGAACGCATACAGCGCGCAGCCTCTTCAAGATTAAAACCATGTGTCACATAACCAATTCGCATTGTGACAAGTGGCTCATTTAGAGAGTTCAGCTTCGTAATGATAG\n+\nCCCGGGGGGGGGCGJJGJGGGCJJJGJJJJCJJJGJGJ=JCJJCJJJ=CGGGG=JJGGGGCG=GGCGGJGG1GCCGGCG=GCGGCCGGGG88G=GGC=GCG(CCCJC=GGC8CGGGGCCG=CGGGGCGGG88GCC1GG=CGCCGGCCGCG\n\n========================================================================================================================\nFile Name: paired_1seq_150bp1.fq.\n--------------------------------------------------------------------------------\n@2591237:ncbi:1-20100/1\nCTACCAACCACCACAGACATCAATCACTTCTGCTGTTCTGCAGAGTGGTTTTAGGAAAATGGCATTCCCATCAGGCAAAGTTGAAGGGTGCATGGTACAAGTAACCTGTGGAACTACAACTCTTAATGGATTGTGGTTAGATGACACAGT\n+\nCCCGCCGGGGG=GGJJJ(JJJJJJGJGGJGJCJJJJCGCJ(J8CCJJJJJCGJGGJJG=JJGJCGGGGJGGJGG=JGGGGGGGCCCC=GCGGGGGGCGGCJC=CCCCGCGGGGG=GGCGGGGCCCCGGGGGCCGGG1GCCGG(G=CCGCC\n@2591237:ncbi:1-20098/1\nCGGGCTGCACTTACACCGCAAACCCGTTTAAAAACGTTGACGCATCCGCAGACTGCATCATGGGTTCGCGGAGTTGATCACAACTACAGCCATAACCTTTCCACATTCCGCAGACGGTACAGACTGTGTTTCTAAGTGTAAAACCCACTG\n+\nCCC1CCGGG==GGCCJJ1JJJCJGJJGGJGCGJJGJJ8GG=GJJGJCGJJ=JJJJG=CJJGJCCCGJGGC=GGG=GGCGGGGCGGCCGC=GGGGGCCGGGJGCCGCGGGGCGGGCCGGGGGCGGGCGCGCGGCG8GCGGGGG8CCCGGGC\n@2591237:ncbi:1-20096/1\nTTCAAGAAGGCATTGTTGACTATGGAGTCCGATTCTTCTTTTATACTAGTAAAGAGCCTGTAGCTTCTATCATTACGAAGCTGAACTCTCTAAATGAGCCACTTGTCACAATGCCAATTGGTTATGTGACACATGGTTTTAATCTTGAAG\n+\n8CCGGGGCGCGGGGJJCJGG=JJGJJJJJJJJGGJJJJJCJJJJCJGCGGGGG(GJGGJCGCJGGGGJ=GCGGJGGGGGGCCCGCGGGCCGGGGCGCGGCJGGCGCGGCGCGGCCGGGGCGCGGG1C8G8CGGCGGGGCGGCCGGCCGGC\n\n\n\n\nart.list_all_output_files()\n\npaired_1seq_150bp\n- paired_1seq_150bp2.aln\n- paired_1seq_150bp2.fq\n- paired_1seq_150bp1.fq\n- paired_1seq_150bp1.aln\nsingle_1seq_150bp\n- single_1seq_150bp.fq\n- single_1seq_150bp.aln",
    "crumbs": [
      "General Code",
      "art"
    ]
  },
  {
    "objectID": "bio.html",
    "href": "bio.html",
    "title": "bio",
    "section": "",
    "text": "FASTA is a standard format to store genetic sequences.\n\n\nFASTA files count two lines for each sequence (see reference on NCBI site):\n\nline 1: the fasta definition line starting with &gt; and a unique identifier, followed by optional additional information.\nline 2: the sequence line: TATTAGGTTTTCTACCTACCCAGGAAAAGCCAACCA ...\n\nThe format of the definition line varies from data source to data source.\nExample:\n    &gt;MCHU - Calmodulin - Human, rabbit, bovine, rat, and chicken\n    MADQLTEEQIAEFKEAFSLFDKDGDGTITTKELGTVMRSLGQNPTEAELQDMINEVDADGNGTIDFP ....\n\n\n\n\nIn this project, we use read sequences from NextGen sequencing tools as well as read sequences simulated using the ART Illumina simulator tool.\nNextGen sequencing tools most often store read sequences in a FASTQ format.\nART Illumina simulator tool outputs both a FASTQ file and an alignment file (ALN) providing information on the original reference sequence it was simulated from. ALN files are also referred to as Clustal Alignnent format.\n\n\nA FASTQ file contains one 4-line block for each read. It includes a readID, followed by both the read sequence and a quality scores, in the following format:\n    @readid \n    sequence_read \n    + \n    base_quality_scores \nExample:\n    @2591237:ncbi:1-60400\n    ACAACTCCTATTCGTAGTTGAAGTTGTTGACAAATACTTTGATTGTTACG\n    +\n    CCCBCGFGBGGGGGGGBGGGGGGGGG&gt;GGG1G=/GGGGGGGGGGGGGGGG\nFor each base in the read sequence, a base quality score is coded by an ASCII character. They are Q Scores or Phred+33 encoded, where the quality score is equal to ASCII code of the character minus 33.\n\nReference information:\n\nART Illumina README file\nIllumina site\n\n\nInformation extraction\nThe following metadata information can be parsed from FASTQ generated by ART Illumina:\nFASTQ file element:\n    @2591237:ncbi:1-60400\n    ACAACTCCTATTCGTAGTTGAAGTTGTTGACAAATACTTTGATTGTTACG\n    +\n    CCCBCGFGBGGGGGGGBGGGGGGGGG&gt;GGG1G=/GGGGGGGGGGGGGGGG\n\nreadid, e.g. 2591237:ncbi:1-60400.\nread_sequence itself, e.g. ACAACTCCTATTCGTAGTTGAAGTTGTTGACAAATACTTTGATTGTTACG\nbase_quality_score, the Q Score in ASCII, e.g. CCCBCGFGBGGGGGGGBGGGGGGGGG&gt;GGG1G=/GGGGGGGGGGGGGGGG\n\nFurthermore, the following metadata can be parsed from the first line:\n- `refseqid` of the original sequence used for the read, e.g. `2591237:nbci-1`\n- `read_nbr` of the read, e.g. `1-60400\n\n\n\nAn alignment file in ALN format has a Header and main Body parts.\nThe header part includes the command used to generate this file and reference sequence id and length. The header @CM tag for command line, and @SQ for reference sequence.\nA Header always starts with ##ART and ends with ##Header End.\nHeader example, for ALN file generated by ART Illumina:\n    ##ART_Illumina  read_length 50\n    @CM /bin/art_illumina -i /home/vtec/projects/bio/metagentools/data/cov_data/cov_virus_sequences_ten.fa -ss HS25 -l 50 -f 100 -o /home/vtec/projects/bio/metagentools/data/cov_simreads/single_10seq_50bp/single_10seq_50bp -rs 1674660835\n    @SQ 2591237:ncbi:1 [MK211378]   2591237 ncbi    1 [MK211378] 2591237    Coronavirus BtRs-BetaCoV/YN2018D    30213\n    @SQ 11128:ncbi:2 [LC494191] 11128   ncbi    2 [LC494191] 11128  Bovine coronavirus      30942\n    @SQ 31631:ncbi:3 [KY967361] 31631   ncbi    3 [KY967361] 31631  Human coronavirus OC43      30661\n    ##Header End\nFor each reference sequence used to build the reads, we can parse the following metadata info:\n    refseqid:       2591237:ncbi:1\n    ref_seq_length: 30213\nThe Body part contains each read’s alignments in the following format:\n    &gt;refseqid   read_id   aln_start_pos    ref_seq_strand\n    ref_seq_aligned\n    read_seq_aligned \n\naln_start_pos is the alignment start position of the read in the reference sequence.\nref_seq_aligned is the aligned region of reference sequence, which can be from plus strand or minus strand of the reference sequence.\n\nread_seq_aligned is the aligned sequence read, which always in the same orientation of the same read in the corresponding fastq file.\n\naln_start_pos is always relative to the strand of reference sequence. That is, aln_start_pos 10 in the plus (+) strand is different from aln_start_pos 10 in the minus (‐) stand.\nBody example:\n    &gt;2591237:ncbi:1 2591237:ncbi:1-60400    14770   +\n    ACAACTCCTATTCGTAGTTGAAGTTGTTGACAAATACTTTGATTGTTACG\n    ACAACTCCTATTCGTAGTTGAAGTTGTTGACAAATACTTTGATTGTTACG\n    refseqid:          2591237:ncbi:1\n    readid:            2591237:ncbi:1-20100\n    aln_start_pos:     23878\n    ref_seq_strand:    -\n    ref_seq_aligned:   ACAACTCCTATTCGTAGTTGAAGTTGTTGACAAATACTTTGATTGTTACG\n    read_seq_aligned:  ACAACTCCTATTCGTAGTTGAAGTTGTTGACAAATACTTTGATTGTTACG\n\nReference information:\n\nART Illumina README file\nIllumina site\n\n\nThe quality score of a base, also known as a Phred or Q score, is an integer value representing the estimated probability of an error, i.e. the probability that the base is incorrectly sequenced.\nIf \\(P\\) is the error probability and \\(Q\\) is the quality score for a base, then:\n\n\\(P = 10^{-Q/10}\\)\n\\(Q = -10 \\log_{10}(P)\\)\n\nQ scores are often represented as ASCII characters. The rule for converting an ASCII character to an integer varies.\nThe two tables below convert between integer Q scores, ASCII characters and error probabilities.\nASCII_BASE = 33 (table on top) is now almost universally used. In older systems, ASCII_BASE = 64 is also used.\n\n\n\nimage.png\n\n\n(See reference here)\n\n\n\nASCII character is K\nASCII code is 75\nQ score: $Q = 75 - $ \\(= 75 - 33 = 42\\)\nP_error = \\(P = 10^{-Q/10}\\), i.e. \\(10^{-42/10}\\) = 0.00006\n\n\nPython note:\nDecode an ASCII character with ord(c) and encode it with chr(i)\n\n\nord('!'), chr(33), ord('K'), chr(75)\n\n(33, '!', 75, 'K')\n\n\n\nsource\n\n\n\n\n\n q_score2prob_error (char:str, ASCII_base:int=33)\n\nReturn the probability of error for a given Q score encoded as ASCII character\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nchar\nstr\n\nASCII character retrieved from Q Score or Phred value in FASTQ\n\n\nASCII_base\nint\n33\nASCII base. Mostly 33, can be 64 in old FASTQ files\n\n\n\n\n\nSelection of high Q score ASICC code, Q score values and corresponding P error:\nASCII Q Score | Q Score | P error\n--------------|---------|--------\n      K       |   42    | 0.00006 \n      J       |   41    | 0.00008 \n      I       |   40    | 0.00010 \n      H       |   39    | 0.00013 \n      G       |   38    | 0.00016 \n      F       |   37    | 0.00020 \n      E       |   36    | 0.00025 \n      D       |   35    | 0.00032 \n      C       |   34    | 0.00040 \n      B       |   33    | 0.00050 \n      A       |   32    | 0.00063 \n      @       |   31    | 0.00079 \n      ?       |   30    | 0.00100 \n      &gt;       |   29    | 0.00126 \n      =       |   28    | 0.00158 \n\n\nIn the case of the following FASTQ file:\n    @2591237:ncbi:1-60400\n    ACAACTCCTATTCGTAGTTGAAGTTGTTGACAAATACTTTGATTGTTACG\n    +\n    CCCBCGFGBGGGGGGGBGGGGGGGGG&gt;GGG1G=/GGGGGGGGGGGGGGGG\nThe following metadata information can be parsed:\n\nread_id, e.g. 2591237:ncbi:1-60400. The following information can be parsed:\n\nref_seq_id of the original sequence used for the read, e.g. 2591237:nbci-1\nread_nbr of the read, e.g. `60400\n\nsequence_read itself, e.g. ACAACTCCTATTCGTAGTTGAAGTTGTTGACAAATACTTTGATTGTTACG\nbase_quality_score, the Q Score in ASCII, e.g. CCCBCGFGBGGGGGGGBGGGGGGGGG&gt;GGG1G=/GGGGGGGGGGGGGGGG\n\nThis ASCII encoded Q Score can be converted into probability of error for each bp in the read:\n\nq_scores = 'CCCBCGFGBGGGGGGGBGGGGGGGGG&gt;GGG1G=/GGGGGGGGGGGGGGGG'\nnum_scores = [f\"{q_score2prob_error(char):6.5f}\" for char in q_scores]\nprint('; '.join(num_scores))\nprint(f\"Maximum error probability: {max(num_scores)}\")\n\n0.00040; 0.00040; 0.00040; 0.00050; 0.00040; 0.00016; 0.00020; 0.00016; 0.00050; 0.00016; 0.00016; 0.00016; 0.00016; 0.00016; 0.00016; 0.00016; 0.00050; 0.00016; 0.00016; 0.00016; 0.00016; 0.00016; 0.00016; 0.00016; 0.00016; 0.00016; 0.00126; 0.00016; 0.00016; 0.00016; 0.02512; 0.00016; 0.00158; 0.03981; 0.00016; 0.00016; 0.00016; 0.00016; 0.00016; 0.00016; 0.00016; 0.00016; 0.00016; 0.00016; 0.00016; 0.00016; 0.00016; 0.00016; 0.00016; 0.00016\nMaximum error probability: 0.03981\n\n\nIt shows that most bp have a very low probability of error, except a few bp with probability or 2.5% and 3.9%,",
    "crumbs": [
      "General Code",
      "bio"
    ]
  },
  {
    "objectID": "bio.html#sequence-file-formats",
    "href": "bio.html#sequence-file-formats",
    "title": "bio",
    "section": "",
    "text": "FASTA is a standard format to store genetic sequences.\n\n\nFASTA files count two lines for each sequence (see reference on NCBI site):\n\nline 1: the fasta definition line starting with &gt; and a unique identifier, followed by optional additional information.\nline 2: the sequence line: TATTAGGTTTTCTACCTACCCAGGAAAAGCCAACCA ...\n\nThe format of the definition line varies from data source to data source.\nExample:\n    &gt;MCHU - Calmodulin - Human, rabbit, bovine, rat, and chicken\n    MADQLTEEQIAEFKEAFSLFDKDGDGTITTKELGTVMRSLGQNPTEAELQDMINEVDADGNGTIDFP ....",
    "crumbs": [
      "General Code",
      "bio"
    ]
  },
  {
    "objectID": "bio.html#read-files",
    "href": "bio.html#read-files",
    "title": "bio",
    "section": "",
    "text": "In this project, we use read sequences from NextGen sequencing tools as well as read sequences simulated using the ART Illumina simulator tool.\nNextGen sequencing tools most often store read sequences in a FASTQ format.\nART Illumina simulator tool outputs both a FASTQ file and an alignment file (ALN) providing information on the original reference sequence it was simulated from. ALN files are also referred to as Clustal Alignnent format.\n\n\nA FASTQ file contains one 4-line block for each read. It includes a readID, followed by both the read sequence and a quality scores, in the following format:\n    @readid \n    sequence_read \n    + \n    base_quality_scores \nExample:\n    @2591237:ncbi:1-60400\n    ACAACTCCTATTCGTAGTTGAAGTTGTTGACAAATACTTTGATTGTTACG\n    +\n    CCCBCGFGBGGGGGGGBGGGGGGGGG&gt;GGG1G=/GGGGGGGGGGGGGGGG\nFor each base in the read sequence, a base quality score is coded by an ASCII character. They are Q Scores or Phred+33 encoded, where the quality score is equal to ASCII code of the character minus 33.\n\nReference information:\n\nART Illumina README file\nIllumina site\n\n\nInformation extraction\nThe following metadata information can be parsed from FASTQ generated by ART Illumina:\nFASTQ file element:\n    @2591237:ncbi:1-60400\n    ACAACTCCTATTCGTAGTTGAAGTTGTTGACAAATACTTTGATTGTTACG\n    +\n    CCCBCGFGBGGGGGGGBGGGGGGGGG&gt;GGG1G=/GGGGGGGGGGGGGGGG\n\nreadid, e.g. 2591237:ncbi:1-60400.\nread_sequence itself, e.g. ACAACTCCTATTCGTAGTTGAAGTTGTTGACAAATACTTTGATTGTTACG\nbase_quality_score, the Q Score in ASCII, e.g. CCCBCGFGBGGGGGGGBGGGGGGGGG&gt;GGG1G=/GGGGGGGGGGGGGGGG\n\nFurthermore, the following metadata can be parsed from the first line:\n- `refseqid` of the original sequence used for the read, e.g. `2591237:nbci-1`\n- `read_nbr` of the read, e.g. `1-60400\n\n\n\nAn alignment file in ALN format has a Header and main Body parts.\nThe header part includes the command used to generate this file and reference sequence id and length. The header @CM tag for command line, and @SQ for reference sequence.\nA Header always starts with ##ART and ends with ##Header End.\nHeader example, for ALN file generated by ART Illumina:\n    ##ART_Illumina  read_length 50\n    @CM /bin/art_illumina -i /home/vtec/projects/bio/metagentools/data/cov_data/cov_virus_sequences_ten.fa -ss HS25 -l 50 -f 100 -o /home/vtec/projects/bio/metagentools/data/cov_simreads/single_10seq_50bp/single_10seq_50bp -rs 1674660835\n    @SQ 2591237:ncbi:1 [MK211378]   2591237 ncbi    1 [MK211378] 2591237    Coronavirus BtRs-BetaCoV/YN2018D    30213\n    @SQ 11128:ncbi:2 [LC494191] 11128   ncbi    2 [LC494191] 11128  Bovine coronavirus      30942\n    @SQ 31631:ncbi:3 [KY967361] 31631   ncbi    3 [KY967361] 31631  Human coronavirus OC43      30661\n    ##Header End\nFor each reference sequence used to build the reads, we can parse the following metadata info:\n    refseqid:       2591237:ncbi:1\n    ref_seq_length: 30213\nThe Body part contains each read’s alignments in the following format:\n    &gt;refseqid   read_id   aln_start_pos    ref_seq_strand\n    ref_seq_aligned\n    read_seq_aligned \n\naln_start_pos is the alignment start position of the read in the reference sequence.\nref_seq_aligned is the aligned region of reference sequence, which can be from plus strand or minus strand of the reference sequence.\n\nread_seq_aligned is the aligned sequence read, which always in the same orientation of the same read in the corresponding fastq file.\n\naln_start_pos is always relative to the strand of reference sequence. That is, aln_start_pos 10 in the plus (+) strand is different from aln_start_pos 10 in the minus (‐) stand.\nBody example:\n    &gt;2591237:ncbi:1 2591237:ncbi:1-60400    14770   +\n    ACAACTCCTATTCGTAGTTGAAGTTGTTGACAAATACTTTGATTGTTACG\n    ACAACTCCTATTCGTAGTTGAAGTTGTTGACAAATACTTTGATTGTTACG\n    refseqid:          2591237:ncbi:1\n    readid:            2591237:ncbi:1-20100\n    aln_start_pos:     23878\n    ref_seq_strand:    -\n    ref_seq_aligned:   ACAACTCCTATTCGTAGTTGAAGTTGTTGACAAATACTTTGATTGTTACG\n    read_seq_aligned:  ACAACTCCTATTCGTAGTTGAAGTTGTTGACAAATACTTTGATTGTTACG\n\nReference information:\n\nART Illumina README file\nIllumina site\n\n\nThe quality score of a base, also known as a Phred or Q score, is an integer value representing the estimated probability of an error, i.e. the probability that the base is incorrectly sequenced.\nIf \\(P\\) is the error probability and \\(Q\\) is the quality score for a base, then:\n\n\\(P = 10^{-Q/10}\\)\n\\(Q = -10 \\log_{10}(P)\\)\n\nQ scores are often represented as ASCII characters. The rule for converting an ASCII character to an integer varies.\nThe two tables below convert between integer Q scores, ASCII characters and error probabilities.\nASCII_BASE = 33 (table on top) is now almost universally used. In older systems, ASCII_BASE = 64 is also used.\n\n\n\nimage.png\n\n\n(See reference here)\n\n\n\nASCII character is K\nASCII code is 75\nQ score: $Q = 75 - $ \\(= 75 - 33 = 42\\)\nP_error = \\(P = 10^{-Q/10}\\), i.e. \\(10^{-42/10}\\) = 0.00006\n\n\nPython note:\nDecode an ASCII character with ord(c) and encode it with chr(i)\n\n\nord('!'), chr(33), ord('K'), chr(75)\n\n(33, '!', 75, 'K')\n\n\n\nsource\n\n\n\n\n\n q_score2prob_error (char:str, ASCII_base:int=33)\n\nReturn the probability of error for a given Q score encoded as ASCII character\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nchar\nstr\n\nASCII character retrieved from Q Score or Phred value in FASTQ\n\n\nASCII_base\nint\n33\nASCII base. Mostly 33, can be 64 in old FASTQ files\n\n\n\n\n\nSelection of high Q score ASICC code, Q score values and corresponding P error:\nASCII Q Score | Q Score | P error\n--------------|---------|--------\n      K       |   42    | 0.00006 \n      J       |   41    | 0.00008 \n      I       |   40    | 0.00010 \n      H       |   39    | 0.00013 \n      G       |   38    | 0.00016 \n      F       |   37    | 0.00020 \n      E       |   36    | 0.00025 \n      D       |   35    | 0.00032 \n      C       |   34    | 0.00040 \n      B       |   33    | 0.00050 \n      A       |   32    | 0.00063 \n      @       |   31    | 0.00079 \n      ?       |   30    | 0.00100 \n      &gt;       |   29    | 0.00126 \n      =       |   28    | 0.00158 \n\n\nIn the case of the following FASTQ file:\n    @2591237:ncbi:1-60400\n    ACAACTCCTATTCGTAGTTGAAGTTGTTGACAAATACTTTGATTGTTACG\n    +\n    CCCBCGFGBGGGGGGGBGGGGGGGGG&gt;GGG1G=/GGGGGGGGGGGGGGGG\nThe following metadata information can be parsed:\n\nread_id, e.g. 2591237:ncbi:1-60400. The following information can be parsed:\n\nref_seq_id of the original sequence used for the read, e.g. 2591237:nbci-1\nread_nbr of the read, e.g. `60400\n\nsequence_read itself, e.g. ACAACTCCTATTCGTAGTTGAAGTTGTTGACAAATACTTTGATTGTTACG\nbase_quality_score, the Q Score in ASCII, e.g. CCCBCGFGBGGGGGGGBGGGGGGGGG&gt;GGG1G=/GGGGGGGGGGGGGGGG\n\nThis ASCII encoded Q Score can be converted into probability of error for each bp in the read:\n\nq_scores = 'CCCBCGFGBGGGGGGGBGGGGGGGGG&gt;GGG1G=/GGGGGGGGGGGGGGGG'\nnum_scores = [f\"{q_score2prob_error(char):6.5f}\" for char in q_scores]\nprint('; '.join(num_scores))\nprint(f\"Maximum error probability: {max(num_scores)}\")\n\n0.00040; 0.00040; 0.00040; 0.00050; 0.00040; 0.00016; 0.00020; 0.00016; 0.00050; 0.00016; 0.00016; 0.00016; 0.00016; 0.00016; 0.00016; 0.00016; 0.00050; 0.00016; 0.00016; 0.00016; 0.00016; 0.00016; 0.00016; 0.00016; 0.00016; 0.00016; 0.00126; 0.00016; 0.00016; 0.00016; 0.02512; 0.00016; 0.00158; 0.03981; 0.00016; 0.00016; 0.00016; 0.00016; 0.00016; 0.00016; 0.00016; 0.00016; 0.00016; 0.00016; 0.00016; 0.00016; 0.00016; 0.00016; 0.00016; 0.00016\nMaximum error probability: 0.03981\n\n\nIt shows that most bp have a very low probability of error, except a few bp with probability or 2.5% and 3.9%,",
    "crumbs": [
      "General Code",
      "bio"
    ]
  },
  {
    "objectID": "bio.html#standard-dna-codon-table",
    "href": "bio.html#standard-dna-codon-table",
    "title": "bio",
    "section": "Standard DNA codon table",
    "text": "Standard DNA codon table\nThese are the basic codon tables for DNA sequences. They are used to translate DNA sequences into amino acid sequences.\nDirect DNA codon table\n\nInverse DNA codon table\n\n(Source)\n\nsource\n\nStandardDNACodon\n\n StandardDNACodon ()\n\n*Hold standard DNA codon reference information\n\nDNA codon direct table: codon -&gt; amino acid information\nDNA codin inverse table amino acid code (e.g. Cys) -&gt; list of codons*\n\n\ncodons = StandardDNACodon()\n\n\nkey = 'Phe'\ncodons.inverse_table[key]\n\n{'amino acid name': 'Phenylalanine',\n 'amino acid letter': 'F',\n 'codons': ['TTT', 'TTC']}\n\n\n\nkey = 'TTT'\ncodons.direct_table[key]\n\n{'amino acid symbol': 'Phe',\n 'amino acid name': 'Phenylalanine',\n 'amino acid letter': 'F'}\n\n\n\ncodons.amino_acid_symbols[:5]\n\n['Ala', 'Arg', 'Asn', 'Asp', 'Cys']\n\n\n\ncodons.amino_acid_names[:5]\n\n['Alanine', 'Arginine', 'Asparagine', 'Aspartic acid', 'Cysteine']\n\n\n\ncodons.amino_acid_letters[:5]\n\n['A', 'R', 'N', 'D', 'C']",
    "crumbs": [
      "General Code",
      "bio"
    ]
  },
  {
    "objectID": "data_dev/ncbi/simreads/readme.html",
    "href": "data_dev/ncbi/simreads/readme.html",
    "title": "metagentools",
    "section": "",
    "text": "NCBI simulated reads\nThis directory includes all sets of simulated read sequence files generated from NCBI viral sequences using ARC Illumina.\nthis-directory\n    |--cov\n    |    |\n    |    |--single_10seq_50bp\n    |    |    |--single_10seq_50bp.fq\n    |    |    |--single_10seq_50bp.alnEnd\n    |    |-- ...\n    |    |--single_100seq_150bp\n    |    |    |--single_100seq_150bp.fq\n    |    |    |--single_100seq_150bp.aln\n    |    |--paired_100seq_50bp\n    |    |    |--paired_100seq_50bp2.aln\n    |    |    |--paired_100seq_50bp1.aln\n    |    |    |--paired_100seq_50bp2.fq\n    |    |    |--paired_100seq_50bp1.fq\n    |    |-- ...\n    |    |\n    |---yf\n    |    |\n    |    |--yf_AY968064-single-150bp\n    |    |    |--yf_AY968064-single-1seq-150bp.fq\n    |    |    |--yf_AY968064-single-1seq-150bp.aln\n    |    |\n    |--mRhiFer1\n    |    |--mRhiFer1_v1.p.dna_rm.primary_assembly.1\n    |    |    |--mRhiFer1_v1.p.dna_rm.primary_assembly.1.fq\n    |    |    |--mRhiFer1_v1.p.dna_rm.primary_assembly.1.aln\n    |    |\n\nThis directory includes several subdirectories, each for one virus, e.g. cov for corona, yf for yellow fever.\nIn each virus subdirectory, several simreads directory includes simulated reads with various parameters, named as &lt;method&gt;_&lt;nb-seq&gt;_&lt;nb-bp&gt; where” - &lt;method&gt; is either single or paired depending on the simulation method - &lt;nb-seq&gt; is the number of reference sequences used for simulation, and refers to the fa file used - &lt;nb-bp&gt; is the number of base pairs used to simulate reads\nEach sub-directory includes simreads files made using a simulation method and a specific number of reference sequences. - xxx.fq and xxx.aln files when method is single - xxx1.fq, xxx2.fq, xxx1.aln and xxx2.aln files when method is paired.\nExample: - paired_10seq_50bp means that the simreads were generated by using the paired method to simulate 50-bp reads, and using the fa file cov_virus_sequences_010-seqs.fa. - single_100seq_50bp means that the simreads were generated by using the single method to simulate 50-bp reads, and using the fa file cov_virus_sequences_100-seqs.fa. Note that this generated 20,660,104 reads !\n\nSimread file formats\nSimulated reads information is split between two files: - FASTQ (.fq) files providing the read sequences and their ASCII quality scores - ALN (.aln) files with alignment information\n\nFASTQ (.fq)\nFASTQ files generated by ART Illumina have the following structure (showing 5 reads), with 4 lines for each read:\n@2591237:ncbi:1-60400\nACAACTCCTATTCGTAGTTGAAGTTGTTGACAAATACTTTGATTGTTACG\n+\nCCCBCGFGBGGGGGGGBGGGGGGGGG&gt;GGG1G=/GGGGGGGGGGGGGGGG\n@2591237:ncbi:1-60399\nGATCAATGTGGCATCTACAATACAGACAGCATGAAGCACCACCAAAGGAC\n+\nBCBCCFGGGGGGGG1CGGGG&lt;GGBGGGGGFGCGGGGGGDGGG/GG1GGGG\n@2591237:ncbi:1-60398\nATCTACCAGTGGTAGATGGGTTCTTAATAATGAACATTATAGAGCTCTAC\n+\nCCCCCGGGEGG1GGF1G/GGEGGGGGGGGGGGGFFGGGGGGGGGGDGGDG\n@2591237:ncbi:1-60397\nCGTAAAGTAGAGGCTGTATGGTAGCTAGCACAAATGCCAGCACCAATAGG\n+\nBCCCCGGGFGGGGGGFGGGGFGG1GGGGGGG&gt;GG1GGGGGGGGGGE&lt;GGG\n@2591237:ncbi:1-60396\nGGTATCGGGTATCTCCTGCATCAATGCAAGGTCTTACAAAGATAAATACT\n+\nCBCCCGGG@CGGGGGGGGGGGG=GFGGGGDGGGFG1GGGGGGGG@GGGGG\nThe following information can be parsed from the each read sequence in the FASTQ file:\n\nLine 1: readid, a unique ID for the read, under for format @readid\nLine 2: readseq, the sequence of the read\nLine 3: a separator +\nLine 4: read_qscores, the base quality scores encoded in ASCII\n\nExample:\n@2591237:ncbi:1-60400\nACAACTCCTATTCGTAGTTGAAGTTGTTGACAAATACTTTGATTGTTACG\n+\nCCCBCGFGBGGGGGGGBGGGGGGGGG&gt;GGG1G=/GGGGGGGGGGGGGGGG\n\nreadid = 2591237:ncbi:1-60400\nreadseq = ACAACTCCTATTCGTAGTTGAAGTTGTTGACAAATACTTTGATTGTTACG, a 50 bp read\nread_qscores = CCCBCGFGBGGGGGGGBGGGGGGGGG&gt;GGG1G=/GGGGGGGGGGGGGGGG\n\n\n\n\nALN (.aln)\nALN files generated by ART Illumina consist of : - a header with the ART-Ilumina command used for the simulation (@CM) and info on each of the reference sequences used for the simulations (@SQ). Header always starts with ##ART_Illumina and ends with ##Header End : - the body with 3 lines for each read: 1. definition line with readid, - reference sequence identification number refseqid, - the position in the read in the reference sequence aln_start_pos - the strand the read was taken from ref_seq_strand. + for coding strand and - for template strand 2. aligned reference sequence, that is the sequence segment in the original reference corresponding to the read 3. aligned read sequence, that is the simmulated read sequence, where each bp corresponds to the reference sequence bp in the same position.\nExample of a ALN file generated by ART Illumina (showing 5 reads):\n##ART_Illumina    read_length    50\n@CM    /bin/art_illumina -i /home/vtec/projects/bio/metagentools/data/cov_data/cov_virus_sequences_ten.fa -ss HS25 -l 50 -f 100 -o /home/vtec/projects/bio/metagentools/data/cov_simreads/single_10seq_50bp/single_10seq_50bp -rs 1674660835\n@SQ    2591237:ncbi:1 1   MK211378    2591237    ncbi    1     Coronavirus BtRs-BetaCoV/YN2018D    30213\n@SQ    11128:ncbi:2   2   LC494191    11128    ncbi    2     Bovine coronavirus    30942\n@SQ    31631:ncbi:3   3   KY967361    31631    ncbi    3     Human coronavirus OC43        30661\n@SQ    277944:ncbi:4  4   LC654455    277944    ncbi    4     Human coronavirus NL63    27516\n@SQ    11120:ncbi:5   5   MN987231    11120    ncbi    5     Infectious bronchitis virus    27617\n@SQ    28295:ncbi:6   6   KU893866    28295    ncbi    6     Porcine epidemic diarrhea virus    28043\n@SQ    28295:ncbi:7   7   KJ645638    28295    ncbi    7     Porcine epidemic diarrhea virus    27998\n@SQ    28295:ncbi:8   8   KJ645678    28295    ncbi    8     Porcine epidemic diarrhea virus    27998\n@SQ    28295:ncbi:9   9   KR873434    28295    ncbi    9     Porcine epidemic diarrhea virus    28038\n@SQ    1699095:ncbi:10 10  KT368904    1699095    ncbi    10     Camel alphacoronavirus    27395\n##Header End\n&gt;2591237:ncbi:1    2591237:ncbi:1-60400    14770    +\nACAACTCCTATTCGTAGTTGAAGTTGTTGACAAATACTTTGATTGTTACG\nACAACTCCTATTCGTAGTTGAAGTTGTTGACAAATACTTTGATTGTTACG\n&gt;2591237:ncbi:1    2591237:ncbi:1-60399    17012    -\nGATCAATGTGGCATCTACAATACAGACAGCATGAAGCACCACCAAAGGAC\nGATCAATGTGGCATCTACAATACAGACAGCATGAAGCACCACCAAAGGAC\n&gt;2591237:ncbi:1    2591237:ncbi:1-60398    9188    +\nATCTACCAGTGGTAGATGGGTTCTTAATAATGAACATTATAGAGCTCTAC\nATCTACCAGTGGTAGATGGGTTCTTAATAATGAACATTATAGAGCTCTAC\n....."
  },
  {
    "objectID": "data_dev/readme.html",
    "href": "data_dev/readme.html",
    "title": "metagentools",
    "section": "",
    "text": "Data directory for metagentools development\nThis directory includes all the data required to test and validate metagentools code.\ndata_dev\n |--- CNN_Virus_data\n |     |--- 50mer_ds_100_seq\n |     |--- 150mer_ds_100_seq\n |     |--- train_short\n |     |--- val_short\n |     |--- weight_of_classes\n |--- ncbi\n |     |--- infer_results\n |     |     |--- cnn_virus\n |     |     |--- csv\n |     |     |--- xlsx\n |     |--- refsequences\n |     |     |--- cov\n |     |     |     |--- another_sequence.fa\n |     |     |     |--- cov_virus_sequences_one.fa\n |     |     |     |--- cov_virus_sequences_two.fa\n |     |     |     |--- sequences_two_no_matching_rule.fa\n |     |--- simreads\n |     |     |--- cov\n |     |     |     |--- paired_1seq_50bp\n |     |     |     |      |--- paired_1seq_50bp_1.aln\n |     |     |     |      |--- paired_1seq_50bp_1.fq\n |     |     |     |--- single_1seq_50bp\n |     |     |     |      |--- single_1seq_50bp_1.aln\n |     |     |     |      |--- single_1seq_50bp_1.fq\n |--- ....           \n |--- readme.md"
  }
]