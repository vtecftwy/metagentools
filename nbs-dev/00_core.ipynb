{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# core\n",
    "\n",
    "> This module is a placeholder and is a WIP that needs to be completed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp core"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from ecutilities.ipython import nb_setup\n",
    "from nbdev import nbdev_export, show_doc\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set autoreload mode\n"
     ]
    }
   ],
   "source": [
    "#| hide\n",
    "nb_setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import json\n",
    "import re\n",
    "from ecutilities.core import validate_path, validate_type\n",
    "from pathlib import Path\n",
    "from typing import Any, Optional"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Base iterators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class TextFileBaseIterator:\n",
    "    \"\"\"Iterator going through a text file by chunks of `nb_lines` lines\"\"\"\n",
    "    def __init__(\n",
    "        self, \n",
    "        path:str|Path,  # path to the file to read \n",
    "        nb_lines:int=1, # number of text lines in each text chunk \n",
    "    ):\n",
    "        validate_path(path, raise_error=True)\n",
    "        self.fp = open(path, 'r')\n",
    "        self.nb_lines = nb_lines\n",
    "\n",
    "    def __iter__(self):\n",
    "        return self\n",
    "\n",
    "    def _safe_readline(self):\n",
    "        \"\"\"Read a new line and handle end of file tasks\"\"\"\n",
    "        line = self.fp.readline()\n",
    "        if line == '':\n",
    "            self.fp.close()\n",
    "            raise StopIteration()\n",
    "        return line\n",
    "\n",
    "    def __next__(self):\n",
    "        \"\"\"Return one chunk at the time\"\"\"\n",
    "        lines = []\n",
    "        for i in range(self.nb_lines):\n",
    "            lines.append(self._safe_readline())\n",
    "        return ''.join(lines)\n",
    "    \n",
    "    def print_first_chuncks(self, nb_chunks=3):\n",
    "        \"\"\"Print the first few chuncks of text from the file\"\"\"\n",
    "        for i, chunk in enumerate(self.__iter__()):\n",
    "            if i > nb_chunks-1: break\n",
    "            print(f\"{self.nb_lines}-line chunk {i+1}\")\n",
    "            print(chunk)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/vtecftwy/metagentools/blob/main/metagentools/core.py#L14){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### TextFileBaseIterator\n",
       "\n",
       ">      TextFileBaseIterator (path:str|pathlib.Path, nb_lines:int=1)\n",
       "\n",
       "Iterator going through a text file by chunks of `nb_lines` lines\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| path | str \\| pathlib.Path |  | path to the file to read |\n",
       "| nb_lines | int | 1 | number of text lines in each text chunk |"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/vtecftwy/metagentools/blob/main/metagentools/core.py#L14){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### TextFileBaseIterator\n",
       "\n",
       ">      TextFileBaseIterator (path:str|pathlib.Path, nb_lines:int=1)\n",
       "\n",
       "Iterator going through a text file by chunks of `nb_lines` lines\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| path | str \\| pathlib.Path |  | path to the file to read |\n",
       "| nb_lines | int | 1 | number of text lines in each text chunk |"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(TextFileBaseIterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3-line chunk 1\n",
      "TCAAAATAATCAGAAATGTTGAACCTAGGGTTGGACACATAATGACCAGC\t76\t0\n",
      "ATTGTTTAACAATTTGTGCTCGTCCCGGTCACCCGCATCCAATCTTGATG\t4\t9\n",
      "AATCTTGTCCTATCCTACCCGCAGGGGAATTGATGATAGANGTGCTTTTA\t181\t0\n",
      "\n",
      "3-line chunk 2\n",
      "GGAGCGGAGCCAACCCCTATGCTCACTTGCAACCCAAGGGGCGTTCCAGT\t74\t3\n",
      "TGGATCCTGCGCGGGACGTCCTTTGTCTACGTCCCGTCGGCGCATCCCGC\t60\t3\n",
      "GAGAGACTTACTAAAAAGCTGGCACTTACCATCAGTGTTTCACCTACATG\t44\t0\n",
      "\n",
      "3-line chunk 3\n",
      "ACACACGACACTAGAGATAATGTGTCAGTGGATTATAAACAAACCAAGTT\t43\t7\n",
      "TTGTAGCATAAGAACTGGTCTTCGCTGAAATTCTTGTCTTGATCTCATCT\t35\t2\n",
      "TGGCCCTGCGGTCTGGGGCCCAGAAGCATATGTCAAGTCCTTTGAGAAGT\t73\t4\n",
      "\n",
      "3-line chunk 4\n",
      "TAGATTTAGTGGTTAGGTAGTAAGGCTACAATGTAAACACGTAGTGGCAA\t11\t6\n",
      "AACCCCTGGGGCTATAAAAGGCGCGGTCTGTGCACGGGGACTTCGGTNGG\t7\t7\n",
      "AGAATGGATAGTAAGGCAGACAGTAATAGGGGAGGCAATGAAGGAAACCA\t9\t2\n",
      "\n"
     ]
    }
   ],
   "source": [
    "p2textfile = Path('data_dev/train_short')\n",
    "\n",
    "it = TextFileBaseIterator(path=p2textfile, nb_lines=3)\n",
    "\n",
    "it.print_first_chuncks(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a base class.\n",
    "\n",
    "It is easy to override `__next__` method to customize how the iterator parses files.\n",
    "\n",
    "For instance, the following class takes a fasta sequence file, extracts the definition line and the sequence, and return them as a dictionary (to keep the output clean, we only return the first 25 bases of the sequence:\n",
    "```\n",
    "    {\n",
    "    'definition line': '>2591237:ncbi:1 [MK211378]\\t2591237\\tncbi\\t1 [MK211378] '\n",
    "                    '2591237\\tCoronavirus BtRs-BetaCoV/YN2018D\\t\\tscientific '\n",
    "                    'name\\n',\n",
    "    'sequence': 'TATTAGGTTTTCTACCTACCCAGGA'\n",
    "    }\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class FastaFileIterator(TextFileBaseIterator):\n",
    "    def __next__(self):\n",
    "        \"\"\"Return one definition line and the corresponding sequence\"\"\"\n",
    "        lines = []\n",
    "        for i in range(2):\n",
    "            lines.append(self._safe_readline())\n",
    "        return {'definition line':lines[0], 'sequence':f\"{lines[1]}\"}\n",
    "    def print_first_chuncks(self, nb_chunks=3):\n",
    "        \"\"\"Print the first few chuncks of text from the file\"\"\"\n",
    "        for i, seq_dict in enumerate(self.__iter__()):\n",
    "            print(f\"\\nSequence {i+1}:\")\n",
    "            print(seq_dict['definition line'])\n",
    "            print(f\"{seq_dict['sequence'][:80]} ...\")\n",
    "            if i >= nb_chunks: break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sequence 1:\n",
      ">2591237:ncbi:1 [MK211378]\t2591237\tncbi\t1 [MK211378] 2591237\tCoronavirus BtRs-BetaCoV/YN2018D\t\tscientific name\n",
      "\n",
      "TATTAGGTTTTCTACCTACCCAGGAAAAGCCAACCAACCTCGATCTCTTGTAGATCTGTTCTCTAAACGAACTTTAAAAT ...\n",
      "\n",
      "Sequence 2:\n",
      ">11128:ncbi:2 [LC494191]\n",
      "\n",
      "CATCCCGCTTCACTGATCTCTTGTTAGATCTTTTCATAATCTAAACTTTATAAAAACATCCACTCCCTGTAGTCTATGCC ...\n"
     ]
    }
   ],
   "source": [
    "p2fasta = Path('data_dev/cov_virus_sequences_two.fa')\n",
    "\n",
    "it = FastaFileIterator(p2fasta)\n",
    "it.print_first_chuncks(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "nbdev_export()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
